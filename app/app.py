# -------------------------------------------------------------
# ğŸ— AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ (ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper)
# -------------------------------------------------------------
# ğŸ“Š CSV ê¸°ë°˜ ë°ì´í„° ë°˜ì˜ ë²„ì „
# -------------------------------------------------------------

# --- must come first: add project root to sys.path BEFORE importing utils ---
import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent  # .../seoul_dashboard_3
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))
# ---------------------------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import altair as alt
from datetime import datetime

# === ì™¸ë¶€ ëª¨ë“ˆ (utils) ì„í¬íŠ¸ ===
from utils.traffic_preproc import ensure_speed_csv

# Altair/MPL/Plotly ìŠ¤ìœ„ì¹˜í˜•: plot_speedê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ í•¨ìˆ˜ë¡œ í´ë°±
try:
    from utils.traffic_plot import plot_speed
    _HAS_PLOT_SPEED = True
except Exception as e:
    print("utils.traffic_plot import fallback:", e)
    from utils.traffic_plot import plot_nearby_speed_from_csv
    _HAS_PLOT_SPEED = False

# === ë°ì´í„° ë””ë ‰í„°ë¦¬ ===
DATA_DIR = BASE_DIR / "data"

# === ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì´ë¦„ ì¶©ëŒ ë°©ì§€: ë³€ìˆ˜ëª… êµ¬ë¶„) ===
BASE_YEAR = 2023   # 24ë…„ìœ¼ë¡œ ë°”ê¿”ë„ ë¨

# ì¬ê±´ì¶• í”„ë¡œì íŠ¸ ì›ë³¸ CSV (ë‹¹ì‹ ì˜ appì—ì„œ ì“°ë˜ í‘œ ë°ì´í„°)
PROJECTS_CSV_PATH = DATA_DIR / "seoul_redev_projects.csv"

# êµí†µ ê¸°ì¤€ë…„ë„ ë°ì´í„° (ì—‘ì…€ â†’ CSV ìë™ ë³€í™˜ ëŒ€ìƒ)
TRAFFIC_XLSX_PATH = DATA_DIR / "AverageSpeed(LINK).xlsx"
TRAFFIC_CSV_PATH  = DATA_DIR / f"AverageSpeed_Seoul_{BASE_YEAR}.csv"

# ë„ë¡œë§ ë ˆë²¨55 ì‰ì´í”„
SHP_PATH = DATA_DIR / "seoul_link_lev5.5_2023.shp"



#===========================ìºì‹œ ë¹„ìš°ê¸°=================


with st.sidebar:
    if st.button("ìºì‹œ ë¹„ìš°ê¸°"):
        st.cache_data.clear()
        st.rerun()
   # ì¦‰ì‹œ ì¬ì‹¤í–‰
#======================================================

# ğŸ”¤ ì•ˆì „í•œ CSV ë¡œë”: ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
def smart_read_csv(path, encodings=("utf-8-sig", "cp949", "euc-kr", "utf-8", "latin1")):
    import pandas as pd
    last_err = None
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            return df
        except UnicodeDecodeError as e:
            last_err = e
            continue
    # ìµœí›„ ìˆ˜ë‹¨: errors='replace' ë¡œë¼ë„ ì½ê¸°
    try:
        df = pd.read_csv(path, encoding="utf-8", errors="replace")
        return df
    except Exception:
        raise last_err or Exception(f"Failed to read {path} with tried encodings.")



# -------------------------------------------------------------
# âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ ìë™ ì„¤ì •
# -------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent.parent
CSV_PATH = BASE_DIR / "data" / "seoul_redev_projects.csv"
CSV_ENCODING = "cp949"

# -------------------------------------------------------------
# ğŸ“¦ ì¢Œí‘œ CSV ë³‘í•© ìœ í‹¸
# -------------------------------------------------------------
# ë³€ê²½:
COORD_CSV_PATH = BASE_DIR / "data" / "ì„œìš¸ì‹œ_ì¬ê°œë°œì¬ê±´ì¶•_clean_kakao.csv"
COORD_ENCODING = "utf-8-sig"  # (ìŠ¤ë§ˆíŠ¸ ë¡œë”ê°€ ìë™íŒë³„í•˜ë¯€ë¡œ ì—†ì–´ë„ ë™ì‘)

# 1) CSV ë¡œë“œ ìœ í‹¸ (êµí†µëŸ‰ CSV)
@st.cache_data(show_spinner=False)
def load_volume_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["link_id"] = df["link_id"].astype(str)

    # ì‹œê°„ ì•ˆì „ ì •ê·œí™”: "0ì‹œ", " 08 ", "8.0" ë“±ë„ 0~23ìœ¼ë¡œ ë³€í™˜
    h = pd.to_numeric(
        pd.Series(df["hour"]).astype(str).str.extract(r"(\d+)", expand=False),
        errors="coerce"
    ).fillna(0).astype(int) % 24
    df["hour"] = h

    df["ì°¨ëŸ‰ëŒ€ìˆ˜"] = pd.to_numeric(df["ì°¨ëŸ‰ëŒ€ìˆ˜"], errors="coerce").fillna(0)
    return df


# 2) êµí†µëŸ‰ ê°€ì¤‘ í˜¼ì¡ë¹ˆë„ê°•ë„(CFI) ê³„ì‚°
def compute_cfi_weighted(speed_df: pd.DataFrame, vol_df: pd.DataFrame, boundary_speed: float = 30.0):
    d = speed_df.copy()
    d["link_id"] = d["link_id"].astype(str)
    d["hour"] = d["hour"].astype(int)
    d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")

    # merge
    m = d.merge(vol_df, on=["link_id", "hour"], how="inner")

    # í˜¼ì¡ ì°¨ëŸ‰ìˆ˜(ì†ë„<=ê²½ê³„ê°’) vs ì „ì²´ ì°¨ëŸ‰ìˆ˜
    m["í˜¼ì¡ì°¨ëŸ‰ìˆ˜"] = (m["í‰ê· ì†ë„(km/h)"] <= boundary_speed).astype(int) * m["ì°¨ëŸ‰ëŒ€ìˆ˜"]
    g = m.groupby(["link_id", "hour"], as_index=False).agg(
        ì „ì²´ì°¨ëŸ‰ìˆ˜=("ì°¨ëŸ‰ëŒ€ìˆ˜", "sum"),
        í˜¼ì¡ì°¨ëŸ‰ìˆ˜=("í˜¼ì¡ì°¨ëŸ‰ìˆ˜", "sum"),
    )
    g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = (g["í˜¼ì¡ì°¨ëŸ‰ìˆ˜"] / g["ì „ì²´ì°¨ëŸ‰ìˆ˜"]).replace([float("inf"), float("nan")], 0) * 100
    return g

def compute_cfi_soft(
    speed_df: pd.DataFrame,
    vol_df: pd.DataFrame,
    boundary_mode: str = "percentile",  # "percentile" or "fixed"
    boundary_value: float = 40.0,       # percentile: 10~90(%), fixed: km/h
    tau_kmh: float = 6.0                # ì‹œê·¸ëª¨ì´ë“œ ê¸‰ê²½ì‚¬ í­(ê°’ì´ í¬ë©´ ë” ë¶€ë“œëŸ¬ì›€)
):
    """
    í‰ê· ì†ë„(ì‹œê°„ëŒ€ë³„ 1ê°œ) + ì‹œê°„ëŒ€ ì´ ì°¨ëŸ‰ëŒ€ìˆ˜ë§Œ ìˆì„ ë•Œ
    ì‹œê·¸ëª¨ì´ë“œ ê¸°ë°˜ì˜ 'ë¶€ë“œëŸ¬ìš´' í˜¼ì¡ í™•ë¥ ì„ ë§Œë“¤ì–´ êµí†µëŸ‰ ê°€ì¤‘ CFI ê·¼ì‚¬.

    p_cong(V) = 1 / (1 + exp((V - vb) / tau)),  vbëŠ” ê²½ê³„ì†ë„
    í˜¼ì¡ë¹ˆë„ê°•ë„(%) = 100 * ( sum(volume * p_cong) / sum(volume) )

    - hour ì •ê·œí™”: 0~23
    - ì†ë„/êµí†µëŸ‰ ìˆ«ìí˜• ê°•ì œ ë³€í™˜
    """
    # --- ì†ë„ ë°ì´í„° ì •ë¦¬ ---
    d = speed_df.copy()
    d["link_id"] = d["link_id"].astype(str)
    d["hour"] = pd.to_numeric(d["hour"], errors="coerce").astype("Int64")  # allow NA
    d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")

    # --- êµí†µëŸ‰ ë°ì´í„° ì •ë¦¬ ---
    v = vol_df.copy()
    v["link_id"] = v["link_id"].astype(str)
    # "0ì‹œ" ê°™ì€ ë¬¸ìì—´ì´ ì™€ë„ ì•ˆì „í•˜ê²Œ 0~23ìœ¼ë¡œ ì •ê·œí™”
    v["hour"] = pd.to_numeric(v["hour"], errors="coerce").astype("Int64") % 24
    v["ì°¨ëŸ‰ëŒ€ìˆ˜"] = pd.to_numeric(v["ì°¨ëŸ‰ëŒ€ìˆ˜"], errors="coerce").fillna(0)

    # --- ë³‘í•© ---
    m = d.merge(v, on=["link_id", "hour"], how="inner").dropna(subset=["í‰ê· ì†ë„(km/h)"])
    if m.empty:
        out = m[["link_id","hour"]].copy()
        out["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = 0.0
        out.attrs = {"boundary": np.nan, "mode": boundary_mode}
        return out

    # --- ê²½ê³„ì†ë„ ê²°ì • ---
    if boundary_mode == "percentile":
        p = float(boundary_value)
        p = max(5.0, min(95.0, p))  # ì•ˆì „ ë²”ìœ„
        vb = float(np.nanpercentile(m["í‰ê· ì†ë„(km/h)"], p))
    else:
        vb = float(boundary_value)

    # --- ì‹œê·¸ëª¨ì´ë“œ í˜¼ì¡í™•ë¥  ---
    tau = max(1e-6, float(tau_kmh))
    # V > vbì´ë©´ 0ìª½, V < vbì´ë©´ 1ìª½ìœ¼ë¡œ ì—°ì†ì ìœ¼ë¡œ ë³€í•¨
    m["p_cong"] = 1.0 / (1.0 + np.exp((m["í‰ê· ì†ë„(km/h)"] - vb) / tau))

    # --- ë§í¬Ã—ì‹œê°„ëŒ€ë¡œ ì§‘ê³„ (êµí†µëŸ‰ ê°€ì¤‘ í‰ê· ) ---
    # ê°€ì¤‘í‰ê· : sum(w*x)/sum(w)
    def _wavg(x, w):
        w = np.asarray(w)
        x = np.asarray(x)
        mask = np.isfinite(x) & np.isfinite(w) & (w >= 0)
        if not mask.any():
            return 0.0
        return float((x[mask] * w[mask]).sum() / max(1e-9, w[mask].sum()))

    g = (
        m.groupby(["link_id","hour"], as_index=False)
         .apply(lambda df: pd.Series({
             "í˜¼ì¡ë¹ˆë„ê°•ë„(%)": _wavg(df["p_cong"], df["ì°¨ëŸ‰ëŒ€ìˆ˜"]) * 100.0
         }))
         .reset_index()
    )

    # ì•ˆì „ í´ë¦½
    g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"].clip(0, 100)
    g.attrs = {"boundary": vb, "mode": boundary_mode, "tau": tau}
    return g



@st.cache_data(show_spinner=False)
def load_coords() -> pd.DataFrame:
    df = smart_read_csv(COORD_CSV_PATH)

    # ìˆ«ìí™”
    df["lat"] = pd.to_numeric(df.get("lat"), errors="coerce")
    df["lon"] = pd.to_numeric(df.get("lon"), errors="coerce")

    # ì•ˆì „í•œ ë³‘í•©ìš© ê¸°ì´ˆ ì»¬ëŸ¼ ìƒì„±
    def coalesce(a, b):
        a = "" if a is None else str(a).strip()
        b = "" if b is None else str(b).strip()
        return a if a else b

    # name, address ë§Œë“¤ê¸°
    if ("ì •ë¹„êµ¬ì—­ëª…ì¹­" in df.columns) or ("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…" in df.columns):
        name = [coalesce(n, m) for n, m in zip(df.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), df.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))]
    else:
        name = df.get("name")

    address = [coalesce(a, b) for a, b in zip(df.get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), df.get("ëŒ€í‘œì§€ë²ˆ"))]

    out = pd.DataFrame({
        "apt_id": df.get("ì‚¬ì—…ë²ˆí˜¸").astype(str) if "ì‚¬ì—…ë²ˆí˜¸" in df.columns else "",
        "name": pd.Series(name, index=df.index),
        "gu": df.get("ìì¹˜êµ¬"),
        "address": pd.Series(address, index=df.index),
        "full_address": df.get("full_address"),
        "lat": df["lat"],
        "lon": df["lon"],
    })
    for col in ["apt_id", "name", "gu", "address", "full_address"]:
        if col in out.columns:
            out[col] = out[col].fillna("").astype(str).str.strip()
    return out


@st.cache_data(show_spinner=False)
def merge_projects_with_coords(gu: str) -> pd.DataFrame:
    # 1) ì›ë³¸ ë¡œë“œ + ìŠ¤í‚¤ë§ˆ í†µì¼
    raw = load_raw_csv()
    proj = normalize_schema(raw)
    proj = proj[proj["gu"] == gu].copy()

    # 2) ì¢Œí‘œ ë¡œë“œ
    coords = load_coords()
    coords = coords[coords["gu"] == gu].copy()

    # 3) âœ… name+gu ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­í•˜ê³  full_addressê¹Œì§€ ê°€ì ¸ì˜¤ê¸°
    out = proj.merge(
        coords[["name", "gu", "lat", "lon", "full_address"]],
        on=["name", "gu"],
        how="left"
    )

    # 4) ì¢Œí‘œ ê²°ì¸¡ ë³´ì • (êµ¬ ì¤‘ì‹¬ + ì§€í„°)
    missing = out["lat"].isna() | out["lon"].isna()
    base_lat, base_lon = GU_CENTER.get(gu, (37.55, 127.0))
    rng = np.random.default_rng(42)
    jitter = lambda n: rng.normal(0, 0.002, n)  # â‰ˆ 200m
    if missing.any():
        n = int(missing.sum())
        out.loc[missing, "lat"] = base_lat + jitter(n)
        out.loc[missing, "lon"] = base_lon + jitter(n)
    out["has_geo"] = ~missing

    # 5) âœ… í‘œì‹œìš© ì£¼ì†Œ: full_address ìš°ì„ , ì—†ìœ¼ë©´ ì›ë³¸ address
    out["address_display"] = out["full_address"].fillna("").replace("", pd.NA)
    out["address_display"] = out["address_display"].fillna(out["address"]).fillna("")

    return out.reset_index(drop=True)


# -------------------------------------------------------------
# âš™ï¸ Streamlit ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------------
st.set_page_config(
    page_title="AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ | ì¬ê±´ì¶• Helper",
    layout="wide",
)

st.markdown("""
<style>
/* ëª¨ë“  LaTeX ìˆ˜ì‹ì„ ì™¼ìª½ ì •ë ¬ë¡œ */
.katex-display {
    text-align: left !important;
    margin-left: 0 !important;
}

/* í…ìŠ¤íŠ¸ ì „ì²´ ê¸°ë³¸ ì™¼ìª½ ì •ë ¬ ìœ ì§€ */
.block-container {
    text-align: left !important;
}
</style>
""", unsafe_allow_html=True)


STYLE = """
<style>
.small-muted { color: #7a7a7a; font-size: 0.9rem; }
.kpi-card { padding: 16px; border-radius: 16px; background: #111827; border: 1px solid #1f2937; }
.kpi-title { font-size: 0.9rem; color: #9ca3af; margin-bottom: 8px; }
.kpi-value { font-size: 1.4rem; font-weight: 700; color: #e5e7eb; }
.section-title { font-size: 1.1rem; font-weight: 700; margin-bottom: 8px; }
hr.soft { border: none; height: 1px; background: #1f2937; margin: 16px 0; }
</style>
"""
st.markdown(STYLE, unsafe_allow_html=True)

st.markdown("""
<style>
/* Streamlitì˜ ê¸°ë³¸ center ì •ë ¬ì„ ê°•ì œë¡œ ë¬´ë ¥í™” â€” ë” ê°•í•œ ì„ íƒì ì‚¬ìš© */
div[data-testid="stMarkdownContainer"] .katex-display {
    text-align: left !important;
    margin-left: 0 !important;
    margin-right: auto !important;
}

/* KaTeX ë‚´ë¶€ ë°•ìŠ¤ë¥¼ ì¤„ ë§ì¶° ë¶™ê²Œ */
div[data-testid="stMarkdownContainer"] .katex-display > .katex {
    display: inline-block !important;
}

/* ì¼ë°˜ ë¬¸ë‹¨ë„ í˜¹ì‹œ ëª¨ë¥¼ ê°€ìš´ë°ì •ë ¬ì„ ë°©ì§€ */
div[data-testid="stMarkdownContainer"] p {
    text-align: left !important;
    margin-left: 0 !important;
}
</style>
""", unsafe_allow_html=True)


# -------------------------------------------------------------
# ğŸ§¾ CSV ë¡œë“œ & ì „ì²˜ë¦¬
# -------------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_raw_csv() -> pd.DataFrame:
    return smart_read_csv(PROJECTS_CSV_PATH)  # âœ… ì¸ì½”ë”© ìë™ ê°ì§€ ì‚¬ìš©


def _coalesce(*vals):
    for v in vals:
        if pd.notna(v) and str(v).strip():
            return v
    return None

def normalize_schema(df_raw: pd.DataFrame) -> pd.DataFrame:
    c = df_raw.columns
    get = lambda name: df_raw[name] if name in c else pd.Series([None]*len(df_raw))

    def _num(x):
        return pd.to_numeric(pd.Series(x, index=df_raw.index), errors="coerce")

    def _pct_to_num(x):
        s = pd.Series(x, index=df_raw.index).astype(str).str.replace("%", "", regex=False)
        s = s.str.replace(",", "", regex=False)
        return pd.to_numeric(s, errors="coerce")

    def _floors_to_num(x):
        # ìˆ«ìë§Œ ì¶”ì¶œ(ì§€ìƒ/ì§€í•˜ ë‘˜ ë‹¤ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        s = pd.Series(x, index=df_raw.index).astype(str).str.extract(r"(-?\d+)", expand=False)
        return pd.to_numeric(s, errors="coerce")

    # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ë§¤í•‘
    df = pd.DataFrame({
        "apt_id": get("ì‚¬ì—…ë²ˆí˜¸"),
        "name": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))],
        "org_name": get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "biz_type": get("ì‚¬ì—…êµ¬ë¶„"),
        "op_type": get("ìš´ì˜êµ¬ë¶„"),
        "gu": get("ìì¹˜êµ¬"),
        "address": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), get("ëŒ€í‘œì§€ë²ˆ"))],
        "households": _num(get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜")),
        "land_area_m2": _num(get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)")),
        "far": _pct_to_num(get("ìš©ì ë¥ ")),          # ìš©ì ë¥ (%) â†’ ìˆ«ì
        "floors": _floors_to_num(get("ì¸µìˆ˜")),      # ë‹¨ì¼ â€˜ì¸µìˆ˜â€™ê°€ ìˆì„ ë•Œ
        "status": get("ì§„í–‰ë‹¨ê³„"),                  # âœ… ì§„í–‰ë‹¨ê³„ ì¶”ê°€
        # â¬‡ï¸ ì§€ìƒ/ì§€í•˜ì¸µìˆ˜ ì§€ì› (ìˆìœ¼ë©´ í‘œì‹œìš©ìœ¼ë¡œ ì˜ˆì˜ê²Œ)
        "floors_up": _floors_to_num(get("ì§€ìƒì¸µìˆ˜")),
        "floors_down": _floors_to_num(get("ì§€í•˜ì¸µìˆ˜")),
    })

    # ì¸µìˆ˜ í‘œì‹œ ë¬¸ìì—´ (ì˜ˆ: "ì§€ìƒ 35 / ì§€í•˜ 3")
    def _fmt_floor(u, d):
        parts = []
        if pd.notna(u):
            parts.append(f"ì§€ìƒ {int(u)}")
        if pd.notna(d):
            parts.append(f"ì§€í•˜ {int(d)}")
        return " / ".join(parts)

    df["floors_display"] = [_fmt_floor(u, d) for u, d in zip(df["floors_up"], df["floors_down"])]

    # ìµœì¢… í‘œì‹œìš© ì¸µìˆ˜: ì§€ìƒ/ì§€í•˜ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ ë‹¨ì¼ ìˆ«ìì¸µì„ "Nì¸µ"ìœ¼ë¡œ
    df["floors_show"] = df["floors_display"].fillna("").astype(str).str.strip()
    mask_empty = df["floors_show"] == ""
    df.loc[mask_empty, "floors_show"] = df.loc[mask_empty, "floors"].apply(
        lambda x: f"{int(x)}ì¸µ" if pd.notna(x) else ""
    )

    # ë¬¸ìì—´ ì •ë¦¬
    df["apt_id"] = df["apt_id"].astype(str)
    df["name"] = df["name"].fillna("ë¬´ëª… ì •ë¹„êµ¬ì—­")
    for col in ["org_name","biz_type","op_type","gu","address","status"]:
        df[col] = df[col].fillna("").astype(str).str.strip()

    return df



@st.cache_data(show_spinner=False)
def get_projects_by_gu(gu: str) -> pd.DataFrame:
    raw = load_raw_csv()
    norm = normalize_schema(raw)
    return norm[norm["gu"] == gu].reset_index(drop=True)

# -------------------------------------------------------------
# ğŸ“ ì„œìš¸ì‹œ 25ê°œ ìì¹˜êµ¬ ë¦¬ìŠ¤íŠ¸ & ì¤‘ì‹¬ì¢Œí‘œ
# -------------------------------------------------------------
DISTRICTS = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬",
    "ë…¸ì›êµ¬","ë„ë´‰êµ¬","ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬",
    "ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬","ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]

GU_CENTER = {
    "ê°•ë‚¨êµ¬": (37.5172, 127.0473),
    "ê°•ë™êµ¬": (37.5301, 127.1238),
    "ê°•ë¶êµ¬": (37.6396, 127.0257),
    "ê°•ì„œêµ¬": (37.5509, 126.8495),
    "ê´€ì•…êµ¬": (37.4784, 126.9516),
    "ê´‘ì§„êµ¬": (37.5386, 127.0822),
    "êµ¬ë¡œêµ¬": (37.4955, 126.8876),
    "ê¸ˆì²œêµ¬": (37.4569, 126.8958),
    "ë…¸ì›êµ¬": (37.6543, 127.0565),
    "ë„ë´‰êµ¬": (37.6688, 127.0471),
    "ë™ëŒ€ë¬¸êµ¬": (37.5740, 127.0396),
    "ë™ì‘êµ¬": (37.5124, 126.9393),
    "ë§ˆí¬êµ¬": (37.5638, 126.9084),
    "ì„œëŒ€ë¬¸êµ¬": (37.5791, 126.9368),
    "ì„œì´ˆêµ¬": (37.4836, 127.0326),
    "ì„±ë™êµ¬": (37.5633, 127.0369),
    "ì„±ë¶êµ¬": (37.5894, 127.0167),
    "ì†¡íŒŒêµ¬": (37.5145, 127.1068),
    "ì–‘ì²œêµ¬": (37.5169, 126.8665),
    "ì˜ë“±í¬êµ¬": (37.5264, 126.8963),
    "ìš©ì‚°êµ¬": (37.5311, 126.9811),
    "ì€í‰êµ¬": (37.6176, 126.9227),
    "ì¢…ë¡œêµ¬": (37.5736, 126.9780),
    "ì¤‘êµ¬": (37.5636, 126.9976),
    "ì¤‘ë‘êµ¬": (37.6063, 127.0929),
}


def attach_latlon_by_gu_centroid(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["lat"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[0]) + np.random.normal(scale=0.004, size=len(df))
    df["lon"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[1]) + np.random.normal(scale=0.004, size=len(df))
    return df


# -------------------------------------------------------------
# ğŸ§­ ì‚¬ì´ë“œë°”
# -------------------------------------------------------------
st.sidebar.title("ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper")


# ì‚¬ì´ë“œë°” - êµ¬ ì„ íƒ
selected_gu = st.sidebar.selectbox("êµ¬ ì„ íƒ", DISTRICTS, index=0)

# âœ… ì„¸ì…˜ì— ì„ íƒ ì¸ë±ìŠ¤ ì´ˆê¸°í™”(ë§¨ ìœ„ í•œ ë²ˆ)
# - ì²« ì§„ì…: selected_row í‚¤ê°€ ì—†ìœ¼ë‹ˆ Noneìœ¼ë¡œ ì„¸íŒ…
# - ìì¹˜êµ¬ë¥¼ ë³€ê²½í–ˆì„ ë•Œ: ì´ì „ êµ¬ì™€ ë‹¤ë¥´ë©´ ì„ íƒì„ ë¦¬ì…‹
if "selected_row" not in st.session_state:
    st.session_state.selected_row = None
if "selected_gu_prev" not in st.session_state:
    st.session_state.selected_gu_prev = selected_gu

if st.session_state.selected_gu_prev != selected_gu:
    st.session_state.selected_row = None           # êµ¬ê°€ ë°”ë€Œë©´ ì„ íƒ ì´ˆê¸°í™”
    st.session_state.selected_gu_prev = selected_gu

st.sidebar.markdown(
    "<div class='small-muted'>êµ¬ ì„ íƒ ì‹œ, í•´ë‹¹ êµ¬ì˜ ì •ë¹„ì‚¬ì—… ë‹¨ì§€ ëª©ë¡ê³¼ ì§€ë„ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.</div>",
    unsafe_allow_html=True,
)

project_name = st.sidebar.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=f"{selected_gu} ì¬ê±´ì¶• ì‹œë‚˜ë¦¬ì˜¤")

# -------------------------------------------------------------
# ğŸ—ºï¸ 1-2ì‚¬ë¶„ë©´: ì§€ë„ + ë‹¨ì§€ ì„ íƒ
# -------------------------------------------------------------
col12_left, col12_right = st.columns([2.2, 1.4], gap="large")

with col12_left:
    st.markdown("### ğŸ—º 1-2ì‚¬ë¶„ë©´ Â· ì§€ë„ & ë‹¨ì§€ì„ íƒ")

    base_df = get_projects_by_gu(selected_gu)
    df_map = merge_projects_with_coords(selected_gu)


    # ì§€ë„ ìë¦¬ë§Œ ë¨¼ì € í™•ë³´ (í•„í„°/ì„ íƒ ì ìš© í›„ ì•„ë˜ì—ì„œ ì‹¤ì œ ì°¨íŠ¸ ë Œë”)
    map_slot = st.empty()

    if df_map.empty:
        st.warning("âš ï¸ í•´ë‹¹ êµ¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()


# ---------------------------
# ğŸ“‹ ë‹¨ì§€ í…Œì´ë¸” + í•„í„° UI
# ---------------------------
with st.expander("ğŸ” ë°ì´í„° ì†ŒìŠ¤ í™•ì¸(ì„ì‹œ)", expanded=False):
    # 1) ì›ë³¸ CSV ê·¸ëŒ€ë¡œ ë³´ê¸°
    raw = load_raw_csv()
    cols_raw = ["ìì¹˜êµ¬", "ì •ë¹„êµ¬ì—­ëª…ì¹­", "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…", "ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜", "ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"]
    exist_cols = [c for c in cols_raw if c in raw.columns]
    st.caption(f"ì›ë³¸: {CSV_PATH.name} Â· í‘œì‹œì—´: {', '.join(exist_cols)}")
    try:
        st.dataframe(
            raw[exist_cols][raw["ìì¹˜êµ¬"] == selected_gu].head(20),
            use_container_width=True
        )
    except Exception:
        st.dataframe(raw[exist_cols].head(20), use_container_width=True)

    # 2) í˜„ì¬ í™”ë©´ì— ì“°ëŠ” df_map ê°’ ë³´ê¸°
    st.caption("í˜„ì¬ í‘œì‹œê°’(df_map)")
    st.dataframe(
        df_map[["gu", "address_display", "name", "households", "land_area_m2"]].head(20),
        use_container_width=True
    )

    # 3) ì›ë³¸ê°’ê³¼ df_map ê°’ ìë™ ë¹„êµ (name+gu ê¸°ì¤€)
    def _coalesce(a, b):
        a = "" if a is None else str(a).strip()
        b = "" if b is None else str(b).strip()
        return a if a else b

    raw_norm = pd.DataFrame({
        "gu": raw.get("ìì¹˜êµ¬"),
        "name_raw": [
            _coalesce(n, m) for n, m in zip(
                raw.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"),
                raw.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…")
            )
        ],
        "households_src": pd.to_numeric(raw.get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜"), errors="coerce"),
        "land_area_m2_src": pd.to_numeric(raw.get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"), errors="coerce"),
    })

    comp = df_map.merge(
        raw_norm, left_on=["name","gu"], right_on=["name_raw","gu"], how="left"
    )

    # ì •ìˆ˜/ì‹¤ìˆ˜ ë¹„êµ: ë©´ì ì€ ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ë¥¼ í—ˆìš©
    hh_match  = (comp["households"].fillna(-1).astype(float) == comp["households_src"].fillna(-1).astype(float))
    area_match = np.isclose(
        comp["land_area_m2"].astype(float),
        comp["land_area_m2_src"].astype(float),
        rtol=1e-6, atol=1e-6, equal_nan=True
    )

    comp["households_match"] = hh_match
    comp["land_area_match"]  = area_match

    total = len(comp)
    hh_ok  = int(hh_match.sum())
    ar_ok  = int(area_match.sum())

    st.write(
        f"âœ… ì„¸ëŒ€ìˆ˜ ì¼ì¹˜: **{hh_ok}/{total}**  Â·  "
        f"âœ… ë©´ì  ì¼ì¹˜: **{ar_ok}/{total}**"
    )

    bad = comp[~(hh_match & area_match)][
        ["gu","address_display","name","households","households_src","land_area_m2","land_area_m2_src"]
    ]
    if not bad.empty:
        st.warning("ë¶ˆì¼ì¹˜ ìƒ˜í”Œ(ìµœëŒ€ 20ê±´):")
        st.dataframe(bad.head(20), use_container_width=True)



st.markdown("**ë‹¨ì§€ ëª©ë¡**")

# âœ… í…Œì´ë¸”ì— ì“¸ ì»¬ëŸ¼ êµ¬ì„±
# âœ… í…Œì´ë¸”ì— ì“¸ ì»¬ëŸ¼ êµ¬ì„± (ìš©ì ë¥ /ì¸µìˆ˜/ì§„í–‰ë‹¨ê³„ í¬í•¨)
df_list = df_map[[
    "apt_id",
    "address_display",
    "org_name", "biz_type", "op_type",
    "status",            # ì§„í–‰ë‹¨ê³„
    "households", "land_area_m2",
    "far",               # ìš©ì ë¥ (%)
    "floors_show",       # ì¸µìˆ˜(ì§€ìƒ/ì§€í•˜ ìˆìœ¼ë©´ ì˜ˆì˜ê²Œ, ì—†ìœ¼ë©´ Nì¸µ)
]].copy()

# ìˆ«ìí˜• ë³´ì • (í‘œì‹œí˜• í…ìŠ¤íŠ¸ì¸ floors_showëŠ” ê·¸ëŒ€ë¡œ)
df_list["households"]   = pd.to_numeric(df_list["households"], errors="coerce")
df_list["land_area_m2"] = pd.to_numeric(df_list["land_area_m2"], errors="coerce")
df_list["far"]          = pd.to_numeric(df_list["far"], errors="coerce")

# ===== í•„í„° ì˜ì—­ =====
fcol1, fcol2, fcol3, fcol4 = st.columns([1.6, 1.4, 1.6, 1.2])

with fcol1:
    kw = st.text_input("ê²€ìƒ‰ì–´(ì£¼ì†Œ/ì¡°í•©ëª…/í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ) ê°œí¬, ëª©ë™, ì¡°í•©")

# âœ… ë“œë¡­ë‹¤ìš´ ë²”ì£¼ ì •ì˜
HH_BUCKETS = {
    "ì „ì²´": (None, None),
    "~ 300ì„¸ëŒ€": (0, 300),
    "301â€“500ì„¸ëŒ€": (301, 500),
    "501â€“1,000ì„¸ëŒ€": (501, 1000),
    "1,001â€“2,000ì„¸ëŒ€": (1001, 2000),
    "2,001ì„¸ëŒ€ ì´ìƒ": (2001, None),
}

AREA_BUCKETS = {
    "ì „ì²´": (None, None),
    "~ 30,000 mÂ²": (0, 30000),
    "30,001â€“50,000 mÂ²": (30001, 50000),
    "50,001â€“100,000 mÂ²": (50001, 100000),
    "100,001â€“200,000 mÂ²": (100001, 200000),
    "200,001 mÂ² ì´ìƒ": (200001, None),
}

with fcol2:
    hh_choice = st.selectbox("ì„¸ëŒ€ìˆ˜ ë²”ì£¼", list(HH_BUCKETS.keys()), index=0)

with fcol3:
    la_choice = st.selectbox("ë©´ì  ë²”ì£¼(mÂ²)", list(AREA_BUCKETS.keys()), index=0)

with fcol4:
    hide_zero = st.checkbox("0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°", value=True)


# ===== í•„í„° ì ìš© =====
mask = pd.Series(True, index=df_list.index)

if kw.strip():
    _kw = kw.strip().lower()
    mask &= (
        df_list["address_display"].fillna("").str.lower().str.contains(_kw) |
        df_list["org_name"].fillna("").str.lower().str.contains(_kw)
    )

# âœ… ë“œë¡­ë‹¤ìš´ ì„ íƒê°’ì„ ì‹¤ì œ í•„í„°ë¡œ ì ìš©
hh_lo, hh_hi = HH_BUCKETS[hh_choice]
la_lo, la_hi = AREA_BUCKETS[la_choice]

# ì„¸ëŒ€ìˆ˜ í•„í„°
col_series = df_list["households"].fillna(-1)
if hh_lo is not None:
    mask &= col_series >= hh_lo
if hh_hi is not None:
    mask &= col_series <= hh_hi

# ë©´ì  í•„í„°
col_series = df_list["land_area_m2"].fillna(-1)
if la_lo is not None:
    mask &= col_series >= la_lo
if la_hi is not None:
    mask &= col_series <= la_hi

# 0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°
if hide_zero:
    mask &= df_list["households"].fillna(0) > 0
    mask &= df_list["land_area_m2"].fillna(0) > 0

filtered = df_list[mask].reset_index().rename(columns={"index": "orig_index"})

# ===== ì •ë ¬ ì˜µì…˜ =====
scol1, scol2 = st.columns([1.2, 1.2])
with scol1:
    sort_key = st.selectbox("ì •ë ¬ ê¸°ì¤€",
        ["ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ", "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ", "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ", "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ", "ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ"], index=0)
with scol2:
    topn = st.selectbox("í‘œì‹œ ê°œìˆ˜", [10, 20, 50, 100, "ì „ì²´"], index=1)

if sort_key == "ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=False, na_position="last")
elif sort_key == "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=True, na_position="last")
elif sort_key == "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=False, na_position="last")
elif sort_key == "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=True, na_position="last")
elif sort_key == "ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("address_display", ascending=True, na_position="last")

if topn != "ì „ì²´":
    filtered = filtered.head(int(topn))

# ===== í…Œì´ë¸” í‘œì‹œ (ìš”ì²­í•œ ì»¬ëŸ¼/ë¼ë²¨ë¡œ)
show_df = filtered[[
    "orig_index",
    "address_display", "org_name", "biz_type", "op_type",
    "status",                    # ì§„í–‰ë‹¨ê³„
    "households", "land_area_m2",
    "far", "floors_show",        # ìš©ì ë¥ , ì¸µìˆ˜
]].copy().rename(columns={
    "address_display": "ì£¼ì†Œ",
    "org_name": "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…",
    "biz_type": "ì‚¬ì—…êµ¬ë¶„",
    "op_type": "ìš´ì˜êµ¬ë¶„",
    "status": "ì§„í–‰ë‹¨ê³„",
    "households": "ê³„íšì„¸ëŒ€ìˆ˜",
    "land_area_m2": "ë©´ì ",
    "far": "ìš©ì ë¥ (%)",
    "floors_show": "ì¸µìˆ˜",        # í‘œì‹œìš© í…ìŠ¤íŠ¸ë¥¼ â€˜ì¸µìˆ˜â€™ ë¼ë²¨ë¡œ
})

# âœ… í‘œ ë‚´ë¶€ì—ì„œ ì§ì ‘ ì„ íƒí•˜ëŠ” 'ì„ íƒ' ì»¬ëŸ¼ ì¶”ê°€(ë‹¨ì¼ ì„ íƒ ê°•ì œ ë¡œì§ì€ ê¸°ì¡´ ê·¸ëŒ€ë¡œ ìœ ì§€)
show_df.insert(1, "ì„ íƒ", False)

curr_ids = show_df["orig_index"].tolist()
if (st.session_state.selected_row is None) or (st.session_state.selected_row not in curr_ids):
    st.session_state.selected_row = int(curr_ids[0]) if curr_ids else None
show_df.loc[show_df["orig_index"] == st.session_state.selected_row, "ì„ íƒ"] = True


edited = st.data_editor(
    show_df,
    use_container_width=True,
    hide_index=True,
    disabled=[
        "orig_index", "ì£¼ì†Œ", "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…", "ì‚¬ì—…êµ¬ë¶„", "ìš´ì˜êµ¬ë¶„",
        "ì§„í–‰ë‹¨ê³„", "ê³„íšì„¸ëŒ€ìˆ˜", "ë©´ì ", "ìš©ì ë¥ (%)", "ì¸µìˆ˜"   # ë¹„í¸ì§‘
    ],
    column_config={
        "orig_index": st.column_config.NumberColumn("ì›ë³¸ì¸ë±ìŠ¤", help="ë‚´ë¶€ ì„ íƒìš©", width="small"),
        "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ì´ í–‰ì„ ì„ íƒ"),
        "ì£¼ì†Œ": st.column_config.TextColumn("ì£¼ì†Œ"),
        "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…": st.column_config.TextColumn("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "ì‚¬ì—…êµ¬ë¶„": st.column_config.TextColumn("ì‚¬ì—…êµ¬ë¶„"),
        "ìš´ì˜êµ¬ë¶„": st.column_config.TextColumn("ìš´ì˜êµ¬ë¶„"),
        "ì§„í–‰ë‹¨ê³„": st.column_config.TextColumn("ì§„í–‰ë‹¨ê³„"),
        "ê³„íšì„¸ëŒ€ìˆ˜": st.column_config.NumberColumn("ê³„íšì„¸ëŒ€ìˆ˜", format="%,d"),
        "ë©´ì ": st.column_config.NumberColumn("ë©´ì (mÂ²)", format="%,d"),
        "ìš©ì ë¥ (%)": st.column_config.NumberColumn("ìš©ì ë¥ (%)", format=",.1f"),
        "ì¸µìˆ˜": st.column_config.TextColumn("ì¸µìˆ˜"),  # ì§€ìƒ/ì§€í•˜ í‘œê¸°ê°€ ë“¤ì–´ê°ˆ ìˆ˜ ìˆì–´ TextColumn
    },
    key=f"project_table_{selected_gu}",
)

# âœ… ë‹¨ì¼ ì„ íƒ ê°•ì œ ë¡œì§
prev = st.session_state.selected_row
sel_list = [int(x) for x in edited.loc[edited["ì„ íƒ"] == True, "orig_index"].tolist()]

if len(sel_list) == 0:
    # ì²´í¬ë¥¼ ëª¨ë‘ í•´ì œí•œ ê²½ìš°: ì´ì „ ì„ íƒì´ ëª©ë¡ì— ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ì²« í–‰ìœ¼ë¡œ
    if prev in curr_ids:
        st.session_state.selected_row = int(prev)
    elif curr_ids:
        st.session_state.selected_row = int(curr_ids[0])
elif len(sel_list) == 1:
    st.session_state.selected_row = int(sel_list[0])
else:
    # ì—¬ëŸ¬ ê°œ ì²´í¬ëœ ê²½ìš° â†’ ìƒˆë¡œ ì²´í¬ëœ(ì´ì „ ì„ íƒì´ ì•„ë‹Œ) ì²« í›„ë³´ë¡œ ê°•ì œ ì „í™˜
    if prev in sel_list:
        new_choice = next((x for x in sel_list if x != prev), sel_list[0])
    else:
        new_choice = sel_list[0]
    st.session_state.selected_row = int(new_choice)
    # ë‹¤ìŒ ë Œë”ì—ì„œ í•œ ê°œë§Œ ì²´í¬ëœ ìƒíƒœë¡œ ë³´ì´ë„ë¡ ì¦‰ì‹œ ì¬ë Œë”
    st.rerun()

# ìµœì¢… ì„ íƒê°’ í™•ì •
if st.session_state.selected_row is None:
    st.info("ì„ íƒëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
selected_row = st.session_state.selected_row


# âœ… ì§€ë„ ë°ì´í„°/ë ˆì´ì–´ ë§Œë“¤ê¸° (selected_row í™•ì • ì´í›„)
filtered_indices = edited["orig_index"].tolist()
map_data = df_map.loc[filtered_indices].reset_index(drop=True)

sel_lat = float(df_map.loc[selected_row, "lat"])
sel_lon = float(df_map.loc[selected_row, "lon"])
view_state = pdk.ViewState(latitude=sel_lat, longitude=sel_lon, zoom=12.5)

layer_points = pdk.Layer(
    "ScatterplotLayer",
    data=map_data,
    get_position='[lon, lat]',
    get_radius=60,
    pickable=True,
    get_fill_color=[255, 140, 0, 160],
    get_line_color=[255, 255, 255],
    line_width_min_pixels=0.5,
)

highlight_row = df_map.loc[[selected_row]].assign(_selected=True)
layer_highlight = pdk.Layer(
    "ScatterplotLayer",
    data=highlight_row,
    get_position='[lon, lat]',
    get_radius=150,
    pickable=False,
    get_fill_color=[0, 200, 255, 220],
    get_line_color=[0, 0, 0],
    line_width_min_pixels=1.2,
)

tooltip = {
    "html": "<b>{address_display}</b><br/>ìì¹˜êµ¬: {gu}<br/>ì„¸ëŒ€ìˆ˜: {households}<br/>êµ¬ì—­ë©´ì (mÂ²): {land_area_m2}",
    "style": {"backgroundColor": "#0f172a", "color": "white"},
}

if map_data.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_highlight], initial_view_state=view_state, tooltip=tooltip))
else:
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_points, layer_highlight], initial_view_state=view_state, tooltip=tooltip))


# --- ì§€ë„ ë Œë” (ì™¼ìª½ ì»¬ëŸ¼ì—ì„œ ì‹¤í–‰) ---
with col12_left:
    if map_data.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
        map_slot.pydeck_chart(
            pdk.Deck(
                layers=[layer_highlight],

                initial_view_state=view_state,
                tooltip=tooltip,
            )
        )
    else:
        map_slot.pydeck_chart(
            pdk.Deck(
                layers=[layer_points, layer_highlight],
                initial_view_state=view_state,
                tooltip=tooltip,
            )
        )

with col12_right:
    st.markdown("### ğŸ§¾ 1ì‚¬ë¶„ë©´ Â· ì‹ ì„¤ì¡°ê±´ ì…ë ¥")
    current = df_map.loc[selected_row]
    with st.container(border=True):
        st.markdown("**ê¸°ì¡´ ë‹¨ì§€ ì •ë³´**")
        st.markdown(
            f"- ì£¼ì†Œ: **{current['address_display']}**\n\n"
            f"- ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…: **{current['org_name']}**\n\n"
            f"- ìì¹˜êµ¬: **{current['gu']}**\n\n"
            f"- ê³„íš ì„¸ëŒ€ìˆ˜: **{int(current['households']) if pd.notna(current['households']) else 'ë¯¸ìƒ'} ì„¸ëŒ€**\n\n"
            f"- ì •ë¹„êµ¬ì—­ë©´ì : **{int(current['land_area_m2']):,} mÂ²**"
        )

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
    desired_py = st.number_input("ì›í•˜ëŠ” ì „ìš© í‰í˜•(í‰)", min_value=15, max_value=60, value=34, step=1)


    # --- ê¸°ì¡´ ì½”ë“œ êµì²´ ---
    # desired_households = st.number_input("ì›í•˜ëŠ” ì„¸ëŒ€ìˆ˜(ì‹ ê·œ)", min_value=100, max_value=3000,
    #                                      value=int(current["households"]) + 200 if pd.notna(current["households"]) else 500, step=50)

    def _clamp(v, lo, hi):
        return max(lo, min(hi, v))


    min_val, max_val = 100, 3000
    base_households = int(current["households"]) if pd.notna(current["households"]) else 500
    default_desired = base_households + 200

    desired_households = st.number_input(
        "ì›í•˜ëŠ” ì„¸ëŒ€ìˆ˜(ì‹ ê·œ)",
        min_value=min_val,
        max_value=max_val,
        value=_clamp(default_desired, min_val, max_val),
        step=50,
    )

    expected_pop_increase_ratio = st.slider("ì˜ˆìƒ ì¸êµ¬ì¦ê°€ìœ¨(%)", 0, 100, 15, 5)
    new_bus_count = st.slider("ì‹ ì„¤ ë²„ìŠ¤ ëŒ€ìˆ˜", 0, 20, 2, 1)
    bus_capacity = st.number_input("ë²„ìŠ¤ 1ëŒ€ ìˆ˜ìš© ì¸ì›(ëª…)", min_value=30, max_value=120, value=70, step=5)



        # ê·¸ë˜í”„ ë Œë” ìƒëµ
    # else: ì´ë¯¸ CSVê°€ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©

# 3â€“4ì‚¬ë¶„ë©´ ë ˆì´ì•„ì›ƒ ì»¬ëŸ¼
col3, col4 = st.columns([1.6, 1.4], gap="large")


# === 3ì‚¬ë¶„ë©´: í˜¼ì¡ë„ ê·¸ë˜í”„ ===

# 3ì‚¬ë¶„ë©´ ì„¹ì…˜ ì‹œì‘ ì „ì— CSV ë³´ì¥
with st.spinner("êµí†µ ê¸°ì¤€ë…„ë„ ë°ì´í„° ì¤€ë¹„ ì¤‘..."):
    if TRAFFIC_XLSX_PATH.exists():
        ensure_speed_csv(TRAFFIC_XLSX_PATH, TRAFFIC_CSV_PATH)  # âœ… ì´ë¦„ ìˆ˜ì •
    elif not TRAFFIC_CSV_PATH.exists():
        st.warning(f"ê¸°ì¤€ CSVê°€ ì—†ìŠµë‹ˆë‹¤: {TRAFFIC_CSV_PATH.name}\n"
                   f"â†’ data í´ë”ì— {TRAFFIC_XLSX_PATH.name} ë¥¼ ë„£ìœ¼ë©´ ìë™ ë³€í™˜ë©ë‹ˆë‹¤.")



# ===
sel_lat = float(current.get("lat", 37.5667))
sel_lon = float(current.get("lon", 126.9784))

with col3:
    st.markdown("### ğŸš¦ 3ì‚¬ë¶„ë©´ Â· ì£¼ë³€ ë„ë¡œ í˜¼ì¡ë„ (ê¸°ì¤€ë…„ë„)")


    radius = st.slider("ë°˜ê²½(m)", 500, 3000, 1000, step=250, key="radius_m")
    max_links = st.slider("í‘œì‹œ ë§í¬ ìˆ˜", 5, 20, 10, step=1, key="max_links")

    if TRAFFIC_CSV_PATH.exists() and SHP_PATH.exists():
        if _HAS_PLOT_SPEED:
            chart_or_fig, df_plot = plot_speed(
                csv_path=TRAFFIC_CSV_PATH,
                shp_path=SHP_PATH,
                center_lon=sel_lon,
                center_lat=sel_lat,
                radius_m=radius,
                max_links=max_links,
                renderer="altair",
                chart_height=700,
            )

            # Altair Chartì´ë©´ st.altair_chart()ë¡œ í‘œì‹œ
            if isinstance(chart_or_fig, alt.Chart):
                # Streamlit í…Œë§ˆê°€ Altair configë¥¼ ë®ì–´ì“°ì§€ ì•Šê²Œ
                st.altair_chart(chart_or_fig, use_container_width=True, theme=None)
            else:
                st.pyplot(chart_or_fig, use_container_width=True)

        else:
            # utilsì— plot_speedê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨ ì‹œ, ê¸°ì¡´ í•¨ìˆ˜ë¡œ ì•ˆì „í•˜ê²Œ í‘œì‹œ
            fig, df_plot = plot_nearby_speed_from_csv(
                csv_path=TRAFFIC_CSV_PATH,
                shp_path=SHP_PATH,
                center_lon=sel_lon,
                center_lat=sel_lat,
                radius_m=radius,
                max_links=max_links,
            )
            st.pyplot(fig, use_container_width=True)

        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(
                df_plot.sort_values(["link_id", "hour"]).head(300),
                use_container_width=True
            )
    else:
        st.info("êµí†µ CSV ë˜ëŠ” SHPê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

# === í˜¼ì¡ë„ / í˜¼ì¡ë¹ˆë„ê°•ë„ í† ê¸€ ê·¸ë˜í”„ ===
if df_plot is not None and not df_plot.empty:
    st.markdown("### ğŸ“ˆ í˜¼ì¡ì§€í‘œ ë¹„êµ (í˜¼ì¡ë„ vs í˜¼ì¡ë¹ˆë„ê°•ë„)")

    # --- í˜¼ì¡ë„ ê³„ì‚° ---
    def compute_congestion_from_speed(df_plot):
        d = df_plot.copy()
        # ğŸ”¹ ì†ë„ ë°ì´í„°ë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜
        d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")

        # ğŸ”¹ ììœ ì£¼í–‰ì†ë„ ê³„ì‚° í›„ í˜¼ì¡ë„ ê³„ì‚°
        d["free_flow"] = d.groupby("link_id")["í‰ê· ì†ë„(km/h)"].transform("max").clip(lower=1)
        d["í˜¼ì¡ë„(%)"] = ((1 - (d["í‰ê· ì†ë„(km/h)"] / d["free_flow"]).clip(0, 1)) * 100).clip(0, 100)
        d["ì§€í‘œëª…"] = "í˜¼ì¡ë„"
        return d[["link_id", "hour", "í˜¼ì¡ë„(%)", "ì§€í‘œëª…"]]


    # --- í˜¼ì¡ë¹ˆë„ê°•ë„ ê³„ì‚° ---
    def compute_congestion_freq_intensity(df_plot, boundary_speed=30):
        d = df_plot.copy()
        d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")
        d["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = (d["í‰ê· ì†ë„(km/h)"] <= boundary_speed).astype(int) * 100
        d = (
            d.groupby(["link_id", "hour"], as_index=False)["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"]
            .mean()
        )
        d["ì§€í‘œëª…"] = "í˜¼ì¡ë¹ˆë„ê°•ë„"
        return d


    def compute_cfi_weighted_robust(
            speed_df: pd.DataFrame,
            vol_df: pd.DataFrame,
            boundary_mode: str = "percentile",  # "fixed" or "percentile"
            boundary_value: float = 30.0,  # fixed: km/h, percentile: 10~90
            min_samples: int = 1  # ì‹œê°„ëŒ€ë³„ ìµœì†Œ í‘œë³¸ ì°¨ëŸ‰ìˆ˜
    ):
        """
        - hour ì •ë ¬ ìë™ë³´ì • (0~23 ê°•ì œ)
        - í˜¼ì¡ê²½ê³„ì†ë„ ë™ì  ì‚°ì • ì§€ì›:
            * boundary_mode="fixed": boundary_value(km/h) ê·¸ëŒ€ë¡œ ì‚¬ìš©
            * boundary_mode="percentile": speed ë¶„í¬ì˜ p-ë¶„ìœ„ìˆ˜(km/h) ì‚¬ìš©
        - ì°¨ëŸ‰ í‘œë³¸ì´ ë„ˆë¬´ ì ì€ ì‹œê°„ëŒ€ëŠ” ì œì™¸(ë˜ëŠ” 0 ì²˜ë¦¬)
        """
        d = speed_df.copy()
        d["link_id"] = d["link_id"].astype(str)
        d["hour"] = pd.to_numeric(d["hour"], errors="coerce").astype("Int64")
        d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")

        v = vol_df.copy()
        v["link_id"] = v["link_id"].astype(str)
        v["hour"] = pd.to_numeric(v["hour"], errors="coerce").astype("Int64") % 24
        v["ì°¨ëŸ‰ëŒ€ìˆ˜"] = pd.to_numeric(v["ì°¨ëŸ‰ëŒ€ìˆ˜"], errors="coerce").fillna(0)

        # ë³‘í•©
        m = d.merge(v, on=["link_id", "hour"], how="inner").dropna(subset=["í‰ê· ì†ë„(km/h)"])

        # boundary ê²°ì •
        if boundary_mode == "percentile":
            import numpy as np
            p = float(boundary_value)
            p = max(5.0, min(95.0, p))
            boundary = np.nanpercentile(m["í‰ê· ì†ë„(km/h)"], p)
        else:
            boundary = float(boundary_value)

        m["í˜¼ì¡ì°¨ëŸ‰ìˆ˜"] = (m["í‰ê· ì†ë„(km/h)"] <= boundary).astype(int) * m["ì°¨ëŸ‰ëŒ€ìˆ˜"]

        g = (m.groupby(["link_id", "hour"], as_index=False)
             .agg(ì „ì²´ì°¨ëŸ‰ìˆ˜=("ì°¨ëŸ‰ëŒ€ìˆ˜", "sum"),
                  í˜¼ì¡ì°¨ëŸ‰ìˆ˜=("í˜¼ì¡ì°¨ëŸ‰ìˆ˜", "sum")))

        g.loc[g["ì „ì²´ì°¨ëŸ‰ìˆ˜"] < max(1, min_samples), ["í˜¼ì¡ì°¨ëŸ‰ìˆ˜", "ì „ì²´ì°¨ëŸ‰ìˆ˜"]] = np.nan
        g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = (g["í˜¼ì¡ì°¨ëŸ‰ìˆ˜"] / g["ì „ì²´ì°¨ëŸ‰ìˆ˜"]) * 100
        g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"] = g["í˜¼ì¡ë¹ˆë„ê°•ë„(%)"].fillna(0).clip(0, 100)

        g.attrs = {"boundary": boundary, "mode": boundary_mode}
        return g


    # --- ì‚¬ìš©ì í† ê¸€ ---
    metric_choice = st.radio(
        "í‘œì‹œí•  í˜¼ì¡ì§€í‘œ ì„ íƒ",
        ["í˜¼ì¡ë„", "í˜¼ì¡ë¹ˆë„ê°•ë„"],
        horizontal=True,
        index=0,
        key="metric_toggle"
    )

    # ------------------------------
    # í˜¼ì¡ë„ / í˜¼ì¡ë¹ˆë„ê°•ë„ ê³„ì‚°
    # ------------------------------
    if metric_choice == "í˜¼ì¡ë„":
        df_metric = compute_congestion_from_speed(df_plot).rename(columns={"í˜¼ì¡ë„(%)": "value"})
        y_title = "í˜¼ì¡ë„ (0=ììœ ì£¼í–‰, 100=ë§¤ìš°í˜¼ì¡)"
    else:
        # êµí†µëŸ‰ íŒŒì¼ì´ ìˆìœ¼ë©´ 'êµí†µëŸ‰ ê°€ì¤‘ Soft CFI', ì—†ìœ¼ë©´ ë‹¨ìˆœ CFI
        vol_path = DATA_DIR / "TrafficVolume_Seoul_2023.csv"
        if vol_path.exists():
            vol_norm = load_volume_csv(vol_path)

            # ê²½ê³„ì†ë„/ë°´ë“œ UI
            bcol1, bcol2, bcol3 = st.columns([1, 1, 1])
            with bcol1:
                boundary_mode = st.radio("ê²½ê³„ë°©ì‹", ["percentile", "fixed"], horizontal=True, index=0, key="bd_mode")
            with bcol2:
                if boundary_mode == "percentile":
                    boundary_value = float(st.slider("ì†ë„ë¶„í¬ ë¶„ìœ„ìˆ˜(%)", 10, 90, 40, 5, key="bd_pct"))
                else:
                    boundary_value = float(st.number_input("ê³ ì • ê²½ê³„ì†ë„(km/h)", 10.0, 100.0, 30.0, 1.0, key="bd_fix"))
            with bcol3:
                band_kmh = float(st.slider("ì™„í™” ë°´ë“œí­ (km/h)", 5, 20, 10, 1, key="bd_band"))

            # êµí†µëŸ‰ ê°€ì¤‘ Soft CFI
            df_cfi = compute_cfi_soft(
                df_plot, vol_norm,
                boundary_mode=boundary_mode,
                boundary_value=boundary_value,
                tau_kmh=band_kmh
            )

            used_boundary = getattr(df_cfi, "attrs", {}).get("boundary", None)
            if used_boundary is not None:
                st.caption(f"ì‚¬ìš©ëœ ê²½ê³„ì†ë„ â‰ˆ {used_boundary:.1f} km/h (ë°´ë“œí­ {band_kmh:.1f} km/h)")

            df_metric = df_cfi.rename(columns={"í˜¼ì¡ë¹ˆë„ê°•ë„(%)": "value"})
            y_title = "í˜¼ì¡ë¹ˆë„ê°•ë„ (êµí†µëŸ‰ ê°€ì¤‘ Â· Soft)"
        else:
            # ë³¼ë¥¨ íŒŒì¼ ì—†ì„ ë•Œì˜ ë‹¨ìˆœ CFI
            df_metric = compute_congestion_freq_intensity(df_plot).rename(columns={"í˜¼ì¡ë¹ˆë„ê°•ë„(%)": "value"})
            y_title = "í˜¼ì¡ë¹ˆë„ê°•ë„ (í˜¼ì¡êµ¬ê°„ ì°¨ëŸ‰ë¹„ìœ¨)"

    # ------------------------------
    # âœ… ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    # ------------------------------
    # í‰ê· ì†ë„ ê·¸ë˜í”„ì™€ ë¹„ìŠ·í•œ ë†’ì´
    CHART_H = 400  # average speedì—ì„œ chart_height=700 ì´ë¼ë©´ ë™ì¼ ì ìš©
    HALF_W = 1100  # ê°€ë¡œ ì ˆë°˜ ëŠë‚Œì˜ ê³ ì •í­(ì›í•˜ë©´ 500~700ì—ì„œ ì¡°ì •)

    chart = (
        alt.Chart(df_metric)
        .mark_line(point=True)
        .encode(
            x=alt.X("hour:Q", title="ì‹œê°„ëŒ€ (ì‹œ)"),
            y=alt.Y("value:Q", title=y_title, scale=alt.Scale(domain=[0, 100])),
            color=alt.Color(
                "link_id:N",
                title="ë§í¬ ID",
                legend=alt.Legend(
                    orient="bottom",  # âœ… ë²”ì£¼ë¥¼ ì•„ë˜ìª½ì— ë°°ì¹˜
                    direction="horizontal",  # ê°€ë¡œë¡œ ë‚˜ì—´
                    columns=4  # í•œ ì¤„ì— 4ê°œì”© (ì›í•˜ë©´ 3~6ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥)
                ),
            ),
            tooltip=[
                alt.Tooltip("link_id:N", title="ë§í¬"),
                alt.Tooltip("hour:Q", title="ì‹œ"),
                alt.Tooltip("value:Q", title=y_title, format=".1f"),
            ],
        )
        .properties(
            title=f"{metric_choice} ë³€í™” ì¶”ì´",
            width=HALF_W,  # â¬…ï¸ ê°€ë¡œí­ ê³ ì •
            height=CHART_H  # â¬…ï¸ ì„¸ë¡œë†’ì´ ê³ ì •(í‰ê· ì†ë„ì™€ ë§ì¶¤)
        )
        .configure_view(strokeWidth=0)
    )

    # width/heightë¥¼ ì ìš©í•˜ë ¤ë©´ use_container_width=False ë¡œ!
    st.altair_chart(chart, use_container_width=False, theme=None)

    # ------------------------------
    # âœ… ê·¸ë˜í”„ ì•„ë˜ ìˆ˜ì‹/ì„¤ëª…
    # ------------------------------
    if metric_choice == "í˜¼ì¡ë„":
        st.markdown("### ğŸ§® í˜¼ì¡ë„(%) ì •ì˜")
        st.markdown("- ë§í¬ $(l)$, ì‹œê°„ëŒ€ $(h)$ì—ì„œì˜ í‰ê· ì†ë„ë¥¼ $v_{l,h}$ ë¼ í•  ë•Œ,")
        st.latex(r"v_{\mathrm{ff},l}=\max v_{l,h}")
        st.latex(r"\mathrm{í˜¼ì¡ë„}_{l,h}(\%)=\Big(1-\min\big(1,\frac{v_{l,h}}{v_{\mathrm{ff},l}}\big)\Big)\times 100")
        st.markdown("- ê°’ì˜ ì˜ë¯¸: **0% = ììœ ì£¼í–‰**, **100% = ë§¤ìš° í˜¼ì¡**")
    else:
        st.markdown("### ğŸ§® í˜¼ì¡ë¹ˆë„ê°•ë„(%) ì •ì˜ (êµí†µëŸ‰ ê°€ì¤‘ Â· Soft)")
        st.markdown("- ê²½ê³„ì†ë„ $v_b$ ë¶€ê·¼ì—ì„œ ë¶€ë“œëŸ½ê²Œ ì „í™˜ë˜ëŠ” ì‹œê·¸ëª¨ì´ë“œ í™•ë¥ ë¡œ í˜¼ì¡ ì—¬ë¶€ë¥¼ ê·¼ì‚¬í•©ë‹ˆë‹¤.")
        st.latex(r"p_{\mathrm{cong}}(v)=\frac{1}{1+\exp\!\left(\frac{v-v_b}{\tau}\right)}")
        st.markdown("- ë§í¬Â·ì‹œê°„ëŒ€ë³„ í˜¼ì¡ë¹ˆë„ê°•ë„ëŠ” **êµí†µëŸ‰ ê°€ì¤‘ í‰ê· **ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        st.latex(r"""\mathrm{CFI}_{l,h}(\%)=100\times
        \frac{\sum_i w_{l,h,i}\,p_{\mathrm{cong}}(v_{l,h,i})}{\sum_i w_{l,h,i}}""")
        st.markdown("- ì—¬ê¸°ì„œ $w$ëŠ” ì°¨ëŸ‰ëŒ€ìˆ˜, $\\tau$ëŠ” ì „í™˜ì˜ ë¶€ë“œëŸ¬ì›€ì„ ì œì–´í•˜ëŠ” ë°´ë“œí­(km/h)ì…ë‹ˆë‹¤.")



# === (ê°„ë‹¨ ì˜ˆì¸¡) í˜¼ì¡ë„ ì§€ìˆ˜ ì‚°ì¶œ: 4ì‚¬ë¶„ë©´ KPIìš© ===
baseline_congestion = float(np.random.uniform(45, 65))
people_per_household = 2.3

delta_households = max(
    0,
    (desired_households - int(current["households"])) if pd.notna(current["households"]) else desired_households
)
added_population = delta_households * people_per_household * (1 + expected_pop_increase_ratio / 100)

alpha, beta = 0.004, 0.0006
congestion_delta = alpha * added_population - beta * (new_bus_count * bus_capacity)
predicted_congestion = max(0.0, min(100.0, baseline_congestion + congestion_delta))




# -------------------------------------------------------------
# ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼
# -------------------------------------------------------------
with col4:
    st.markdown("### ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼ & ë¦¬í¬íŠ¸")

    price_per_py = st.number_input("í‰ë‹¹ ë¶„ì–‘ê°€/ë§¤ë§¤ê°€(ë§Œì›)", 1000, 100000, 4800, 100)
    cost_per_py = st.number_input("í‰ë‹¹ ì´ë¹„ìš©(ë§Œì›)", 500, 80000, 3100, 100)

    unit_py = desired_py
    margin_per_unit_million = (price_per_py - cost_per_py) * unit_py
    expected_margin_billion = (margin_per_unit_million * desired_households) / 10000

    kcol1, kcol2, kcol3 = st.columns(3)
    with kcol1:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì˜ˆìƒ ìˆ˜ìµ(ì´)</div><div class='kpi-value'>{expected_margin_billion:.1f} ì‹­ì–µ</div></div>", unsafe_allow_html=True)
    with kcol2:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>í˜¼ì¡ë„ ì§€ìˆ˜(ì˜ˆì¸¡)</div><div class='kpi-value'>{predicted_congestion:.1f}</div></div>", unsafe_allow_html=True)
    with kcol3:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì‹ ê·œ ì„¸ëŒ€ìˆ˜</div><div class='kpi-value'>{desired_households:,} ì„¸ëŒ€</div></div>", unsafe_allow_html=True)
