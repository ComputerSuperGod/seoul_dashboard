# -------------------------------------------------------------
# ğŸ— AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ (ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper) â€” OPTIMIZED
# -------------------------------------------------------------
# ì£¼ìš” ê°œì„ ì 
# - ì¤‘ë³µ import/ë³€ìˆ˜ ì œê±°, ìƒìˆ˜ ì¼ì›í™”
# - ëŒ€ìš©ëŸ‰ ë¦¬ì†ŒìŠ¤(Shapefile/êµí†µCSV) ìºì‹±(@st.cache_resource / @st.cache_data)
# - GeoJSON ì„¸ì…˜ ì €ì¥ ìµœì†Œí™”: ì„¸ì…˜ì—ëŠ” "í‚¤"ë§Œ ì €ì¥í•˜ê³ , ì‹¤ë°ì´í„°ëŠ” ìºì‹œì—ì„œ ì°¸ì¡°
# - dtype ìµœì í™”(category/numeric ë‹¤ìš´ìºìŠ¤íŠ¸)ë¡œ ë©”ëª¨ë¦¬ ì ˆê°
# - ê³µí†µ ê³„ì‚°(í˜¼ì¡ë„ ë³€í™˜/ì¼í‰ê· /ì‹œê·¸ëª¨ì´ë“œCFI ë“±) í•¨ìˆ˜í™” + ì¬ì‚¬ìš©
# - ë°©ì–´ì  ì½”ë”©(ê²°ì¸¡/ë¶€ì¬ íŒŒì¼ ì²˜ë¦¬), ë¶ˆí•„ìš”í•œ ë°ì´í„°í”„ë ˆì„ ë³µì œ ì œê±°
# - ë ˆì´ì•„ì›ƒ/Altair ë Œë” ë¶„ë¦¬ë¡œ ë¶ˆí•„ìš”í•œ ì¬ê³„ì‚° ìµœì†Œí™”
# -------------------------------------------------------------

import sys
from pathlib import Path
import json
import numpy as np
import pandas as pd
import geopandas as gpd
import pydeck as pdk
import altair as alt
import streamlit as st
import numpy_financial as npf  # (í–¥í›„ ì¬ë¬´ëª¨ë¸ í™•ì¥ ëŒ€ë¹„)
from datetime import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ë¡œ/ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).resolve().parent.parent  # .../seoul_dashboard_3
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

DATA_DIR = BASE_DIR / "data"
BASE_YEAR = 2023  # ê¸°ì¤€ë…„ë„

# íŒŒì¼ ê²½ë¡œ
PROJECTS_CSV_PATH = DATA_DIR / "seoul_redev_projects.csv"
TRAFFIC_XLSX_PATH = DATA_DIR / "AverageSpeed(LINK).xlsx"
TRAFFIC_CSV_PATH  = DATA_DIR / f"AverageSpeed(LINK)_{BASE_YEAR}.csv"  # âœ… ëˆ„ë½ ë³´ì™„
TRAFFIC_VOL_CSV_PATH = DATA_DIR / f"TrafficVolume_Seoul_{BASE_YEAR}.csv"
SHP_PATH = DATA_DIR / "seoul_link_lev5.5_2023.shp"
LINK_ID_COL = "k_link_id"

# ì™¸ë¶€ ìœ í‹¸
from components.sidebar_presets import render_sidebar_presets
from components.sidebar_4quadrant_guide import render_sidebar_4quadrant_guide
from utils.traffic_preproc import ensure_speed_csv

# plot_speed ìˆìœ¼ë©´ í™œìš©, ì—†ìœ¼ë©´ fallback
try:
    from utils.traffic_plot import plot_speed
    _HAS_PLOT_SPEED = True
except Exception:
    from utils.traffic_plot import plot_nearby_speed_from_csv as plot_speed_fallback
    _HAS_PLOT_SPEED = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit ì„¤ì • & ì „ì—­ ìŠ¤íƒ€ì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ | ì¬ê±´ì¶• Helper", layout="wide")

st.markdown("""
<style>
.katex-display { text-align: left !important; margin-left: 0 !important; }
.block-container { text-align: left !important; }
div[data-testid="stMarkdownContainer"] .katex-display { text-align: left !important; margin-left: 0 !important; margin-right: auto !important; }
div[data-testid="stMarkdownContainer"] .katex-display > .katex { display: inline-block !important; }
div[data-testid="stMarkdownContainer"] p { text-align: left !important; margin-left: 0 !important; }
.small-muted { color: #7a7a7a; font-size: 0.9rem; }
.kpi-card { padding: 16px; border-radius: 16px; background: #111827; border: 1px solid #1f2937; }
.kpi-title { font-size: 0.9rem; color: #9ca3af; margin-bottom: 8px; }
.kpi-value { font-size: 1.4rem; font-weight: 700; color: #e5e7eb; }
.section-title { font-size: 1.1rem; font-weight: 700; margin-bottom: 8px; }
hr.soft { border: none; height: 1px; background: #1f2937; margin: 16px 0; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ì…˜ ì´ˆê¸°í™” (í•„ìš” í‚¤ë§Œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for k, v in {
    "matched_geo_key_daily": None,     # ìºì‹œëœ GeoJSONì˜ í‚¤ (ì‹¤ë°ì´í„°ëŠ” ìºì‹œì— ì¡´ì¬)
    "matched_geo_key_hourly": None,    # (ë¯¸ì‚¬ìš©ì‹œ None ìœ ì§€)
    "color_mode_daily_val": "ì ˆëŒ€(30/70)",
    "selected_row": None,
    "selected_gu_prev": None,
    "eta_by_gu": {},
}.items():
    st.session_state.setdefault(k, v)

# ìºì‹œ ë¹„ìš°ê¸°
with st.sidebar:
    if st.button("ìºì‹œ ë¹„ìš°ê¸°"):
        st.cache_data.clear()
        st.cache_resource.clear()
        st.session_state["matched_geo_key_daily"] = None
        st.session_state["matched_geo_key_hourly"] = None
        st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë³´ì¡° ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def smart_read_csv(path, encodings=("utf-8-sig", "cp949", "euc-kr", "utf-8", "latin1")) -> pd.DataFrame:
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError as e:
            last_err = e
    try:
        return pd.read_csv(path, encoding="utf-8", errors="replace")
    except Exception:
        raise last_err or Exception(f"Failed to read {path}")

def _downcast_numeric(df: pd.DataFrame, exclude: set[str] = frozenset()) -> pd.DataFrame:
    # ìˆ˜ì¹˜í˜• ë‹¤ìš´ìºìŠ¤íŠ¸ë¡œ ë©”ëª¨ë¦¬ ì ˆê°
    for c in df.columns:
        if c in exclude:
            continue
        if pd.api.types.is_integer_dtype(df[c]):
            df[c] = pd.to_numeric(df[c], downcast="integer")
        elif pd.api.types.is_float_dtype(df[c]):
            df[c] = pd.to_numeric(df[c], downcast="float")
    return df

def _categorify(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = df[c].astype("category")
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë”© & ì •ê·œí™” (ìºì‹±)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def load_raw_projects() -> pd.DataFrame:
    df = smart_read_csv(PROJECTS_CSV_PATH)
    return df

def _pct_to_num(s):
    s = pd.Series(s).astype(str).str.replace("%", "", regex=False).str.replace(",", "", regex=False)
    return pd.to_numeric(s, errors="coerce")

def _floors_to_num(s):
    return pd.to_numeric(pd.Series(s).astype(str).str.extract(r"(-?\d+)", expand=False), errors="coerce")

@st.cache_data(show_spinner=False)
def normalize_projects(df_raw: pd.DataFrame) -> pd.DataFrame:
    c = df_raw.columns
    get = lambda name: df_raw[name] if name in c else pd.Series([None]*len(df_raw))

    df = pd.DataFrame({
        "apt_id": get("ì‚¬ì—…ë²ˆí˜¸"),
        "name": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))],
        "org_name": get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "biz_type": get("ì‚¬ì—…êµ¬ë¶„"),
        "op_type": get("ìš´ì˜êµ¬ë¶„"),
        "gu": get("ìì¹˜êµ¬"),
        "address": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), get("ëŒ€í‘œì§€ë²ˆ"))],
        "households": pd.to_numeric(get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜"), errors="coerce"),
        "land_area_m2": pd.to_numeric(get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"), errors="coerce"),
        "far": _pct_to_num(get("ìš©ì ë¥ ")),
        "floors": _floors_to_num(get("ì¸µìˆ˜")),
        "status": get("ì§„í–‰ë‹¨ê³„"),
        "floors_up": _floors_to_num(get("ì§€ìƒì¸µìˆ˜")),
        "floors_down": _floors_to_num(get("ì§€í•˜ì¸µìˆ˜")),
    })
    def _fmt_floor(u, d):
        parts = []
        if pd.notna(u): parts.append(f"ì§€ìƒ {int(u)}")
        if pd.notna(d): parts.append(f"ì§€í•˜ {int(d)}")
        return " / ".join(parts)

    df["floors_display"] = [_fmt_floor(u, d) for u, d in zip(df["floors_up"], df["floors_down"])]
    df["floors_show"] = df["floors_display"].fillna("").astype(str).str.strip()
    mask_empty = df["floors_show"] == ""
    df.loc[mask_empty, "floors_show"] = df.loc[mask_empty, "floors"].apply(lambda x: f"{int(x)}ì¸µ" if pd.notna(x) else "")

    # ì •ë¦¬/íƒ€ì… ìµœì í™”
    df["apt_id"] = df["apt_id"].astype(str)
    df["name"]   = df["name"].fillna("ë¬´ëª… ì •ë¹„êµ¬ì—­")
    for col in ["org_name","biz_type","op_type","gu","address","status"]:
        df[col] = df[col].fillna("").astype(str).str.strip()
    df = _downcast_numeric(df)
    df = _categorify(df, ["gu","biz_type","op_type","status"])
    return df

@st.cache_data(show_spinner=False)
def load_coords() -> pd.DataFrame:
    path = DATA_DIR / "ì„œìš¸ì‹œ_ì¬ê°œë°œì¬ê±´ì¶•_clean_kakao.csv"
    df = smart_read_csv(path)
    # ì•ˆì „ ìˆ«ìí™”
    df["lat"] = pd.to_numeric(df.get("lat"), errors="coerce")
    df["lon"] = pd.to_numeric(df.get("lon"), errors="coerce")

    def _coalesce(a,b):
        a = "" if a is None else str(a).strip()
        b = "" if b is None else str(b).strip()
        return a if a else b

    if ("ì •ë¹„êµ¬ì—­ëª…ì¹­" in df.columns) or ("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…" in df.columns):
        name = [_coalesce(n, m) for n, m in zip(df.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), df.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))]
    else:
        name = df.get("name")

    address = [_coalesce(a, b) for a, b in zip(df.get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), df.get("ëŒ€í‘œì§€ë²ˆ"))]

    out = pd.DataFrame({
        "apt_id": df.get("ì‚¬ì—…ë²ˆí˜¸").astype(str) if "ì‚¬ì—…ë²ˆí˜¸" in df.columns else "",
        "name": pd.Series(name, index=df.index),
        "gu": df.get("ìì¹˜êµ¬"),
        "address": pd.Series(address, index=df.index),
        "full_address": df.get("full_address"),
        "lat": df["lat"], "lon": df["lon"],
    })
    for col in ["apt_id","name","gu","address","full_address"]:
        if col in out.columns:
            out[col] = out[col].fillna("").astype(str).str.strip()
    out = _downcast_numeric(out)
    out = _categorify(out, ["gu"])
    return out

@st.cache_data(show_spinner=False)
def projects_by_gu(gu: str) -> pd.DataFrame:
    return normalize_projects(load_raw_projects()).query("gu == @gu").reset_index(drop=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§€ì˜¤ ë°ì´í„° (Shapefile/êµí†µCSV) ë¡œë”© (ë¦¬ì†ŒìŠ¤ ìºì‹œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def load_links_gdf() -> gpd.GeoDataFrame | None:
    if not SHP_PATH.exists():
        return None
    gdf = gpd.read_file(SHP_PATH, columns=[LINK_ID_COL, "geometry"])
    if gdf.crs and gdf.crs.to_epsg() != 4326:
        gdf = gdf.to_crs(epsg=4326)
    gdf["link_id_norm"] = gdf[LINK_ID_COL].astype(str).str.replace(r"\.0$", "", regex=True).str.strip()
    return gdf[[ "link_id_norm", "geometry" ]]

@st.cache_data(show_spinner=False)
def load_speed_csv_from_xlsx_if_needed():
    # ì—‘ì…€ì„ CSVë¡œ ë³€í™˜í•´ë‘ê³  CSV ë¡œë“œ(ì—†ìœ¼ë©´ ê²½ê³ )
    if TRAFFIC_XLSX_PATH.exists():
        ensure_speed_csv(TRAFFIC_XLSX_PATH, TRAFFIC_CSV_PATH)

@st.cache_data(show_spinner=False)
def load_volume_csv(path: Path) -> pd.DataFrame | None:
    if not path.exists():
        return None
    df = pd.read_csv(path)
    df["link_id"] = df["link_id"].astype(str)
    h = pd.to_numeric(pd.Series(df["hour"]).astype(str).str.extract(r"(\d+)", expand=False), errors="coerce").fillna(0).astype(int) % 24
    df["hour"] = h
    df["ì°¨ëŸ‰ëŒ€ìˆ˜"] = pd.to_numeric(df["ì°¨ëŸ‰ëŒ€ìˆ˜"], errors="coerce").fillna(0)
    return _downcast_numeric(df)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§€ë„/í˜¼ì¡ ê³„ì‚° ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def color_by_value(v: float):
    if pd.isna(v): return (200,200,200)
    v = float(v)
    if v < 30: return (0,200,0)
    if v < 70: return (255,200,0)
    return (255,0,0)

def color_by_quantile(v: float, q30: float, q70: float):
    if pd.isna(v): return (200,200,200)
    if v < q30: return (0,200,0)
    if v < q70: return (255,200,0)
    return (255,0,0)

def compute_congestion_from_speed(df_plot: pd.DataFrame) -> pd.DataFrame:
    # ì†ë„â†’í˜¼ì¡% (0=ììœ , 100=ë§¤ìš°í˜¼ì¡)
    d = df_plot.copy()
    d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")
    d["free_flow"] = d.groupby("link_id")["í‰ê· ì†ë„(km/h)"].transform("max").clip(lower=1)
    d["value"] = ((1 - (d["í‰ê· ì†ë„(km/h)"] / d["free_flow"]).clip(0, 1)) * 100).clip(0, 100)
    return d[["link_id","hour","value"]]

@st.cache_data(show_spinner=False)
def build_daily_geojson_key(
    df_daily: pd.DataFrame,
    color_mode: str
) -> str:
    """
    df_daily: columns [link_id, daily_value]
    ìºì‹œì— GeoJSON ê°ì²´ë¥¼ ì €ì¥í•˜ê³ , sessionì—ëŠ” ê·¸ í‚¤ë§Œ ë³´ê´€.
    """
    links_gdf = load_links_gdf()  # ğŸ” ìºì‹œëœ ë¦¬ì†ŒìŠ¤ë¥¼ ë‚´ë¶€ì—ì„œ ì‚¬ìš© (unhashable ì¸ì ì „ë‹¬ X)
    if links_gdf is None or df_daily.empty:
        return ""

    gdf = links_gdf.merge(
        df_daily.assign(
            link_id_norm=df_daily["link_id"].astype(str).str.replace(r"\.0$","",regex=True).str.strip()
        ),
        on="link_id_norm",
        how="inner"
    )
    if gdf.empty:
        return ""

    if color_mode.startswith("ìƒëŒ€"):
        q30 = float(np.nanpercentile(gdf["daily_value"], 30))
        q70 = float(np.nanpercentile(gdf["daily_value"], 70))
        cols = list(zip(*gdf["daily_value"].apply(lambda x: color_by_quantile(x, q30, q70))))
    else:
        cols = list(zip(*gdf["daily_value"].apply(color_by_value)))

    gdf["color_r"], gdf["color_g"], gdf["color_b"] = cols[0], cols[1], cols[2]
    gdf["tooltip_html"] = (
        "<b>ë§í¬:</b> " + gdf["link_id_norm"].astype(str)
        + "<br/><b>ì¼í‰ê·  í˜¼ì¡ë„:</b> " + gdf["daily_value"].round(1).astype(str) + "%"
    )
    geojson_obj = json.loads(gdf.to_json())

    # í‚¤ëŠ” ê°„ë‹¨ í•´ì‹œ(í–‰ìˆ˜+í‰ê· ê°’+ëª¨ë“œ)
    key = f"{len(gdf)}_{round(float(gdf['daily_value'].mean()),2)}_{'rel' if color_mode.startswith('ìƒëŒ€') else 'abs'}"
    _geojson_cache_store(key, geojson_obj)
    return key


# ê°„ë‹¨í•œ ë‚´ë¶€ ìºì‹œ(dict) â€” st.cache_data ë‚´ë¶€ ìƒíƒœ(ì„¸ì…˜ ì™¸ë¶€)ë¡œ ì €ì¥
@st.cache_resource(show_spinner=False)
def _geojson_store() -> dict:
    # ì„¸ì…˜ ë™ì•ˆ ì‚´ì•„ìˆëŠ” ë³€ê²½ ê°€ëŠ¥í•œ ì €ì¥ì†Œ
    return {}

def _geojson_cache_store(key: str, obj: dict) -> bool:
    _geojson_store()[key] = obj
    return True

def _geojson_cache_get(key: str) -> dict | None:
    return _geojson_store().get(key)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°íƒ€ ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DISTRICTS = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬",
    "ë…¸ì›êµ¬","ë„ë´‰êµ¬","ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬",
    "ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬","ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]
GU_CENTER = {
    "ê°•ë‚¨êµ¬": (37.5172, 127.0473), "ê°•ë™êµ¬": (37.5301, 127.1238), "ê°•ë¶êµ¬": (37.6396, 127.0257),
    "ê°•ì„œêµ¬": (37.5509, 126.8495), "ê´€ì•…êµ¬": (37.4784, 126.9516), "ê´‘ì§„êµ¬": (37.5386, 127.0822),
    "êµ¬ë¡œêµ¬": (37.4955, 126.8876), "ê¸ˆì²œêµ¬": (37.4569, 126.8958), "ë…¸ì›êµ¬": (37.6543, 127.0565),
    "ë„ë´‰êµ¬": (37.6688, 127.0471), "ë™ëŒ€ë¬¸êµ¬": (37.5740, 127.0396), "ë™ì‘êµ¬": (37.5124, 126.9393),
    "ë§ˆí¬êµ¬": (37.5638, 126.9084), "ì„œëŒ€ë¬¸êµ¬": (37.5791, 126.9368), "ì„œì´ˆêµ¬": (37.4836, 127.0326),
    "ì„±ë™êµ¬": (37.5633, 127.0369), "ì„±ë¶êµ¬": (37.5894, 127.0167), "ì†¡íŒŒêµ¬": (37.5145, 127.1068),
    "ì–‘ì²œêµ¬": (37.5169, 126.8665), "ì˜ë“±í¬êµ¬": (37.5264, 126.8963), "ìš©ì‚°êµ¬": (37.5311, 126.9811),
    "ì€í‰êµ¬": (37.6176, 126.9227), "ì¢…ë¡œêµ¬": (37.5736, 126.9780), "ì¤‘êµ¬": (37.5636, 126.9976),
    "ì¤‘ë‘êµ¬": (37.6063, 127.0929),
}
SENS_DEFAULTS = {
    "ê°•ë‚¨êµ¬": 0.75, "ì„œì´ˆêµ¬": 0.70, "ì†¡íŒŒêµ¬": 0.65, "ê°•ë™êµ¬": 0.60,
    "ë§ˆí¬êµ¬": 0.55, "ìš©ì‚°êµ¬": 0.65, "ì˜ë“±í¬êµ¬": 0.60, "ë™ì‘êµ¬": 0.55,
    "ê´€ì•…êµ¬": 0.55, "ê´‘ì§„êµ¬": 0.55, "ì„±ë™êµ¬": 0.60, "ê°•ì„œêµ¬": 0.50,
    "ì–‘ì²œêµ¬": 0.55, "êµ¬ë¡œêµ¬": 0.50, "ê¸ˆì²œêµ¬": 0.50, "ë™ëŒ€ë¬¸êµ¬": 0.55,
    "ì¤‘ë‘êµ¬": 0.50, "ì„±ë¶êµ¬": 0.55, "ê°•ë¶êµ¬": 0.50, "ë„ë´‰êµ¬": 0.50,
    "ë…¸ì›êµ¬": 0.55, "ì„œëŒ€ë¬¸êµ¬": 0.55, "ì€í‰êµ¬": 0.50, "ì¢…ë¡œêµ¬": 0.60, "ì¤‘êµ¬": 0.60,
}

# âœ… [ìƒˆë¡œ ì¶”ê°€] ìƒˆë²½ ì™„ê¸‰ í•¨ìˆ˜
def apply_dawn_smoothing(w_hour: np.ndarray, *, min_factor: float = 0.55, turn_hour: float = 7.5, k: float = 0.9) -> np.ndarray:
    """
    w_hour: ê¸¸ì´ 24, 0~23ì‹œ ê°€ì¤‘ì¹˜
    min_factor: ì‹¬ì•¼(0~3ì‹œ) ìµœì†Œ ë¹„ìœ¨
    turn_hour: íšŒë³µ ì¤‘ì‹¬ ì‹œê°(ì˜ˆ: 7.5 = 07:30)
    k: ì‹œê·¸ëª¨ì´ë“œ ê¸°ìš¸ê¸°
    """
    h = np.arange(24, dtype=float)
    dawn_curve = min_factor + (1.0 - min_factor) / (1.0 + np.exp(-k * (h - turn_hour)))
    return w_hour * dawn_curve

# ê¸°ì¡´ì½”ë“œ <- (ê¸°íƒ€ ìƒìˆ˜ ë¸”ë¡ ë ë¶€ë¶„ì— ì¶”ê°€)
ALPHA_HOURLY = 1.5
EPS_HOURLY   = 0.05

# >>> PATCH B: mitigation solver (uniform bus% to make after<=base) ---
BUS_COST_PER_1PCT_BIL_DEFAULT = 2.0   # 1% ì¦í¸ì— ë“œëŠ” ì—°ê°„ ë¹„ìš©(ì–µì›)Â·ì˜ˆì‹œê°’

def compute_min_bus_increase_to_cap(after: np.ndarray, base: np.ndarray) -> float:
    """
    'ì¬ê±´ì¶• í›„' ê³¡ì„ (after)ì„ ì„ í˜• ê°ì‡  ê³„ìˆ˜ (1 - b/150)ë¡œ ë‚®ì¶°
    ëª¨ë“  ì‹œê°„ëŒ€ì—ì„œ base ì´í•˜ê°€ ë˜ë„ë¡ í•˜ëŠ” ìµœì†Œ b(%)ë¥¼ ë°˜í™˜.
    - after_adj(h) = after(h) * (1 - b/150)
    - ì œì•½: after_adj(h) <= base(h) for all h
    í•´ë¥¼ ë‹«íŒí˜•ìœ¼ë¡œ êµ¬í•˜ë©´:
      b >= 150 * max_h max(0, 1 - base(h)/max(after(h), 1e-6))
    """
    a = np.maximum(after.astype(float), 1e-6)
    b = base.astype(float)
    ratio = 1.0 - (b / a)
    need = np.maximum(0.0, ratio).max()
    return float(np.clip(150.0 * need, 0.0, 100.0))  # 0~100%ë¡œ í´ë¦½
# ---------------------------------------------------------------------



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper")

selected_gu = st.sidebar.selectbox("êµ¬ ì„ íƒ", DISTRICTS, index=0)
if st.session_state["selected_gu_prev"] != selected_gu:
    st.session_state["selected_row"] = None
    st.session_state["selected_gu_prev"] = selected_gu

st.sidebar.markdown("<div class='small-muted'>êµ¬ ì„ íƒ ì‹œ, í•´ë‹¹ êµ¬ì˜ ì •ë¹„ì‚¬ì—… ë‹¨ì§€ ëª©ë¡ê³¼ ì§€ë„ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
project_name = st.sidebar.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=f"{selected_gu} ì¬ê±´ì¶• ì‹œë‚˜ë¦¬ì˜¤")

render_sidebar_presets()
render_sidebar_4quadrant_guide()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1â€“2 ì‚¬ë¶„ë©´: ì§€ë„ & ë‹¨ì§€ ì„ íƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
col12_left, col12_right = st.columns([2.2, 1.4], gap="large")
with col12_left:
    st.markdown("### ğŸ—º [1-2ì‚¬ë¶„ë©´] Â· ì§€ë„ & ë‹¨ì§€ì„ íƒ")

    base_df = projects_by_gu(selected_gu)

    # ì¢Œí‘œ ë³‘í•© (name+gu ê¸°ì¤€). ì¢Œí‘œ ì—†ìŒ â†’ êµ¬ ì¤‘ì‹¬ + jitter
    coords = load_coords().query("gu == @selected_gu").copy()
    df_map = base_df.merge(
        coords[["name","gu","lat","lon","full_address"]],
        on=["name","gu"], how="left"
    )
    miss = df_map["lat"].isna() | df_map["lon"].isna()
    if miss.any():
        base_lat, base_lon = GU_CENTER.get(selected_gu, (37.55, 127.0))
        rng = np.random.default_rng(42)
        df_map.loc[miss, "lat"] = base_lat + rng.normal(0, 0.002, int(miss.sum()))
        df_map.loc[miss, "lon"] = base_lon + rng.normal(0, 0.002, int(miss.sum()))
    df_map["has_geo"] = ~miss
    df_map["address_display"] = df_map["full_address"].fillna("").replace("", pd.NA)
    df_map["address_display"] = df_map["address_display"].fillna(df_map["address"]).fillna("")

    # ë©”ëª¨ë¦¬ ì ˆê°
    df_map = _downcast_numeric(df_map)
    df_map = _categorify(df_map, ["gu","biz_type","op_type","status"])

    map_slot = st.empty()
    if df_map.empty:
        st.warning("âš ï¸ í•´ë‹¹ êµ¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

with st.expander("ğŸ” ë°ì´í„° ì†ŒìŠ¤ í™•ì¸(ì„ì‹œ)", expanded=False):
    raw = load_raw_projects()
    cols_raw = ["ìì¹˜êµ¬", "ì •ë¹„êµ¬ì—­ëª…ì¹­", "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…", "ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜", "ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"]
    exist = [c for c in cols_raw if c in raw.columns]
    st.caption(f"ì›ë³¸: {PROJECTS_CSV_PATH.name} Â· í‘œì‹œì—´: {', '.join(exist)}")
    try:
        st.dataframe(raw[exist][raw["ìì¹˜êµ¬"] == selected_gu].head(20), use_container_width=True)
    except Exception:
        st.dataframe(raw[exist].head(20), use_container_width=True)
    st.caption("í˜„ì¬ í‘œì‹œê°’(df_map)")
    st.dataframe(df_map[["gu","address_display","name","households","land_area_m2"]].head(20), use_container_width=True)

st.markdown("**ë‹¨ì§€ ëª©ë¡**")
df_list = df_map[[
    "apt_id","address_display","org_name","biz_type","op_type","status",
    "households","land_area_m2","far","floors_show"
]].copy()

# ìˆ«ìí˜• ì •ë¦¬
for col in ["households","land_area_m2","far"]:
    df_list[col] = pd.to_numeric(df_list[col], errors="coerce")

# í•„í„° UI
fcol1, fcol2, fcol3, fcol4 = st.columns([1.6,1.4,1.6,1.2])
with fcol1:
    kw = st.text_input("ê²€ìƒ‰ì–´(ì£¼ì†Œ/ì¡°í•©ëª…/í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ) ê°œí¬, ëª©ë™, ì¡°í•©")

HH_BUCKETS = {
    "ì „ì²´": (None, None), "~ 300ì„¸ëŒ€": (0, 300), "301â€“500ì„¸ëŒ€": (301, 500),
    "501â€“1,000ì„¸ëŒ€": (501, 1000), "1,001â€“2,000ì„¸ëŒ€": (1001, 2000), "2,001ì„¸ëŒ€ ì´ìƒ": (2001, None),
}
AREA_BUCKETS = {
    "ì „ì²´": (None, None), "~ 30,000 mÂ²": (0, 30000), "30,001â€“50,000 mÂ²": (30001, 50000),
    "50,001â€“100,000 mÂ²": (50001, 100000), "100,001â€“200,000 mÂ²": (100001, 200000), "200,001 mÂ² ì´ìƒ": (200001, None),
}
with fcol2:
    hh_choice = st.selectbox("ì„¸ëŒ€ìˆ˜ ë²”ì£¼", list(HH_BUCKETS.keys()), index=0)
with fcol3:
    la_choice = st.selectbox("ë©´ì  ë²”ì£¼(mÂ²)", list(AREA_BUCKETS.keys()), index=0)
with fcol4:
    hide_zero = st.checkbox("0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°", value=True)

mask = pd.Series(True, index=df_list.index)
if kw.strip():
    _kw = kw.strip().lower()
    mask &= (
        df_list["address_display"].fillna("").str.lower().str.contains(_kw) |
        df_list["org_name"].fillna("").str.lower().str.contains(_kw)
    )
hh_lo, hh_hi = HH_BUCKETS[hh_choice]; la_lo, la_hi = AREA_BUCKETS[la_choice]
if hh_lo is not None: mask &= df_list["households"].fillna(-1) >= hh_lo
if hh_hi is not None: mask &= df_list["households"].fillna(-1) <= hh_hi
if la_lo is not None: mask &= df_list["land_area_m2"].fillna(-1) >= la_lo
if la_hi is not None: mask &= df_list["land_area_m2"].fillna(-1) <= la_hi
if hide_zero:
    mask &= df_list["households"].fillna(0) > 0
    mask &= df_list["land_area_m2"].fillna(0) > 0

filtered = df_list[mask].reset_index().rename(columns={"index":"orig_index"})
scol1, scol2 = st.columns([1.2,1.2])
with scol1:
    sort_key = st.selectbox("ì •ë ¬ ê¸°ì¤€",
        ["ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ","ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ","ë©´ì  ë‚´ë¦¼ì°¨ìˆœ","ë©´ì  ì˜¤ë¦„ì°¨ìˆœ","ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ"], index=0)
with scol2:
    topn = st.selectbox("í‘œì‹œ ê°œìˆ˜", [10,20,50,100,"ì „ì²´"], index=1)
if sort_key == "ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=False, na_position="last")
elif sort_key == "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=True, na_position="last")
elif sort_key == "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=False, na_position="last")
elif sort_key == "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=True, na_position="last")
elif sort_key == "ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("address_display", ascending=True, na_position="last")
if topn != "ì „ì²´":
    filtered = filtered.head(int(topn))

show_df = filtered[[
    "orig_index","address_display","org_name","biz_type","op_type","status",
    "households","land_area_m2","far","floors_show"
]].copy().rename(columns={
    "address_display":"ì£¼ì†Œ","org_name":"ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…","biz_type":"ì‚¬ì—…êµ¬ë¶„",
    "op_type":"ìš´ì˜êµ¬ë¶„","status":"ì§„í–‰ë‹¨ê³„","households":"ê³„íšì„¸ëŒ€ìˆ˜",
    "land_area_m2":"ë©´ì ","far":"ìš©ì ë¥ (%)","floors_show":"ì¸µìˆ˜"
})
show_df.insert(1, "ì„ íƒ", False)

curr_ids = show_df["orig_index"].tolist()
if (st.session_state["selected_row"] is None) or (st.session_state["selected_row"] not in curr_ids):
    st.session_state["selected_row"] = int(curr_ids[0]) if curr_ids else None
show_df.loc[show_df["orig_index"] == st.session_state["selected_row"], "ì„ íƒ"] = True

edited = st.data_editor(
    show_df, use_container_width=True, hide_index=True,
    disabled=["orig_index","ì£¼ì†Œ","ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…","ì‚¬ì—…êµ¬ë¶„","ìš´ì˜êµ¬ë¶„","ì§„í–‰ë‹¨ê³„","ê³„íšì„¸ëŒ€ìˆ˜","ë©´ì ","ìš©ì ë¥ (%)","ì¸µìˆ˜"],
    column_config={
        "orig_index": st.column_config.NumberColumn("ì›ë³¸ì¸ë±ìŠ¤", help="ë‚´ë¶€ ì„ íƒìš©", width="small"),
        "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ì´ í–‰ì„ ì„ íƒ"),
        "ì£¼ì†Œ": st.column_config.TextColumn("ì£¼ì†Œ"),
        "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…": st.column_config.TextColumn("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "ì‚¬ì—…êµ¬ë¶„": st.column_config.TextColumn("ì‚¬ì—…êµ¬ë¶„"),
        "ìš´ì˜êµ¬ë¶„": st.column_config.TextColumn("ìš´ì˜êµ¬ë¶„"),
        "ì§„í–‰ë‹¨ê³„": st.column_config.TextColumn("ì§„í–‰ë‹¨ê³„"),
        "ê³„íšì„¸ëŒ€ìˆ˜": st.column_config.NumberColumn("ê³„íšì„¸ëŒ€ìˆ˜", format="%,d"),
        "ë©´ì ": st.column_config.NumberColumn("ë©´ì (mÂ²)", format="%,d"),
        "ìš©ì ë¥ (%)": st.column_config.NumberColumn("ìš©ì ë¥ (%)", format=",.1f"),
        "ì¸µìˆ˜": st.column_config.TextColumn("ì¸µìˆ˜"),
    },
    key=f"project_table_{selected_gu}",
)

prev = st.session_state["selected_row"]
sel_list = [int(x) for x in edited.loc[edited["ì„ íƒ"] == True, "orig_index"].tolist()]
if len(sel_list) == 0:
    st.session_state["selected_row"] = int(prev) if prev in curr_ids else (int(curr_ids[0]) if curr_ids else None)
elif len(sel_list) == 1:
    st.session_state["selected_row"] = int(sel_list[0])
else:
    st.session_state["selected_row"] = int(sel_list[0] if prev not in sel_list else next((x for x in sel_list if x != prev), sel_list[0]))
    st.rerun()

if st.session_state["selected_row"] is None:
    st.info("ì„ íƒëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
selected_row = st.session_state["selected_row"]

current = df_map.loc[selected_row]
st.session_state["selected_site"] = current["name"]

# ì§€ë„ ë Œë” ì¤€ë¹„
filtered_indices = edited["orig_index"].tolist()
map_data = df_map.loc[filtered_indices, ["lat","lon","address_display","gu","households","land_area_m2"]].copy()

def _point_tooltip(row):
    return (f"<b>{row.get('address_display','')}</b><br/>"
            f"ìì¹˜êµ¬: {row.get('gu','')}<br/>"
            f"ì„¸ëŒ€ìˆ˜: {row.get('households','')}<br/>"
            f"êµ¬ì—­ë©´ì (mÂ²): {row.get('land_area_m2','')}")
map_data["tooltip_html"] = map_data.apply(_point_tooltip, axis=1)

highlight_row = df_map.loc[[selected_row], ["lat","lon","address_display","gu","households","land_area_m2"]].copy()
highlight_row["tooltip_html"] = highlight_row.apply(_point_tooltip, axis=1)

sel_lat, sel_lon = float(current["lat"]), float(current["lon"])
view_state = pdk.ViewState(latitude=sel_lat, longitude=sel_lon, zoom=12.5)

layer_points = pdk.Layer(
    "ScatterplotLayer", data=map_data, get_position='[lon, lat]', get_radius=60,
    pickable=True, get_fill_color=[255,140,0,160], get_line_color=[255,255,255], line_width_min_pixels=0.5,
)
layer_highlight = pdk.Layer(
    "ScatterplotLayer", data=highlight_row, get_position='[lon, lat]', get_radius=150,
    pickable=False, get_fill_color=[0,200,255,220], get_line_color=[0,0,0], line_width_min_pixels=1.2,
)
tooltip = {"html":"{tooltip_html}", "style":{"backgroundColor":"#0f172a", "color":"white"}}

def render_map(initial_view_state):
    layers = []
    key_daily = st.session_state.get("matched_geo_key_daily")
    if key_daily:
        gj = _geojson_cache_get(key_daily)
        if gj:
            layers.append(pdk.Layer(
                "GeoJsonLayer",
                data=gj,
                pickable=True,
                auto_highlight=True,
                get_line_color='[properties.color_r, properties.color_g, properties.color_b, 220]',
                get_line_width=2,  # ì„  êµµê¸° ì§€ì •
                line_width_min_pixels=2,  # ìµœì†Œ í”½ì…€ êµµê¸° (snake_case)
            ))

    layers += [layer_points, layer_highlight]
    map_slot.pydeck_chart(pdk.Deck(layers=layers, initial_view_state=initial_view_state, tooltip=tooltip))

with col12_right:
    st.markdown("### ğŸ§¾ [1ì‚¬ë¶„ë©´] Â· ê¸°ì¡´ ë‹¨ì§€ ì •ë³´")
    with st.container(border=True):
        st.markdown("**ê¸°ì¡´ ë‹¨ì§€ ì •ë³´**")
        st.markdown(
            f"- ì£¼ì†Œ: **{current['address_display']}**\n\n"
            f"- ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…: **{current['org_name']}**\n\n"
            f"- ìì¹˜êµ¬: **{current['gu']}**\n\n"
            f"- ê³„íš ì„¸ëŒ€ìˆ˜: **{int(current['households']) if pd.notna(current['households']) else 'ë¯¸ìƒ'} ì„¸ëŒ€**\n\n"
            f"- ì •ë¹„êµ¬ì—­ë©´ì : **{int(current['land_area_m2']):,} mÂ²**"
        )
    color_controls_slot = st.container()
    legend_slot = st.empty()

with color_controls_slot:
    color_mode_key = f"color_mode_daily__{selected_gu}"
    default_idx = 0 if st.session_state.get("color_mode_daily_val","ì ˆëŒ€(30/70)").startswith("ì ˆëŒ€") else 1
    _ = st.radio("ì§€ë„ ìƒ‰ ê¸°ì¤€", ["ì ˆëŒ€(30/70)","ìƒëŒ€(30%/70%)"], index=default_idx, horizontal=True, key=color_mode_key,
                 help="ì ˆëŒ€: í˜¼ì¡ë„ 30/70 ê³ ì • ê²½ê³„ Â· ìƒëŒ€: ë¶„í¬ì˜ 30/70 ë¶„ìœ„ìˆ˜")
st.session_state["color_mode_daily_val"] = st.session_state.get(color_mode_key, "ì ˆëŒ€(30/70)")
legend_slot.caption("ğŸŸ© <30 Â· ğŸŸ¨ 30~70 Â· ğŸŸ¥ â‰¥70 (ë‹¨ìœ„: %) â€” ì ˆëŒ€ ê¸°ì¤€ / ìƒëŒ€ ì„ íƒ ì‹œ: ë¶„ìœ„ 30/70 ê¸°ì¤€")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3â€“4 ì‚¬ë¶„ë©´ ë ˆì´ì•„ì›ƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
colL, colR = st.columns([1, 1], gap="large")

# 3-1: ì£¼ë³€ ë„ë¡œ í˜¼ì¡ë„ (ê¸°ì¤€ë…„ë„)
with colL:
    st.markdown("### ğŸš¦ [3-1ì‚¬ë¶„ë©´] Â· ì£¼ë³€ ë„ë¡œ í˜¼ì¡ë„ (ê¸°ì¤€ë…„ë„)")

    with st.spinner("êµí†µ ê¸°ì¤€ë…„ë„ ë°ì´í„° ì¤€ë¹„ ì¤‘..."):
        load_speed_csv_from_xlsx_if_needed()
        if not TRAFFIC_CSV_PATH.exists():
            st.warning(
                f"ê¸°ì¤€ CSVê°€ ì—†ìŠµë‹ˆë‹¤: {TRAFFIC_CSV_PATH.name}\n"
                f"â†’ data í´ë”ì— {TRAFFIC_XLSX_PATH.name} ë¥¼ ë„£ìœ¼ë©´ ìë™ ë³€í™˜ë©ë‹ˆë‹¤."
            )

    radius = st.slider("ë°˜ê²½(m)", 500, 3000, 1000, step=250, key="radius_m")
    graph_topn = st.slider("ê·¸ë˜í”„ì— í‘œì‹œí•  ë§í¬ ìˆ˜ (Top-N)", 5, 50, 10, 1, key="graph_topn")

    df_plot_all = None
    if TRAFFIC_CSV_PATH.exists() and SHP_PATH.exists():
        if _HAS_PLOT_SPEED:
            chart_speed, df_speed = plot_speed(
                csv_path=str(TRAFFIC_CSV_PATH),
                shp_path=str(SHP_PATH),
                center_lon=sel_lon, center_lat=sel_lat,
                radius_m=radius, max_links=graph_topn,
                renderer="altair", chart_height=300,
            )
            st.altair_chart(chart_speed, use_container_width=True, theme=None)

            # ì§€ë„/í˜¼ì¡ë„ìš© ì „ì²´ ë§í¬
            _, df_plot_all = plot_speed(
                csv_path=str(TRAFFIC_CSV_PATH),
                shp_path=str(SHP_PATH),
                center_lon=sel_lon, center_lat=sel_lat,
                radius_m=radius, max_links=10000,
                renderer="altair", chart_height=1,
            )
        else:
            _, df_plot_all = plot_speed_fallback(
                csv_path=str(TRAFFIC_CSV_PATH),
                shp_path=str(SHP_PATH),
                center_lon=sel_lon, center_lat=sel_lat,
                radius_m=radius, max_links=10000,
            )
    else:
        st.info("êµí†µ CSV ë˜ëŠ” SHPê°€ ì—†ì–´ ê·¸ë˜í”„/ì§€ë„ ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # í˜¼ì¡ë„ ë° GeoJSON ìºì‹œ í‚¤ ìƒì„±
    if (df_plot_all is not None) and (not df_plot_all.empty):
        df_metric_all = compute_congestion_from_speed(df_plot_all)
        st.session_state["df_plot_all"] = df_plot_all  # 3-2, 3-3ì—ì„œ ì¬ì‚¬ìš©

        df_daily = (
            df_metric_all.groupby("link_id", as_index=False)["value"].mean()
            .rename(columns={"value":"daily_value"})
        )

        color_mode = st.session_state.get("color_mode_daily_val", "ì ˆëŒ€(30/70)")
        if not df_daily.empty:
            key = build_daily_geojson_key(df_daily, color_mode)
            st.session_state["matched_geo_key_daily"] = key if key else None
        else:
            st.session_state["matched_geo_key_daily"] = None

            legend_text = ("ğŸŸ© <30 Â· ğŸŸ¨ 30~70 Â· ğŸŸ¥ â‰¥70 (ë‹¨ìœ„: %)"
                           if color_mode.startswith("ì ˆëŒ€")
                           else "ğŸŸ© <30% ë¶„ìœ„ Â· ğŸŸ¨ 30~70% Â· ğŸŸ¥ â‰¥70% ë¶„ìœ„")
            legend_slot.caption(legend_text)


        render_map(view_state)

# 3-2: í˜¼ì¡ì§€í‘œ(í˜¼ì¡ë„) â€” Top-N ì‹œê°„ëŒ€ ë³€í™”
with colL:
    st.markdown("### ğŸ“ˆ [3-2ì‚¬ë¶„ë©´] Â· í˜¼ì¡ì§€í‘œ (í˜¼ì¡ë„)")
    df_plot_all = st.session_state.get("df_plot_all", None)
    graph_topn = st.session_state.get("graph_topn", 10)

    if (df_plot_all is not None) and (not df_plot_all.empty):
        df_metric_all = compute_congestion_from_speed(df_plot_all)
        rank = (
            df_metric_all.groupby("link_id", as_index=False)["value"].mean()
            .sort_values("value", ascending=False).head(graph_topn)
        )
        keep = set(rank["link_id"].astype(str))
        df_metric_chart = df_metric_all[df_metric_all["link_id"].astype(str).isin(keep)].copy()
        chart = (
            alt.Chart(df_metric_chart).mark_line(point=True)
            .encode(
                x=alt.X("hour:Q", title="ì‹œê°„ëŒ€ (ì‹œ)"),
                y=alt.Y("value:Q", title="í˜¼ì¡ë„(%)", scale=alt.Scale(domain=[0, 100])),
                color=alt.Color("link_id:N", title="ë§í¬ ID",
                                legend=alt.Legend(orient="bottom", direction="horizontal", columns=4)),
                tooltip=[alt.Tooltip("link_id:N", title="ë§í¬"),
                         alt.Tooltip("hour:Q", title="ì‹œ"),
                         alt.Tooltip("value:Q", title="í˜¼ì¡ë„(%)", format=".1f")],
            ).properties(title=f"[3-2] í˜¼ì¡ë„ ë³€í™” â€” Top {graph_topn}", height=360)
            .configure_view(strokeWidth=0)
        )
        st.altair_chart(chart, use_container_width=True, theme=None)
        with st.expander("ğŸ§® í˜¼ì¡ë„(%) ì •ì˜", expanded=False):
            st.markdown("- ë§í¬ $(l)$, ì‹œê°„ëŒ€ $(h)$ì˜ í‰ê· ì†ë„ $v_{l,h}$, ììœ ì£¼í–‰ì†ë„ $v_{\\mathrm{ff},l}=\\max_h v_{l,h}$ ì¼ ë•Œ")
            st.latex(r"\mathrm{í˜¼ì¡ë„}_{l,h}(\%)=\Big(1-\min\big(1,\frac{v_{l,h}}{v_{\mathrm{ff},l}}\big)\Big)\times 100")
            st.markdown("- ê°’ì˜ ì˜ë¯¸: **0% = ììœ ì£¼í–‰**, **100% = ë§¤ìš° í˜¼ì¡**")
    else:
        st.info("í˜¼ì¡ë„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# 3-3: ì¶”ì„¸ vs ì¬ê±´ì¶• í›„(ì¶”ì •)
with colL:
    st.markdown("### ğŸ“‰ [3-3ì‚¬ë¶„ë©´] Â· ì£¼ë³€ë§í¬ ì¶”ì„¸(ê¸°ì¤€) vs ì¬ê±´ì¶• í›„(ì¶”ì •)")
    df_plot_all = st.session_state.get("df_plot_all", None)

    if (df_plot_all is None) or df_plot_all.empty:
        st.info("ë°˜ê²½ ë‚´ ë§í¬ ë°ì´í„°ê°€ ì—†ì–´ ì¶”ì„¸ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. [3-1]ì—ì„œ ë°˜ê²½ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
    else:
        def _congestionize(df):
            d = df.copy()
            d["í‰ê· ì†ë„(km/h)"] = pd.to_numeric(d["í‰ê· ì†ë„(km/h)"], errors="coerce")
            d["free_flow"] = d.groupby("link_id")["í‰ê· ì†ë„(km/h)"].transform("max").clip(lower=1)
            d["í˜¼ì¡ë„(%)"] = ((1 - (d["í‰ê· ì†ë„(km/h)"] / d["free_flow"]).clip(0, 1)) * 100).clip(0, 100)
            return d[["link_id","hour","í˜¼ì¡ë„(%)"]]

        d0 = _congestionize(df_plot_all)
        grp = d0.groupby("hour")["í˜¼ì¡ë„(%)"]
        trend_base = (
            grp.mean().rename("mean").to_frame()
            .assign(p25=grp.quantile(0.25), p75=grp.quantile(0.75))
            .reset_index()
        )
        # ë‹¤í•­ íšŒê·€(ìµœëŒ€ 3ì°¨)
        x = trend_base["hour"].to_numpy().astype(float)
        y = trend_base["mean"].to_numpy().astype(float)
        deg = int(min(3, max(1, np.unique(x).size - 1)))
        coeff = np.polyfit(x, y, deg=deg)
        poly  = np.poly1d(coeff)
        trend_base["mean_fit"] = np.clip(poly(x), 0, 100)

        planned_hh = int(current.get("households") or 1000)
        # Î· ê¸°ë³¸ê°’(ì„¸ì…˜ ìš°ì„ )
        eta_default = st.session_state["eta_by_gu"].get(selected_gu, SENS_DEFAULTS.get(selected_gu, 0.60))

        c1, c2, c3 = st.columns([1.0, 1.0, 1.0])
        with c1:
            default_base_hh = int(np.clip(planned_hh * 0.8, 50, 30000))
            base_hh = int(st.number_input("ê¸°ì¡´ ì„¸ëŒ€ìˆ˜(ì…ë ¥)", min_value=50, max_value=30000,
                                          value=default_base_hh, step=50,
                                          key=f"base_hh_{selected_gu}_{selected_row}"))
        with c2:
            st.number_input("ê³„íš ì„¸ëŒ€ìˆ˜(í‘œ)", value=planned_hh, disabled=True,
                            key=f"planned_hh_{selected_gu}_{selected_row}")
        sens = float(st.session_state.get("eta_by_gu", {}).get(selected_gu, eta_default))
        with c3:
            st.metric("ë¯¼ê°ë„ Î·(êµ¬)", f"{sens:.2f}")






        # ê¸°ì¡´ í•¨ìˆ˜ì— eps ì¸ì ì¶”ê°€(ìŠ¬ë¼ì´ë” ì˜ì¡´ ì œê±°)
        def _hourly_weight_default(alpha_: float = 1.5, eps_: float = 0.05) -> np.ndarray:
            base = np.array([0.05, 0.05, 0.05, 0.05, 0.06, 0.12, 0.35, 0.60, 0.80, 0.70, 0.55, 0.50,
                             0.45, 0.45, 0.50, 0.65, 0.85, 1.00, 0.80, 0.55, 0.35, 0.20, 0.10, 0.07])
            w = (base / base.max()) ** float(alpha_)
            return np.maximum(w, float(eps_))


        # w(h) ì œê±° + ìƒˆë²½ë§Œ ì•„ì£¼ ì†Œí­ ê°ì‡ 
        #   - min_factor=0.95  â†’ ìƒˆë²½ ì‹œê°„ëŒ€ì—ë„ 5%ë§Œ ê°ì†Œ
        #   - turn_hour=6.5    â†’ 06:30 ì „í›„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì›ë˜ê°’(=1)ë¡œ íšŒë³µ
        #   - k=1.6            â†’ ì „ì´ êµ¬ê°„ì„ ì§§ê²Œ(ê¸‰ê²©íˆ) ë§Œë“¤ì–´ ì˜í–¥ ìµœì†Œí™”
        w_hour = np.ones(24, dtype=float)
        w_hour = apply_dawn_smoothing(w_hour, min_factor=0.2, turn_hour=6.5, k=1.6)


        with st.expander("ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜ w(h) ì•ˆë‚´", expanded=False):
            st.markdown(f"- ì „ì—­ ê³ ì •ê°’ ì‚¬ìš©: Î±={ALPHA_HOURLY}, Îµ={EPS_HOURLY} Â· ìƒˆë²½ ì™„ê¸‰ ì ìš©")

        # ì¬ê±´ì¶• í›„ í˜¼ì¡ ì¶”ì •ì‹
        r = (planned_hh / max(1.0, float(base_hh)))
        base = trend_base["mean_fit"].to_numpy()
        # êµì²´ë³¸ (w(h) ë°˜ì˜)
        w_series = pd.Series(w_hour, index=np.arange(24))  # ì‹œê°„ëŒ€â†’ê°€ì¤‘ì¹˜ ë§¤í•‘
        w_for_hour = trend_base["hour"].astype(int).map(w_series).to_numpy()

        # w(h) â†’ hourë³„ë¡œ ë§¤í•‘í•´ì„œ ë°˜ì˜


        after = 100.0 * (
                1.0 -
                (1.0 - base / 100.0) / (1.0 + sens * w_for_hour * (r - 1.0))
        )
        trend_base["after_fit"] = np.clip(after, 0, 100)

        # ì‹œê°í™”
        plot_df = trend_base[["hour", "mean_fit", "after_fit"]].melt(id_vars=["hour"], var_name="series",
                                                                     value_name="value")
        label_map = {"mean_fit":"ê¸°ì¤€ ì¶”ì„¸", "after_fit":"ì¬ê±´ì¶• í›„(ì¶”ì •)"}
        plot_df["series"] = plot_df["series"].map(label_map)
        color_domain = ["ê¸°ì¤€ ì¶”ì„¸","ì¬ê±´ì¶• í›„(ì¶”ì •)"]; color_range = ["#22c55e","#ef4444"]

        band = alt.Chart(trend_base).mark_area(opacity=0.18).encode(
            x=alt.X("hour:Q", title="ì‹œê°„ëŒ€ (ì‹œ)"),
            y=alt.Y("p25:Q", title="í˜¼ì¡ë„(%)"),
            y2="p75:Q",
        )
        lines = alt.Chart(plot_df).mark_line(point=True).encode(
            x=alt.X("hour:Q", title="ì‹œê°„ëŒ€ (ì‹œ)"),
            y=alt.Y("value:Q", title="í˜¼ì¡ë„(%)", scale=alt.Scale(domain=[0, 100])),
            color=alt.Color("series:N", title="", scale=alt.Scale(domain=color_domain, range=color_range)),
            tooltip=[alt.Tooltip("hour:Q", title="ì‹œ"), alt.Tooltip("series:N", title=""), alt.Tooltip("value:Q", title="í˜¼ì¡ë„(%)", format=".1f")],
        )
        chart_33 = (band + lines).properties(
            title=f"ì£¼ë³€ë§í¬ í˜¼ì¡ ì¶”ì„¸(ê¸°ì¤€) vs ì¬ê±´ì¶• í›„(ì¶”ì •) Â· r={r:.2f}, Î·={sens:.2f}", height=360
        ).configure_view(strokeWidth=0).configure_legend(orient="right")
        st.altair_chart(chart_33, use_container_width=True, theme=None)

        # >>> PATCH A: save curves for quadrant-4 needs ------------------------
        # >>> PATCH A2: 3-4 ê°„ì†Œí™”ìš© ìë™ê¸°ë³¸ê°’ ê³„ì‚°/ì €ì¥ -------------------
        try:
            # â‘  ê¸°ì¤€ í˜¼ì¡ë„(%) ê¸°ë³¸ê°’: base ê³¡ì„ ì˜ í‰ê· 
            auto_cong = float(curve_33["base"].mean())

            # â‘¡ 'ê¸°ì¤€ ì´í•˜'ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ìµœì†Œ ì¦í¸ë¥ (%)
            auto_bus = compute_min_bus_increase_to_cap(
                after=curve_33["after"].to_numpy(),
                base=curve_33["base"].to_numpy()
            )

            # â‘¢ ì„¸ëŒ€ìˆ˜/í‰í˜• ê¸°ë³¸
            auto_house = int(planned_hh)
            auto_py = float(st.session_state.get("desired_py", 25.0))

            # â‘£ ì¬ë¬´ ê³µí†µ(ì„¸ì…˜ì— ìˆìœ¼ë©´ ìš°ì„ )
            auto_non_sale = float(st.session_state.get("non_sale_ratio", 0.15))
            auto_sale_rate = float(st.session_state.get("sale_rate", 0.98))
            auto_disc = float(st.session_state.get("disc_rate", 0.07))
            auto_years = int(st.session_state.get("years", 4))

            st.session_state["auto_defaults"] = {
                "congestion_base": auto_cong,
                "bus_inc_pct": float(np.clip(auto_bus, 0.0, 100.0)),
                "households": auto_house,
                "avg_py": auto_py,
                "non_sale_ratio": auto_non_sale,
                "sale_rate": auto_sale_rate,
                "disc_rate": auto_disc,
                "years": auto_years,
            }
        except Exception as _e:
            # ì•ˆì „ì¥ì¹˜: ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì…‹
            st.session_state["auto_defaults"] = st.session_state.get("auto_defaults", {
                "congestion_base": 50.0, "bus_inc_pct": 10.0,
                "households": int(current.get("households") or 1000),
                "avg_py": float(st.session_state.get("desired_py", 25.0)),
                "non_sale_ratio": 0.15, "sale_rate": 0.98, "disc_rate": 0.07, "years": 4
            })
        # -------------------------------------------------------------------

        curve_33 = trend_base[["hour", "mean_fit", "after_fit"]].rename(
            columns={"mean_fit": "base", "after_fit": "after"}
        ).copy()
        st.session_state["curve_33"] = curve_33
        # ---------------------------------------------------------------------

        # (ëŒ€ì²´í• )ê¸°ì¡´ì½”ë“œ <- ì£¼ì„ì²˜ë¦¬
        # with st.expander("ê·¸ë˜í”„/ëª¨í˜• ì„¤ëª… ë³´ê¸°"):
        #     st.markdown("### ğŸ“˜ ë¬´ì—‡ì„ ë³´ë‚˜ìš”?")
        #     st.markdown(
        #         "- **ì—°í•œ ì˜ì—­**: ë°˜ê²½ ë‚´ ëª¨ë“  ë§í¬ì˜ í˜¼ì¡ë„ ë¶„ìœ„ìˆ˜ ë°´ë“œ(25â€“75%)\n"
        #         "- **ê¸°ì¤€ ì¶”ì„¸ (ì´ˆë¡)**: ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ë¥¼ 3ì°¨ ì´í•˜ ë‹¤í•­ìœ¼ë¡œ ê·¼ì‚¬\n"
        #         "- **ì¬ê±´ì¶• í›„ (ë¹¨ê°•)**: ì„¸ëŒ€ ì¦ê°€ ë¹„ìœ¨ `r = (ê³„íš/ê¸°ì¡´)`ê³¼ ë¯¼ê°ë„ `Î·`ë¥¼ ë°˜ì˜í•œ ê°„ì´ ì¶”ì •"
        #     )
        #     st.markdown("### âš™ï¸ ì¶”ì •ì‹")
        #     st.latex(
        #         r"""
        #         \text{after}(h)= 100 \times
        #         \left[
        #             1 -
        #             \frac{
        #                 1 - \dfrac{\text{base}(h)}{100}
        #             }{
        #                 1 + \eta\,(r - 1)
        #             }
        #         \right]
        #         """
        #     )
        #     st.markdown("### ğŸ”£ ê¸°í˜¸ ì„¤ëª…")
        #     st.latex(r"\text{base}(h):\; \text{ê¸°ì¤€ ì¶”ì„¸ í˜¼ì¡ë„(\%)}")
        #     st.latex(r"r:\; \dfrac{\text{ê³„íšì„¸ëŒ€ìˆ˜}}{\text{ê¸°ì¡´ì„¸ëŒ€ìˆ˜}}")
        #     st.latex(r"\eta:\; \text{êµ¬ë³„ ë¯¼ê°ë„ (í˜¼ì¡ íƒ„ë ¥ì„±)}")

        # (ìˆ˜ì •ëœ) ìƒˆë¡œìš´ ì„¤ëª… ë¸”ë¡ â€” w(h)Â·Î±Â·Îµ ë°˜ì˜
        with st.expander("ê·¸ë˜í”„/ëª¨í˜• ì„¤ëª… ë³´ê¸°"):
            st.markdown("### ğŸ“˜ ë¬´ì—‡ì„ ë³´ë‚˜ìš”?")
            st.markdown(
                "- **ì—°í•œ ì˜ì—­**: ë°˜ê²½ ë‚´ ëª¨ë“  ë§í¬ì˜ í˜¼ì¡ë„ ë¶„ìœ„ìˆ˜ ë°´ë“œ(25â€“75%)\n"
                "- **ê¸°ì¤€ ì¶”ì„¸ (ì´ˆë¡)**: ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ë¥¼ 3ì°¨ ì´í•˜ ë‹¤í•­ìœ¼ë¡œ ê·¼ì‚¬í•œ ê³¡ì„ \n"
                "- **ì¬ê±´ì¶• í›„ (ë¹¨ê°•)**: ì„¸ëŒ€ ì¦ê°€ ë¹„ìœ¨ `r = (ê³„íš/ê¸°ì¡´)`ê³¼ **ë¯¼ê°ë„ `Î·`ì— ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜ `w(h)`**ë¥¼ ê³±í•´ ë°˜ì˜í•œ ê°„ì´ ì¶”ì •"
            )
            st.markdown("### âš™ï¸ ì¶”ì •ì‹ (ì‹œê°„ëŒ€ ê°€ì¤‘ ë°˜ì˜)")
            st.latex(
                r"""
                \text{after}(h)= 100 \times 
                \left[
                    1 -
                    \frac{1 - \dfrac{\text{base}(h)}{100}}
                         {1 + \eta\,\underbrace{\tilde{w}(h)}_{\approx\,1,\ \text{dawn}\simeq0.95}\,(r - 1)}
                \right]


                """
            )
            st.markdown("### ğŸ”£ ê¸°í˜¸ ì„¤ëª…")
            st.latex(r"\text{base}(h):\; \text{ê¸°ì¤€ ì¶”ì„¸ í˜¼ì¡ë„(\%)}")
            st.latex(r"r:\; \dfrac{\text{ê³„íšì„¸ëŒ€ìˆ˜}}{\text{ê¸°ì¡´ì„¸ëŒ€ìˆ˜}}")
            st.latex(r"\eta:\; \text{êµ¬ë³„ ë¯¼ê°ë„ (í˜¼ì¡ íƒ„ë ¥ì„±)}")
            st.latex(r"w(h):\; \text{ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜, ì‹¬ì•¼}\approx 0,\; \text{í”¼í¬}\approx 1")
            st.markdown(
                "- `w(h)`ëŠ” ë°˜ê²½ ë‚´ ì‹œê°„ëŒ€ë³„ ì´ ì°¨ëŸ‰ëŒ€ë¥¼ ì •ê·œí™”í•´ ë§Œë“¤ê³ , "
                "`Î±`(í”¼í¬ ê°•ì¡°) ì§€ìˆ˜ì™€ `Îµ`(ì‹¬ì•¼ ìµœì†Œ ì˜í–¥) í•˜í•œì„ ì ìš©í•©ë‹ˆë‹¤.\n"
                "  - `Î±`â†‘ â†’ í”¼í¬ ì˜í–¥ í™•ëŒ€, ì‹¬ì•¼ ì˜í–¥ ì¶•ì†Œ\n"
                "  - `Îµ`ëŠ” 0ìœ¼ë¡œ ë‘ë©´ ê³¡ì„ ì´ ê¸‰ê²©íˆ êº¾ì¼ ìˆ˜ ìˆì–´, ê¸°ë³¸ì ìœ¼ë¡œ ì†ŒëŸ‰(ì˜ˆ: 0.05) ë¶€ì—¬"
            )


# 3-4: ì‹œë‚˜ë¦¬ì˜¤/ë¯¼ê°ë„/í™•ë¥ 
def calc_kpis(
    households:int, avg_py:float, sale_price_per_m2:float, build_cost_per_m2:float, infra_invest_billion:float,
    congestion_base:float, bus_inc_pct:int, non_sale_ratio:float=0.15, sale_rate:float=0.98, disc_rate:float=0.07, years:int=4
):
    m2_per_py = 3.3058
    avg_m2 = avg_py * m2_per_py
    sellable_m2 = households * avg_m2 * (1 - non_sale_ratio)
    predicted_cong = max(0.0, congestion_base * (1 - bus_inc_pct / 150))
    cong_improve = max(0.0, congestion_base - predicted_cong)

    revenue_won = sellable_m2 * sale_price_per_m2 * sale_rate
    cost_won = sellable_m2 * build_cost_per_m2
    total_cost_bil = cost_won/1e4/100 + infra_invest_billion
    total_rev_bil  = revenue_won/1e4/100

    profit_bil = total_rev_bil - total_cost_bil
    margin_pct = (profit_bil / total_cost_bil * 100) if total_cost_bil>0 else 0

    cf_annual = profit_bil / years if years>0 else profit_bil
    npv = sum([cf_annual / ((1+disc_rate)**t) for t in range(1, years+1)]) if years>0 else profit_bil
    payback = min(years, max(1, int(np.ceil(total_cost_bil / max(1e-6, cf_annual))))) if years>0 else 1

    return {
        "ë¶„ì–‘ë©´ì (ã¡)": sellable_m2,
        "ì˜ˆìƒí˜¼ì¡ë„(%)": round(predicted_cong,1),
        "í˜¼ì¡ë„ê°œì„ (Î”%)": round(cong_improve,1),
        "ì´ë§¤ì¶œ(ì–µì›)": round(total_rev_bil,1),
        "ì´ì‚¬ì—…ë¹„(ì–µì›)": round(total_cost_bil,1),
        "ì´ìµ(ì–µì›)": round(profit_bil,1),
        "ë§ˆì§„ìœ¨(%)": round(margin_pct,1),
        "NPV(ì–µì›)": round(npv,1),
        "íšŒìˆ˜ê¸°ê°„(ë…„)": payback,
    }

    # 3-4: ì‹œë‚˜ë¦¬ì˜¤/ë¯¼ê°ë„/í™•ë¥   â† ê¸°ì¡´ ë‚´ìš© ì „ë¶€ ì‚­ì œí•˜ê³  ì•„ë˜ë¡œ êµì²´
    with colL:
        st.markdown("### ğŸ§¾ [3-4ì‚¬ë¶„ë©´] Â· ì‹œë‚˜ë¦¬ì˜¤ & ì¬ë¬´/ë¯¼ê°ë„ & í™•ë¥ ")
        # ì œëª©ë§Œ ë‚¨ê¸°ê³  ë¹ˆ ê³µê°„ í™•ë³´ (í•„ìš”ì‹œ ë†’ì´ ì¡°ì ˆ)
        st.markdown("<div style='height: 260px'></div>", unsafe_allow_html=True)

    # -------------------------------------------------------------------



# 4ì‚¬ë¶„ë©´: ìµœì¢… ë¦¬í¬íŠ¸
# 4ì‚¬ë¶„ë©´: ìµœì¢… ë¦¬í¬íŠ¸  â† ê¸°ì¡´ ë‚´ìš© ì „ë¶€ ì‚­ì œí•˜ê³  ì•„ë˜ë¡œ êµì²´
with colR:
    st.markdown("### ğŸ§© [4ì‚¬ë¶„ë©´] Â· ìµœì¢… ë¦¬í¬íŠ¸ & ë¶„ì„")
    # ì œëª©ë§Œ ë‚¨ê¸°ê³  ë„‰ë„‰í•œ ë¹ˆ ê³µê°„
    with st.container(border=True):
        st.caption("ì´ ì˜ì—­ì€ í˜„ì¬ ë¹„ì›Œë‘ ")
        st.markdown("<div style='height: 520px'></div>", unsafe_allow_html=True)

        # ---------------------------------------------------------------------

# ----------------------------------------------------
# ğŸ§¾ í™•ì¥ ì„¹ì…˜: ì‹œë‚˜ë¦¬ì˜¤ & ì¬ë¬´/ë¯¼ê°ë„ & í™•ë¥  (í•˜ë‹¨ ë¶„ë¦¬)
# ----------------------------------------------------
st.divider()
with st.expander("ğŸ§¾ [í™•ì¥] ì‹œë‚˜ë¦¬ì˜¤ & ì¬ë¬´/ë¯¼ê°ë„ & í™•ë¥ ", expanded=False):

    st.markdown("### ğŸ§¾ [3-4ì‚¬ë¶„ë©´] Â· ì‹œë‚˜ë¦¬ì˜¤ & ì¬ë¬´/ë¯¼ê°ë„ & í™•ë¥ ")
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ§© ì…ë ¥Â·ì‹œë‚˜ë¦¬ì˜¤", "ğŸ“ˆ ë¯¼ê°ë„", "ğŸ² í™•ë¥ (ê°„ì´)", "ğŸ“¤ ë¦¬í¬íŠ¸"])

    with tab1:
        st.markdown("#### ğŸ“‹ ê³µí†µ ì…ë ¥")
        c1, c2 = st.columns(2)
        with c1:
            households = int(st.number_input("ê³„íš ì„¸ëŒ€ìˆ˜", 100, 10000, int(current.get("households") or 1000), step=50))
            avg_py = st.number_input("í‰ê·  ì „ìš©ë©´ì (í‰)", 10.0, 60.0, float(st.session_state.get("desired_py", 25.0)), 0.5)
            congestion_base = st.number_input("ê¸°ì¤€ í˜¼ì¡ë„(%)", 0.0, 100.0, 50.0, 1.0)
            non_sale_ratio = st.slider("ë¹„ë¶„ì–‘ ë¹„ìœ¨", 0.0, 0.4, 0.15, 0.01, help="ê³µê³µ/ì»¤ë®¤ë‹ˆí‹° ë“±")
        with c2:
            sale_rate = st.slider("ë¶„ì–‘ë¥ ", 0.80, 1.00, 0.98, 0.01)
            disc_rate = st.slider("í• ì¸ìœ¨(ì¬ë¬´)", 0.03, 0.15, 0.07, 0.005)
            years = st.slider("íšŒìˆ˜ê¸°ê°„(ë…„)", 2, 10, 4, 1)
            base_bus_inc = st.slider("ë² ì´ìŠ¤ë¼ì¸ ë²„ìŠ¤ ì¦í¸(%)", 0, 100, 10, 5)

        st.markdown("#### ğŸ§ª ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜")
        st.caption("ë¶„ì–‘ê°€/ê³µì‚¬ë¹„/ë²„ìŠ¤ì¦í¸/ì¸í”„ë¼íˆ¬ìë§Œ ë‹¤ë¥´ê²Œ í•˜ë©°, ë‚˜ë¨¸ì§€ëŠ” ê³µí†µ ì…ë ¥ì„ ìƒì†í•©ë‹ˆë‹¤.")
        def scenario_inputs(label, sale_default, cost_default, bus_default, infra_default):
            a,b,c,d = st.columns(4, gap="small")
            with a: sale = st.number_input(f"{label}Â·ë¶„ì–‘ê°€(ë§Œì›/ã¡)", 500.0, 3000.0, sale_default, 10.0, key=f"sale_{label}")
            with b: cost = st.number_input(f"{label}Â·ê³µì‚¬ë¹„(ë§Œì›/ã¡)", 300.0, 2500.0, cost_default, 10.0, key=f"cost_{label}")
            with c: bus = st.slider(f"{label}Â·ë²„ìŠ¤ì¦í¸(%)", 0, 100, bus_default, 5, key=f"bus_{label}")
            with d: infra = st.number_input(f"{label}Â·ì¸í”„ë¼(ì–µì›)", 0.0, 1000.0, infra_default, 5.0, key=f"infra_{label}")
            return sale, cost, bus, infra

        saleA, costA, busA, infraA = scenario_inputs("A", 1200.0, 900.0, base_bus_inc, 30.0)
        saleB, costB, busB, infraB = scenario_inputs("B", 1300.0, 950.0, base_bus_inc+10, 50.0)
        saleC, costC, busC, infraC = scenario_inputs("C", 1100.0, 850.0, max(0, base_bus_inc-5), 20.0)

        scenarios = {"A": dict(sale=saleA, cost=costA, bus=busA, infra=infraA),
                     "B": dict(sale=saleB, cost=costB, bus=busB, infra=infraB),
                     "C": dict(sale=saleC, cost=costC, bus=busC, infra=infraC)}

        rows = []
        for name, s in scenarios.items():
            k = calc_kpis(households, avg_py, s["sale"], s["cost"], s["infra"], congestion_base, s["bus"],
                          non_sale_ratio, sale_rate, disc_rate, years)
            rows.append({"ì‹œë‚˜ë¦¬ì˜¤": name, **k})
        df_scn = pd.DataFrame(rows).set_index("ì‹œë‚˜ë¦¬ì˜¤")
        st.markdown("#### ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµí‘œ")
        st.dataframe(df_scn, use_container_width=True)
        best = df_scn.sort_values("NPV(ì–µì›)", ascending=False).head(1)
        st.success(f"**ì¶”ì²œ ì‹œë‚˜ë¦¬ì˜¤: {best.index[0]}** Â· NPV {best['NPV(ì–µì›)'].iloc[0]:,.1f}ì–µì› Â· ë§ˆì§„ìœ¨ {best['ë§ˆì§„ìœ¨(%)'].iloc[0]:.1f}%")

        st.session_state["df_scn_result"] = df_scn
        st.session_state["df_scn_summary_for_charts"] = df_scn.reset_index()[["ì‹œë‚˜ë¦¬ì˜¤","NPV(ì–µì›)","ë§ˆì§„ìœ¨(%)","í˜¼ì¡ë„ê°œì„ (Î”%)"]]

    with tab2:
        st.markdown("#### ğŸ“ˆ ë¯¼ê°ë„ ë¶„ì„ (í† ë„¤ì´ë„)")
        base_sale = st.number_input("ê¸°ì¤€ ë¶„ì–‘ê°€(ë§Œì›/ã¡)", 500.0, 3000.0, 1200.0, 10.0)
        base_cost = st.number_input("ê¸°ì¤€ ê³µì‚¬ë¹„(ë§Œì›/ã¡)", 300.0, 2500.0, 900.0, 10.0)
        base_bus  = st.slider("ê¸°ì¤€ ë²„ìŠ¤ì¦í¸(%)", 0, 100, 20, 5)
        base_infra= st.number_input("ê¸°ì¤€ ì¸í”„ë¼(ì–µì›)", 0.0, 1000.0, 30.0, 5.0)
        pct = st.slider("ë³€ë™í­(Â±%)", 1, 30, 15, 1)

        def kpi_with(sale, cost, bus, infra):
            return calc_kpis(households, avg_py, sale, cost, infra, congestion_base, bus,
                             non_sale_ratio, sale_rate, disc_rate, years)["NPV(ì–µì›)"]

        base_npv = kpi_with(base_sale, base_cost, base_bus, base_infra)
        factors = []
        ranges = {
            "ë¶„ì–‘ê°€": (base_sale*(1-pct/100), base_sale*(1+pct/100)),
            "ê³µì‚¬ë¹„": (base_cost*(1-pct/100), base_cost*(1+pct/100)),
            "ë²„ìŠ¤ì¦í¸": (max(0, base_bus-pct), min(100, base_bus+pct)),
            "ì¸í”„ë¼": (max(0, base_infra*(1-pct/100)), base_infra*(1+pct/100)),
        }
        for name, (lo, hi) in ranges.items():
            npv_lo = kpi_with(lo if name=="ë¶„ì–‘ê°€" else base_sale,
                              lo if name=="ê³µì‚¬ë¹„" else base_cost,
                              lo if name=="ë²„ìŠ¤ì¦í¸" else base_bus,
                              lo if name=="ì¸í”„ë¼" else base_infra)
            npv_hi = kpi_with(hi if name=="ë¶„ì–‘ê°€" else base_sale,
                              hi if name=="ê³µì‚¬ë¹„" else base_cost,
                              hi if name=="ë²„ìŠ¤ì¦í¸" else base_bus,
                              hi if name=="ì¸í”„ë¼" else base_infra)
            factors.append({"ìš”ì¸": name, "NPV_low": npv_lo, "NPV_high": npv_hi})

        df_tornado = pd.DataFrame(factors)
        bars = alt.Chart(df_tornado).transform_fold(
            ["NPV_low","NPV_high"], as_=["type","NPV"]
        ).mark_bar().encode(
            y=alt.Y("ìš”ì¸:N", sort=None),
            x=alt.X("NPV:Q", title="NPV(ì–µì›)"),
            color="type:N",
            tooltip=["ìš”ì¸:N","NPV:Q"]
        ).properties(height=220)
        st.altair_chart(bars, use_container_width=True)
        st.session_state["df_tornado"] = df_tornado
        st.session_state["base_npv_for_tornado"] = float(base_npv)

    with tab3:
        st.markdown("#### ğŸ² í™•ë¥  ë¶„ì„ (ê°„ì´ Monte Carlo)")
        n = st.slider("ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µìˆ˜", 200, 5000, 1000, 100)
        sigma_sale = st.slider("ë¶„ì–‘ê°€ í‘œì¤€í¸ì°¨(%)", 1, 20, 7)
        sigma_cost = st.slider("ê³µì‚¬ë¹„ í‘œì¤€í¸ì°¨(%)", 1, 20, 5)
        rng = np.random.default_rng(42)
        sale_samples = rng.normal(loc=base_sale, scale=base_sale*sigma_sale/100, size=n)
        cost_samples = rng.normal(loc=base_cost, scale=base_cost*sigma_cost/100, size=n)
        def kpi_with_sale_cost(s, c):
            return calc_kpis(households, avg_py, s, c, base_infra, congestion_base, base_bus,
                             non_sale_ratio, sale_rate, disc_rate, years)["NPV(ì–µì›)"]
        npvs = [kpi_with_sale_cost(max(100, s), max(100, c)) for s, c in zip(sale_samples, cost_samples)]
        ser = pd.Series(npvs)
        p10, p50, p90 = np.percentile(ser, [10, 50, 90])
        st.metric("P10 NPV", f"{p10:,.1f} ì–µì›")
        st.metric("P50 NPV", f"{p50:,.1f} ì–µì›")
        st.metric("P90 NPV", f"{p90:,.1f} ì–µì›")
        st.caption("â€» P10: ë³´ìˆ˜ì (í•˜ìœ„ 10%), P90: ë‚™ê´€ì (ìƒìœ„ 10%)")
        hist = alt.Chart(pd.DataFrame({"NPV": ser})).mark_bar().encode(
            x=alt.X("NPV:Q", bin=alt.Bin(maxbins=30), title="NPV(ì–µì›)"),
            y="count()"
        ).properties(height=200)
        st.altair_chart(hist, use_container_width=True)
        st.session_state["mc_p10p50p90"] = (float(p10), float(p50), float(p90))
        st.session_state["mc_samples_npv"] = ser.tolist()

    with tab4:
        st.info("ğŸ“Œ ì˜¤ë¥¸ìª½ **[4ì‚¬ë¶„ë©´] ìµœì¢… ë¦¬í¬íŠ¸** íŒ¨ë„ì—ì„œ ì¢…í•© ìš”ì•½Â·ìë™ í•´ì„Â·ë‚´ë³´ë‚´ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”. (ì•ˆë‚´ìš©)")


# ì´ˆê¸° ì§€ë„ ë Œë”(ë°ì´í„° ê³„ì‚° ì „ì— í˜¸ì¶œëœ ê²½ìš° ëŒ€ë¹„)
render_map(view_state)
