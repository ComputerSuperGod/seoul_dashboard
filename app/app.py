# -------------------------------------------------------------
# ğŸ— AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ (ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper)
# -------------------------------------------------------------
# ğŸ“Š CSV ê¸°ë°˜ ë°ì´í„° ë°˜ì˜ ë²„ì „
# -------------------------------------------------------------

# --- must come first: add project root to sys.path BEFORE importing utils ---
import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent  # .../seoul_dashboard_3
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))
# ---------------------------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import altair as alt
from datetime import datetime

# === ì™¸ë¶€ ëª¨ë“ˆ (utils) ì„í¬íŠ¸ ===
from utils.traffic_preproc import ensure_speed_csv

# Altair/MPL/Plotly ìŠ¤ìœ„ì¹˜í˜•: plot_speedê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ í•¨ìˆ˜ë¡œ í´ë°±
try:
    from utils.traffic_plot import plot_speed
    _HAS_PLOT_SPEED = True
except Exception as e:
    print("utils.traffic_plot import fallback:", e)
    from utils.traffic_plot import plot_nearby_speed_from_csv
    _HAS_PLOT_SPEED = False

# === ë°ì´í„° ë””ë ‰í„°ë¦¬ ===
DATA_DIR = BASE_DIR / "data"

# === ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì´ë¦„ ì¶©ëŒ ë°©ì§€: ë³€ìˆ˜ëª… êµ¬ë¶„) ===
BASE_YEAR = 2023   # 24ë…„ìœ¼ë¡œ ë°”ê¿”ë„ ë¨

# ì¬ê±´ì¶• í”„ë¡œì íŠ¸ ì›ë³¸ CSV (ë‹¹ì‹ ì˜ appì—ì„œ ì“°ë˜ í‘œ ë°ì´í„°)
PROJECTS_CSV_PATH = DATA_DIR / "seoul_redev_projects.csv"

# êµí†µ ê¸°ì¤€ë…„ë„ ë°ì´í„° (ì—‘ì…€ â†’ CSV ìë™ ë³€í™˜ ëŒ€ìƒ)
TRAFFIC_XLSX_PATH = DATA_DIR / "AverageSpeed(LINK).xlsx"
TRAFFIC_CSV_PATH  = DATA_DIR / f"AverageSpeed_Seoul_{BASE_YEAR}.csv"

# ë„ë¡œë§ ë ˆë²¨6 ì‰ì´í”„
SHP_PATH = DATA_DIR / "seoul_link_lev6_2023.shp"



#===========================ìºì‹œ ë¹„ìš°ê¸°=================


with st.sidebar:
    if st.button("ìºì‹œ ë¹„ìš°ê¸°"):
        st.cache_data.clear()
        st.rerun()
   # ì¦‰ì‹œ ì¬ì‹¤í–‰
#======================================================

# ğŸ”¤ ì•ˆì „í•œ CSV ë¡œë”: ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
def smart_read_csv(path, encodings=("utf-8-sig", "cp949", "euc-kr", "utf-8", "latin1")):
    import pandas as pd
    last_err = None
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            return df
        except UnicodeDecodeError as e:
            last_err = e
            continue
    # ìµœí›„ ìˆ˜ë‹¨: errors='replace' ë¡œë¼ë„ ì½ê¸°
    try:
        df = pd.read_csv(path, encoding="utf-8", errors="replace")
        return df
    except Exception:
        raise last_err or Exception(f"Failed to read {path} with tried encodings.")



# -------------------------------------------------------------
# âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ ìë™ ì„¤ì •
# -------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent.parent
CSV_PATH = BASE_DIR / "data" / "seoul_redev_projects.csv"
CSV_ENCODING = "cp949"

# -------------------------------------------------------------
# ğŸ“¦ ì¢Œí‘œ CSV ë³‘í•© ìœ í‹¸
# -------------------------------------------------------------
# ë³€ê²½:
COORD_CSV_PATH = BASE_DIR / "data" / "ì„œìš¸ì‹œ_ì¬ê°œë°œì¬ê±´ì¶•_clean_kakao.csv"
COORD_ENCODING = "utf-8-sig"  # (ìŠ¤ë§ˆíŠ¸ ë¡œë”ê°€ ìë™íŒë³„í•˜ë¯€ë¡œ ì—†ì–´ë„ ë™ì‘)




@st.cache_data(show_spinner=False)
def load_coords() -> pd.DataFrame:
    df = smart_read_csv(COORD_CSV_PATH)

    # ìˆ«ìí™”
    df["lat"] = pd.to_numeric(df.get("lat"), errors="coerce")
    df["lon"] = pd.to_numeric(df.get("lon"), errors="coerce")

    # ì•ˆì „í•œ ë³‘í•©ìš© ê¸°ì´ˆ ì»¬ëŸ¼ ìƒì„±
    def coalesce(a, b):
        a = "" if a is None else str(a).strip()
        b = "" if b is None else str(b).strip()
        return a if a else b

    # name, address ë§Œë“¤ê¸°
    if ("ì •ë¹„êµ¬ì—­ëª…ì¹­" in df.columns) or ("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…" in df.columns):
        name = [coalesce(n, m) for n, m in zip(df.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), df.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))]
    else:
        name = df.get("name")

    address = [coalesce(a, b) for a, b in zip(df.get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), df.get("ëŒ€í‘œì§€ë²ˆ"))]

    out = pd.DataFrame({
        "apt_id": df.get("ì‚¬ì—…ë²ˆí˜¸").astype(str) if "ì‚¬ì—…ë²ˆí˜¸" in df.columns else "",
        "name": pd.Series(name, index=df.index),
        "gu": df.get("ìì¹˜êµ¬"),
        "address": pd.Series(address, index=df.index),
        "full_address": df.get("full_address"),
        "lat": df["lat"],
        "lon": df["lon"],
    })
    for col in ["apt_id", "name", "gu", "address", "full_address"]:
        if col in out.columns:
            out[col] = out[col].fillna("").astype(str).str.strip()
    return out


@st.cache_data(show_spinner=False)
def merge_projects_with_coords(gu: str) -> pd.DataFrame:
    # 1) ì›ë³¸ ë¡œë“œ + ìŠ¤í‚¤ë§ˆ í†µì¼
    raw = load_raw_csv()
    proj = normalize_schema(raw)
    proj = proj[proj["gu"] == gu].copy()

    # 2) ì¢Œí‘œ ë¡œë“œ
    coords = load_coords()
    coords = coords[coords["gu"] == gu].copy()

    # 3) âœ… name+gu ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­í•˜ê³  full_addressê¹Œì§€ ê°€ì ¸ì˜¤ê¸°
    out = proj.merge(
        coords[["name", "gu", "lat", "lon", "full_address"]],
        on=["name", "gu"],
        how="left"
    )

    # 4) ì¢Œí‘œ ê²°ì¸¡ ë³´ì • (êµ¬ ì¤‘ì‹¬ + ì§€í„°)
    missing = out["lat"].isna() | out["lon"].isna()
    base_lat, base_lon = GU_CENTER.get(gu, (37.55, 127.0))
    rng = np.random.default_rng(42)
    jitter = lambda n: rng.normal(0, 0.002, n)  # â‰ˆ 200m
    if missing.any():
        n = int(missing.sum())
        out.loc[missing, "lat"] = base_lat + jitter(n)
        out.loc[missing, "lon"] = base_lon + jitter(n)
    out["has_geo"] = ~missing

    # 5) âœ… í‘œì‹œìš© ì£¼ì†Œ: full_address ìš°ì„ , ì—†ìœ¼ë©´ ì›ë³¸ address
    out["address_display"] = out["full_address"].fillna("").replace("", pd.NA)
    out["address_display"] = out["address_display"].fillna(out["address"]).fillna("")

    return out.reset_index(drop=True)


# -------------------------------------------------------------
# âš™ï¸ Streamlit ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------------
st.set_page_config(
    page_title="AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ | ì¬ê±´ì¶• Helper",
    layout="wide",
)

STYLE = """
<style>
.small-muted { color: #7a7a7a; font-size: 0.9rem; }
.kpi-card { padding: 16px; border-radius: 16px; background: #111827; border: 1px solid #1f2937; }
.kpi-title { font-size: 0.9rem; color: #9ca3af; margin-bottom: 8px; }
.kpi-value { font-size: 1.4rem; font-weight: 700; color: #e5e7eb; }
.section-title { font-size: 1.1rem; font-weight: 700; margin-bottom: 8px; }
hr.soft { border: none; height: 1px; background: #1f2937; margin: 16px 0; }
</style>
"""
st.markdown(STYLE, unsafe_allow_html=True)


# -------------------------------------------------------------
# ğŸ§¾ CSV ë¡œë“œ & ì „ì²˜ë¦¬
# -------------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_raw_csv() -> pd.DataFrame:
    return smart_read_csv(PROJECTS_CSV_PATH)  # âœ… ì¸ì½”ë”© ìë™ ê°ì§€ ì‚¬ìš©


def _coalesce(*vals):
    for v in vals:
        if pd.notna(v) and str(v).strip():
            return v
    return None

def normalize_schema(df_raw: pd.DataFrame) -> pd.DataFrame:
    c = df_raw.columns
    get = lambda name: df_raw[name] if name in c else pd.Series([None]*len(df_raw))

    def _num(x):
        return pd.to_numeric(pd.Series(x, index=df_raw.index), errors="coerce")

    def _pct_to_num(x):
        s = pd.Series(x, index=df_raw.index).astype(str).str.replace("%", "", regex=False)
        s = s.str.replace(",", "", regex=False)
        return pd.to_numeric(s, errors="coerce")

    def _floors_to_num(x):
        # ìˆ«ìë§Œ ì¶”ì¶œ(ì§€ìƒ/ì§€í•˜ ë‘˜ ë‹¤ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        s = pd.Series(x, index=df_raw.index).astype(str).str.extract(r"(-?\d+)", expand=False)
        return pd.to_numeric(s, errors="coerce")

    # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ë§¤í•‘
    df = pd.DataFrame({
        "apt_id": get("ì‚¬ì—…ë²ˆí˜¸"),
        "name": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))],
        "org_name": get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "biz_type": get("ì‚¬ì—…êµ¬ë¶„"),
        "op_type": get("ìš´ì˜êµ¬ë¶„"),
        "gu": get("ìì¹˜êµ¬"),
        "address": [v if (pd.notna(v) and str(v).strip()) else w for v, w in zip(get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), get("ëŒ€í‘œì§€ë²ˆ"))],
        "households": _num(get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜")),
        "land_area_m2": _num(get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)")),
        "far": _pct_to_num(get("ìš©ì ë¥ ")),          # ìš©ì ë¥ (%) â†’ ìˆ«ì
        "floors": _floors_to_num(get("ì¸µìˆ˜")),      # ë‹¨ì¼ â€˜ì¸µìˆ˜â€™ê°€ ìˆì„ ë•Œ
        "status": get("ì§„í–‰ë‹¨ê³„"),                  # âœ… ì§„í–‰ë‹¨ê³„ ì¶”ê°€
        # â¬‡ï¸ ì§€ìƒ/ì§€í•˜ì¸µìˆ˜ ì§€ì› (ìˆìœ¼ë©´ í‘œì‹œìš©ìœ¼ë¡œ ì˜ˆì˜ê²Œ)
        "floors_up": _floors_to_num(get("ì§€ìƒì¸µìˆ˜")),
        "floors_down": _floors_to_num(get("ì§€í•˜ì¸µìˆ˜")),
    })

    # ì¸µìˆ˜ í‘œì‹œ ë¬¸ìì—´ (ì˜ˆ: "ì§€ìƒ 35 / ì§€í•˜ 3")
    def _fmt_floor(u, d):
        parts = []
        if pd.notna(u):
            parts.append(f"ì§€ìƒ {int(u)}")
        if pd.notna(d):
            parts.append(f"ì§€í•˜ {int(d)}")
        return " / ".join(parts)

    df["floors_display"] = [_fmt_floor(u, d) for u, d in zip(df["floors_up"], df["floors_down"])]

    # ìµœì¢… í‘œì‹œìš© ì¸µìˆ˜: ì§€ìƒ/ì§€í•˜ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ ë‹¨ì¼ ìˆ«ìì¸µì„ "Nì¸µ"ìœ¼ë¡œ
    df["floors_show"] = df["floors_display"].fillna("").astype(str).str.strip()
    mask_empty = df["floors_show"] == ""
    df.loc[mask_empty, "floors_show"] = df.loc[mask_empty, "floors"].apply(
        lambda x: f"{int(x)}ì¸µ" if pd.notna(x) else ""
    )

    # ë¬¸ìì—´ ì •ë¦¬
    df["apt_id"] = df["apt_id"].astype(str)
    df["name"] = df["name"].fillna("ë¬´ëª… ì •ë¹„êµ¬ì—­")
    for col in ["org_name","biz_type","op_type","gu","address","status"]:
        df[col] = df[col].fillna("").astype(str).str.strip()

    return df



@st.cache_data(show_spinner=False)
def get_projects_by_gu(gu: str) -> pd.DataFrame:
    raw = load_raw_csv()
    norm = normalize_schema(raw)
    return norm[norm["gu"] == gu].reset_index(drop=True)

# -------------------------------------------------------------
# ğŸ“ ì„œìš¸ì‹œ 25ê°œ ìì¹˜êµ¬ ë¦¬ìŠ¤íŠ¸ & ì¤‘ì‹¬ì¢Œí‘œ
# -------------------------------------------------------------
DISTRICTS = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬",
    "ë…¸ì›êµ¬","ë„ë´‰êµ¬","ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬",
    "ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬","ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]

GU_CENTER = {
    "ê°•ë‚¨êµ¬": (37.5172, 127.0473),
    "ê°•ë™êµ¬": (37.5301, 127.1238),
    "ê°•ë¶êµ¬": (37.6396, 127.0257),
    "ê°•ì„œêµ¬": (37.5509, 126.8495),
    "ê´€ì•…êµ¬": (37.4784, 126.9516),
    "ê´‘ì§„êµ¬": (37.5386, 127.0822),
    "êµ¬ë¡œêµ¬": (37.4955, 126.8876),
    "ê¸ˆì²œêµ¬": (37.4569, 126.8958),
    "ë…¸ì›êµ¬": (37.6543, 127.0565),
    "ë„ë´‰êµ¬": (37.6688, 127.0471),
    "ë™ëŒ€ë¬¸êµ¬": (37.5740, 127.0396),
    "ë™ì‘êµ¬": (37.5124, 126.9393),
    "ë§ˆí¬êµ¬": (37.5638, 126.9084),
    "ì„œëŒ€ë¬¸êµ¬": (37.5791, 126.9368),
    "ì„œì´ˆêµ¬": (37.4836, 127.0326),
    "ì„±ë™êµ¬": (37.5633, 127.0369),
    "ì„±ë¶êµ¬": (37.5894, 127.0167),
    "ì†¡íŒŒêµ¬": (37.5145, 127.1068),
    "ì–‘ì²œêµ¬": (37.5169, 126.8665),
    "ì˜ë“±í¬êµ¬": (37.5264, 126.8963),
    "ìš©ì‚°êµ¬": (37.5311, 126.9811),
    "ì€í‰êµ¬": (37.6176, 126.9227),
    "ì¢…ë¡œêµ¬": (37.5736, 126.9780),
    "ì¤‘êµ¬": (37.5636, 126.9976),
    "ì¤‘ë‘êµ¬": (37.6063, 127.0929),
}


def attach_latlon_by_gu_centroid(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["lat"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[0]) + np.random.normal(scale=0.004, size=len(df))
    df["lon"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[1]) + np.random.normal(scale=0.004, size=len(df))
    return df


# -------------------------------------------------------------
# ğŸ§­ ì‚¬ì´ë“œë°”
# -------------------------------------------------------------
st.sidebar.title("ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper")


# ì‚¬ì´ë“œë°” - êµ¬ ì„ íƒ
selected_gu = st.sidebar.selectbox("êµ¬ ì„ íƒ", DISTRICTS, index=0)

# âœ… ì„¸ì…˜ì— ì„ íƒ ì¸ë±ìŠ¤ ì´ˆê¸°í™”(ë§¨ ìœ„ í•œ ë²ˆ)
# - ì²« ì§„ì…: selected_row í‚¤ê°€ ì—†ìœ¼ë‹ˆ Noneìœ¼ë¡œ ì„¸íŒ…
# - ìì¹˜êµ¬ë¥¼ ë³€ê²½í–ˆì„ ë•Œ: ì´ì „ êµ¬ì™€ ë‹¤ë¥´ë©´ ì„ íƒì„ ë¦¬ì…‹
if "selected_row" not in st.session_state:
    st.session_state.selected_row = None
if "selected_gu_prev" not in st.session_state:
    st.session_state.selected_gu_prev = selected_gu

if st.session_state.selected_gu_prev != selected_gu:
    st.session_state.selected_row = None           # êµ¬ê°€ ë°”ë€Œë©´ ì„ íƒ ì´ˆê¸°í™”
    st.session_state.selected_gu_prev = selected_gu

st.sidebar.markdown(
    "<div class='small-muted'>êµ¬ ì„ íƒ ì‹œ, í•´ë‹¹ êµ¬ì˜ ì •ë¹„ì‚¬ì—… ë‹¨ì§€ ëª©ë¡ê³¼ ì§€ë„ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.</div>",
    unsafe_allow_html=True,
)

project_name = st.sidebar.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=f"{selected_gu} ì¬ê±´ì¶• ì‹œë‚˜ë¦¬ì˜¤")

# -------------------------------------------------------------
# ğŸ—ºï¸ 1-2ì‚¬ë¶„ë©´: ì§€ë„ + ë‹¨ì§€ ì„ íƒ
# -------------------------------------------------------------
col12_left, col12_right = st.columns([2.2, 1.4], gap="large")

with col12_left:
    st.markdown("### ğŸ—º 1-2ì‚¬ë¶„ë©´ Â· ì§€ë„ & ë‹¨ì§€ì„ íƒ")

    base_df = get_projects_by_gu(selected_gu)
    df_map = merge_projects_with_coords(selected_gu)


    # ì§€ë„ ìë¦¬ë§Œ ë¨¼ì € í™•ë³´ (í•„í„°/ì„ íƒ ì ìš© í›„ ì•„ë˜ì—ì„œ ì‹¤ì œ ì°¨íŠ¸ ë Œë”)
    map_slot = st.empty()

    if df_map.empty:
        st.warning("âš ï¸ í•´ë‹¹ êµ¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()


# ---------------------------
# ğŸ“‹ ë‹¨ì§€ í…Œì´ë¸” + í•„í„° UI
# ---------------------------
with st.expander("ğŸ” ë°ì´í„° ì†ŒìŠ¤ í™•ì¸(ì„ì‹œ)", expanded=False):
    # 1) ì›ë³¸ CSV ê·¸ëŒ€ë¡œ ë³´ê¸°
    raw = load_raw_csv()
    cols_raw = ["ìì¹˜êµ¬", "ì •ë¹„êµ¬ì—­ëª…ì¹­", "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…", "ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜", "ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"]
    exist_cols = [c for c in cols_raw if c in raw.columns]
    st.caption(f"ì›ë³¸: {CSV_PATH.name} Â· í‘œì‹œì—´: {', '.join(exist_cols)}")
    try:
        st.dataframe(
            raw[exist_cols][raw["ìì¹˜êµ¬"] == selected_gu].head(20),
            use_container_width=True
        )
    except Exception:
        st.dataframe(raw[exist_cols].head(20), use_container_width=True)

    # 2) í˜„ì¬ í™”ë©´ì— ì“°ëŠ” df_map ê°’ ë³´ê¸°
    st.caption("í˜„ì¬ í‘œì‹œê°’(df_map)")
    st.dataframe(
        df_map[["gu", "address_display", "name", "households", "land_area_m2"]].head(20),
        use_container_width=True
    )

    # 3) ì›ë³¸ê°’ê³¼ df_map ê°’ ìë™ ë¹„êµ (name+gu ê¸°ì¤€)
    def _coalesce(a, b):
        a = "" if a is None else str(a).strip()
        b = "" if b is None else str(b).strip()
        return a if a else b

    raw_norm = pd.DataFrame({
        "gu": raw.get("ìì¹˜êµ¬"),
        "name_raw": [
            _coalesce(n, m) for n, m in zip(
                raw.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"),
                raw.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…")
            )
        ],
        "households_src": pd.to_numeric(raw.get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜"), errors="coerce"),
        "land_area_m2_src": pd.to_numeric(raw.get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"), errors="coerce"),
    })

    comp = df_map.merge(
        raw_norm, left_on=["name","gu"], right_on=["name_raw","gu"], how="left"
    )

    # ì •ìˆ˜/ì‹¤ìˆ˜ ë¹„êµ: ë©´ì ì€ ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ë¥¼ í—ˆìš©
    hh_match  = (comp["households"].fillna(-1).astype(float) == comp["households_src"].fillna(-1).astype(float))
    area_match = np.isclose(
        comp["land_area_m2"].astype(float),
        comp["land_area_m2_src"].astype(float),
        rtol=1e-6, atol=1e-6, equal_nan=True
    )

    comp["households_match"] = hh_match
    comp["land_area_match"]  = area_match

    total = len(comp)
    hh_ok  = int(hh_match.sum())
    ar_ok  = int(area_match.sum())

    st.write(
        f"âœ… ì„¸ëŒ€ìˆ˜ ì¼ì¹˜: **{hh_ok}/{total}**  Â·  "
        f"âœ… ë©´ì  ì¼ì¹˜: **{ar_ok}/{total}**"
    )

    bad = comp[~(hh_match & area_match)][
        ["gu","address_display","name","households","households_src","land_area_m2","land_area_m2_src"]
    ]
    if not bad.empty:
        st.warning("ë¶ˆì¼ì¹˜ ìƒ˜í”Œ(ìµœëŒ€ 20ê±´):")
        st.dataframe(bad.head(20), use_container_width=True)



st.markdown("**ë‹¨ì§€ ëª©ë¡**")

# âœ… í…Œì´ë¸”ì— ì“¸ ì»¬ëŸ¼ êµ¬ì„±
# âœ… í…Œì´ë¸”ì— ì“¸ ì»¬ëŸ¼ êµ¬ì„± (ìš©ì ë¥ /ì¸µìˆ˜/ì§„í–‰ë‹¨ê³„ í¬í•¨)
df_list = df_map[[
    "apt_id",
    "address_display",
    "org_name", "biz_type", "op_type",
    "status",            # ì§„í–‰ë‹¨ê³„
    "households", "land_area_m2",
    "far",               # ìš©ì ë¥ (%)
    "floors_show",       # ì¸µìˆ˜(ì§€ìƒ/ì§€í•˜ ìˆìœ¼ë©´ ì˜ˆì˜ê²Œ, ì—†ìœ¼ë©´ Nì¸µ)
]].copy()

# ìˆ«ìí˜• ë³´ì • (í‘œì‹œí˜• í…ìŠ¤íŠ¸ì¸ floors_showëŠ” ê·¸ëŒ€ë¡œ)
df_list["households"]   = pd.to_numeric(df_list["households"], errors="coerce")
df_list["land_area_m2"] = pd.to_numeric(df_list["land_area_m2"], errors="coerce")
df_list["far"]          = pd.to_numeric(df_list["far"], errors="coerce")

# ===== í•„í„° ì˜ì—­ =====
fcol1, fcol2, fcol3, fcol4 = st.columns([1.6, 1.4, 1.6, 1.2])

with fcol1:
    kw = st.text_input("ê²€ìƒ‰ì–´(ì£¼ì†Œ/ì¡°í•©ëª…/í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ) ê°œí¬, ëª©ë™, ì¡°í•©")

# âœ… ë“œë¡­ë‹¤ìš´ ë²”ì£¼ ì •ì˜
HH_BUCKETS = {
    "ì „ì²´": (None, None),
    "~ 300ì„¸ëŒ€": (0, 300),
    "301â€“500ì„¸ëŒ€": (301, 500),
    "501â€“1,000ì„¸ëŒ€": (501, 1000),
    "1,001â€“2,000ì„¸ëŒ€": (1001, 2000),
    "2,001ì„¸ëŒ€ ì´ìƒ": (2001, None),
}

AREA_BUCKETS = {
    "ì „ì²´": (None, None),
    "~ 30,000 mÂ²": (0, 30000),
    "30,001â€“50,000 mÂ²": (30001, 50000),
    "50,001â€“100,000 mÂ²": (50001, 100000),
    "100,001â€“200,000 mÂ²": (100001, 200000),
    "200,001 mÂ² ì´ìƒ": (200001, None),
}

with fcol2:
    hh_choice = st.selectbox("ì„¸ëŒ€ìˆ˜ ë²”ì£¼", list(HH_BUCKETS.keys()), index=0)

with fcol3:
    la_choice = st.selectbox("ë©´ì  ë²”ì£¼(mÂ²)", list(AREA_BUCKETS.keys()), index=0)

with fcol4:
    hide_zero = st.checkbox("0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°", value=True)


# ===== í•„í„° ì ìš© =====
mask = pd.Series(True, index=df_list.index)

if kw.strip():
    _kw = kw.strip().lower()
    mask &= (
        df_list["address_display"].fillna("").str.lower().str.contains(_kw) |
        df_list["org_name"].fillna("").str.lower().str.contains(_kw)
    )

# âœ… ë“œë¡­ë‹¤ìš´ ì„ íƒê°’ì„ ì‹¤ì œ í•„í„°ë¡œ ì ìš©
hh_lo, hh_hi = HH_BUCKETS[hh_choice]
la_lo, la_hi = AREA_BUCKETS[la_choice]

# ì„¸ëŒ€ìˆ˜ í•„í„°
col_series = df_list["households"].fillna(-1)
if hh_lo is not None:
    mask &= col_series >= hh_lo
if hh_hi is not None:
    mask &= col_series <= hh_hi

# ë©´ì  í•„í„°
col_series = df_list["land_area_m2"].fillna(-1)
if la_lo is not None:
    mask &= col_series >= la_lo
if la_hi is not None:
    mask &= col_series <= la_hi

# 0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°
if hide_zero:
    mask &= df_list["households"].fillna(0) > 0
    mask &= df_list["land_area_m2"].fillna(0) > 0

filtered = df_list[mask].reset_index().rename(columns={"index": "orig_index"})

# ===== ì •ë ¬ ì˜µì…˜ =====
scol1, scol2 = st.columns([1.2, 1.2])
with scol1:
    sort_key = st.selectbox("ì •ë ¬ ê¸°ì¤€",
        ["ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ", "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ", "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ", "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ", "ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ"], index=0)
with scol2:
    topn = st.selectbox("í‘œì‹œ ê°œìˆ˜", [10, 20, 50, 100, "ì „ì²´"], index=1)

if sort_key == "ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=False, na_position="last")
elif sort_key == "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=True, na_position="last")
elif sort_key == "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=False, na_position="last")
elif sort_key == "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=True, na_position="last")
elif sort_key == "ì£¼ì†Œ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("address_display", ascending=True, na_position="last")

if topn != "ì „ì²´":
    filtered = filtered.head(int(topn))

# ===== í…Œì´ë¸” í‘œì‹œ (ìš”ì²­í•œ ì»¬ëŸ¼/ë¼ë²¨ë¡œ)
show_df = filtered[[
    "orig_index",
    "address_display", "org_name", "biz_type", "op_type",
    "status",                    # ì§„í–‰ë‹¨ê³„
    "households", "land_area_m2",
    "far", "floors_show",        # ìš©ì ë¥ , ì¸µìˆ˜
]].copy().rename(columns={
    "address_display": "ì£¼ì†Œ",
    "org_name": "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…",
    "biz_type": "ì‚¬ì—…êµ¬ë¶„",
    "op_type": "ìš´ì˜êµ¬ë¶„",
    "status": "ì§„í–‰ë‹¨ê³„",
    "households": "ê³„íšì„¸ëŒ€ìˆ˜",
    "land_area_m2": "ë©´ì ",
    "far": "ìš©ì ë¥ (%)",
    "floors_show": "ì¸µìˆ˜",        # í‘œì‹œìš© í…ìŠ¤íŠ¸ë¥¼ â€˜ì¸µìˆ˜â€™ ë¼ë²¨ë¡œ
})

# âœ… í‘œ ë‚´ë¶€ì—ì„œ ì§ì ‘ ì„ íƒí•˜ëŠ” 'ì„ íƒ' ì»¬ëŸ¼ ì¶”ê°€(ë‹¨ì¼ ì„ íƒ ê°•ì œ ë¡œì§ì€ ê¸°ì¡´ ê·¸ëŒ€ë¡œ ìœ ì§€)
show_df.insert(1, "ì„ íƒ", False)

curr_ids = show_df["orig_index"].tolist()
if (st.session_state.selected_row is None) or (st.session_state.selected_row not in curr_ids):
    st.session_state.selected_row = int(curr_ids[0]) if curr_ids else None
show_df.loc[show_df["orig_index"] == st.session_state.selected_row, "ì„ íƒ"] = True


edited = st.data_editor(
    show_df,
    use_container_width=True,
    hide_index=True,
    disabled=[
        "orig_index", "ì£¼ì†Œ", "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…", "ì‚¬ì—…êµ¬ë¶„", "ìš´ì˜êµ¬ë¶„",
        "ì§„í–‰ë‹¨ê³„", "ê³„íšì„¸ëŒ€ìˆ˜", "ë©´ì ", "ìš©ì ë¥ (%)", "ì¸µìˆ˜"   # ë¹„í¸ì§‘
    ],
    column_config={
        "orig_index": st.column_config.NumberColumn("ì›ë³¸ì¸ë±ìŠ¤", help="ë‚´ë¶€ ì„ íƒìš©", width="small"),
        "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ì´ í–‰ì„ ì„ íƒ"),
        "ì£¼ì†Œ": st.column_config.TextColumn("ì£¼ì†Œ"),
        "ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…": st.column_config.TextColumn("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"),
        "ì‚¬ì—…êµ¬ë¶„": st.column_config.TextColumn("ì‚¬ì—…êµ¬ë¶„"),
        "ìš´ì˜êµ¬ë¶„": st.column_config.TextColumn("ìš´ì˜êµ¬ë¶„"),
        "ì§„í–‰ë‹¨ê³„": st.column_config.TextColumn("ì§„í–‰ë‹¨ê³„"),
        "ê³„íšì„¸ëŒ€ìˆ˜": st.column_config.NumberColumn("ê³„íšì„¸ëŒ€ìˆ˜", format="%,d"),
        "ë©´ì ": st.column_config.NumberColumn("ë©´ì (mÂ²)", format="%,d"),
        "ìš©ì ë¥ (%)": st.column_config.NumberColumn("ìš©ì ë¥ (%)", format=",.1f"),
        "ì¸µìˆ˜": st.column_config.TextColumn("ì¸µìˆ˜"),  # ì§€ìƒ/ì§€í•˜ í‘œê¸°ê°€ ë“¤ì–´ê°ˆ ìˆ˜ ìˆì–´ TextColumn
    },
    key=f"project_table_{selected_gu}",
)

# âœ… ë‹¨ì¼ ì„ íƒ ê°•ì œ ë¡œì§
prev = st.session_state.selected_row
sel_list = [int(x) for x in edited.loc[edited["ì„ íƒ"] == True, "orig_index"].tolist()]

if len(sel_list) == 0:
    # ì²´í¬ë¥¼ ëª¨ë‘ í•´ì œí•œ ê²½ìš°: ì´ì „ ì„ íƒì´ ëª©ë¡ì— ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ì²« í–‰ìœ¼ë¡œ
    if prev in curr_ids:
        st.session_state.selected_row = int(prev)
    elif curr_ids:
        st.session_state.selected_row = int(curr_ids[0])
elif len(sel_list) == 1:
    st.session_state.selected_row = int(sel_list[0])
else:
    # ì—¬ëŸ¬ ê°œ ì²´í¬ëœ ê²½ìš° â†’ ìƒˆë¡œ ì²´í¬ëœ(ì´ì „ ì„ íƒì´ ì•„ë‹Œ) ì²« í›„ë³´ë¡œ ê°•ì œ ì „í™˜
    if prev in sel_list:
        new_choice = next((x for x in sel_list if x != prev), sel_list[0])
    else:
        new_choice = sel_list[0]
    st.session_state.selected_row = int(new_choice)
    # ë‹¤ìŒ ë Œë”ì—ì„œ í•œ ê°œë§Œ ì²´í¬ëœ ìƒíƒœë¡œ ë³´ì´ë„ë¡ ì¦‰ì‹œ ì¬ë Œë”
    st.rerun()

# ìµœì¢… ì„ íƒê°’ í™•ì •
if st.session_state.selected_row is None:
    st.info("ì„ íƒëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
selected_row = st.session_state.selected_row


# âœ… ì§€ë„ ë°ì´í„°/ë ˆì´ì–´ ë§Œë“¤ê¸° (selected_row í™•ì • ì´í›„)
filtered_indices = edited["orig_index"].tolist()
map_data = df_map.loc[filtered_indices].reset_index(drop=True)

sel_lat = float(df_map.loc[selected_row, "lat"])
sel_lon = float(df_map.loc[selected_row, "lon"])
view_state = pdk.ViewState(latitude=sel_lat, longitude=sel_lon, zoom=12.5)

layer_points = pdk.Layer(
    "ScatterplotLayer",
    data=map_data,
    get_position='[lon, lat]',
    get_radius=60,
    pickable=True,
    get_fill_color=[255, 140, 0, 160],
    get_line_color=[255, 255, 255],
    line_width_min_pixels=0.5,
)

highlight_row = df_map.loc[[selected_row]].assign(_selected=True)
layer_highlight = pdk.Layer(
    "ScatterplotLayer",
    data=highlight_row,
    get_position='[lon, lat]',
    get_radius=150,
    pickable=False,
    get_fill_color=[0, 200, 255, 220],
    get_line_color=[0, 0, 0],
    line_width_min_pixels=1.2,
)

tooltip = {
    "html": "<b>{address_display}</b><br/>ìì¹˜êµ¬: {gu}<br/>ì„¸ëŒ€ìˆ˜: {households}<br/>êµ¬ì—­ë©´ì (mÂ²): {land_area_m2}",
    "style": {"backgroundColor": "#0f172a", "color": "white"},
}

if map_data.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_highlight], initial_view_state=view_state, tooltip=tooltip))
else:
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_points, layer_highlight], initial_view_state=view_state, tooltip=tooltip))


# --- ì§€ë„ ë Œë” (ì™¼ìª½ ì»¬ëŸ¼ì—ì„œ ì‹¤í–‰) ---
with col12_left:
    if map_data.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
        map_slot.pydeck_chart(
            pdk.Deck(
                layers=[layer_highlight],

                initial_view_state=view_state,
                tooltip=tooltip,
            )
        )
    else:
        map_slot.pydeck_chart(
            pdk.Deck(
                layers=[layer_points, layer_highlight],
                initial_view_state=view_state,
                tooltip=tooltip,
            )
        )

with col12_right:
    st.markdown("### ğŸ§¾ 1ì‚¬ë¶„ë©´ Â· ì‹ ì„¤ì¡°ê±´ ì…ë ¥")
    current = df_map.loc[selected_row]
    with st.container(border=True):
        st.markdown("**ê¸°ì¡´ ë‹¨ì§€ ì •ë³´**")
        st.markdown(
            f"- ì£¼ì†Œ: **{current['address_display']}**\n\n"
            f"- ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…: **{current['org_name']}**\n\n"
            f"- ìì¹˜êµ¬: **{current['gu']}**\n\n"
            f"- ê³„íš ì„¸ëŒ€ìˆ˜: **{int(current['households']) if pd.notna(current['households']) else 'ë¯¸ìƒ'} ì„¸ëŒ€**\n\n"
            f"- ì •ë¹„êµ¬ì—­ë©´ì : **{int(current['land_area_m2']):,} mÂ²**"
        )

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
    desired_py = st.number_input("ì›í•˜ëŠ” ì „ìš© í‰í˜•(í‰)", min_value=15, max_value=60, value=34, step=1)


    # --- ê¸°ì¡´ ì½”ë“œ êµì²´ ---
    # desired_households = st.number_input("ì›í•˜ëŠ” ì„¸ëŒ€ìˆ˜(ì‹ ê·œ)", min_value=100, max_value=3000,
    #                                      value=int(current["households"]) + 200 if pd.notna(current["households"]) else 500, step=50)

    def _clamp(v, lo, hi):
        return max(lo, min(hi, v))


    min_val, max_val = 100, 3000
    base_households = int(current["households"]) if pd.notna(current["households"]) else 500
    default_desired = base_households + 200

    desired_households = st.number_input(
        "ì›í•˜ëŠ” ì„¸ëŒ€ìˆ˜(ì‹ ê·œ)",
        min_value=min_val,
        max_value=max_val,
        value=_clamp(default_desired, min_val, max_val),
        step=50,
    )

    expected_pop_increase_ratio = st.slider("ì˜ˆìƒ ì¸êµ¬ì¦ê°€ìœ¨(%)", 0, 100, 15, 5)
    new_bus_count = st.slider("ì‹ ì„¤ ë²„ìŠ¤ ëŒ€ìˆ˜", 0, 20, 2, 1)
    bus_capacity = st.number_input("ë²„ìŠ¤ 1ëŒ€ ìˆ˜ìš© ì¸ì›(ëª…)", min_value=30, max_value=120, value=70, step=5)



        # ê·¸ë˜í”„ ë Œë” ìƒëµ
    # else: ì´ë¯¸ CSVê°€ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©

# 3â€“4ì‚¬ë¶„ë©´ ë ˆì´ì•„ì›ƒ ì»¬ëŸ¼
col3, col4 = st.columns([1.6, 1.4], gap="large")


# === 3ì‚¬ë¶„ë©´: í˜¼ì¡ë„ ê·¸ë˜í”„ ===

# 3ì‚¬ë¶„ë©´ ì„¹ì…˜ ì‹œì‘ ì „ì— CSV ë³´ì¥
with st.spinner("êµí†µ ê¸°ì¤€ë…„ë„ ë°ì´í„° ì¤€ë¹„ ì¤‘..."):
    if TRAFFIC_XLSX_PATH.exists():
        ensure_speed_csv(TRAFFIC_XLSX_PATH, TRAFFIC_CSV_PATH)  # âœ… ì´ë¦„ ìˆ˜ì •
    elif not TRAFFIC_CSV_PATH.exists():
        st.warning(f"ê¸°ì¤€ CSVê°€ ì—†ìŠµë‹ˆë‹¤: {TRAFFIC_CSV_PATH.name}\n"
                   f"â†’ data í´ë”ì— {TRAFFIC_XLSX_PATH.name} ë¥¼ ë„£ìœ¼ë©´ ìë™ ë³€í™˜ë©ë‹ˆë‹¤.")



# ===
sel_lat = float(current.get("lat", 37.5667))
sel_lon = float(current.get("lon", 126.9784))

with col3:
    st.markdown("### ğŸš¦ 3ì‚¬ë¶„ë©´ Â· ì£¼ë³€ ë„ë¡œ í˜¼ì¡ë„ (ê¸°ì¤€ë…„ë„)")


    radius = st.slider("ë°˜ê²½(m)", 500, 3000, 1000, step=250, key="radius_m")
    max_links = st.slider("í‘œì‹œ ë§í¬ ìˆ˜", 5, 20, 10, step=1, key="max_links")

    if TRAFFIC_CSV_PATH.exists() and SHP_PATH.exists():
        if _HAS_PLOT_SPEED:
            chart_or_fig, df_plot = plot_speed(
                csv_path=TRAFFIC_CSV_PATH,
                shp_path=SHP_PATH,
                center_lon=sel_lon,
                center_lat=sel_lat,
                radius_m=radius,
                max_links=max_links,
                renderer="altair",  # Altair ë Œë”ëŸ¬ ì‚¬ìš©
                chart_height=700,  # â† ì—¬ê¸°ì„œ ì„¸ë¡œ ê¸¸ì´ ì¡°ì ˆ
            )

            # Altair Chartì´ë©´ st.altair_chart()ë¡œ í‘œì‹œ
            if isinstance(chart_or_fig, alt.Chart):
                # Streamlit í…Œë§ˆê°€ Altair configë¥¼ ë®ì–´ì“°ì§€ ì•Šê²Œ
                st.altair_chart(chart_or_fig, use_container_width=True, theme=None)
            else:
                st.pyplot(chart_or_fig, use_container_width=True)

        else:
            # utilsì— plot_speedê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨ ì‹œ, ê¸°ì¡´ í•¨ìˆ˜ë¡œ ì•ˆì „í•˜ê²Œ í‘œì‹œ
            fig, df_plot = plot_nearby_speed_from_csv(
                csv_path=TRAFFIC_CSV_PATH,
                shp_path=SHP_PATH,
                center_lon=sel_lon,
                center_lat=sel_lat,
                radius_m=radius,
                max_links=max_links,
            )
            st.pyplot(fig, use_container_width=True)

        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(
                df_plot.sort_values(["its_link_id", "hour"]).head(300),
                use_container_width=True
            )
    else:
        st.info("êµí†µ CSV ë˜ëŠ” SHPê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")


# === (ê°„ë‹¨ ì˜ˆì¸¡) í˜¼ì¡ë„ ì§€ìˆ˜ ì‚°ì¶œ: 4ì‚¬ë¶„ë©´ KPIìš© ===
baseline_congestion = float(np.random.uniform(45, 65))
people_per_household = 2.3

delta_households = max(
    0,
    (desired_households - int(current["households"])) if pd.notna(current["households"]) else desired_households
)
added_population = delta_households * people_per_household * (1 + expected_pop_increase_ratio / 100)

alpha, beta = 0.004, 0.0006
congestion_delta = alpha * added_population - beta * (new_bus_count * bus_capacity)
predicted_congestion = max(0.0, min(100.0, baseline_congestion + congestion_delta))




# -------------------------------------------------------------
# ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼
# -------------------------------------------------------------
with col4:
    st.markdown("### ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼ & ë¦¬í¬íŠ¸")

    price_per_py = st.number_input("í‰ë‹¹ ë¶„ì–‘ê°€/ë§¤ë§¤ê°€(ë§Œì›)", 1000, 100000, 4800, 100)
    cost_per_py = st.number_input("í‰ë‹¹ ì´ë¹„ìš©(ë§Œì›)", 500, 80000, 3100, 100)

    unit_py = desired_py
    margin_per_unit_million = (price_per_py - cost_per_py) * unit_py
    expected_margin_billion = (margin_per_unit_million * desired_households) / 10000

    kcol1, kcol2, kcol3 = st.columns(3)
    with kcol1:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì˜ˆìƒ ìˆ˜ìµ(ì´)</div><div class='kpi-value'>{expected_margin_billion:.1f} ì‹­ì–µ</div></div>", unsafe_allow_html=True)
    with kcol2:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>í˜¼ì¡ë„ ì§€ìˆ˜(ì˜ˆì¸¡)</div><div class='kpi-value'>{predicted_congestion:.1f}</div></div>", unsafe_allow_html=True)
    with kcol3:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì‹ ê·œ ì„¸ëŒ€ìˆ˜</div><div class='kpi-value'>{desired_households:,} ì„¸ëŒ€</div></div>", unsafe_allow_html=True)
