# -------------------------------------------------------------
# ğŸ— AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ (ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper)
# -------------------------------------------------------------
# ğŸ“Š CSV ê¸°ë°˜ ë°ì´í„° ë°˜ì˜ ë²„ì „
# -------------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import altair as alt
from datetime import datetime
from pathlib import Path

# ğŸ”¤ ì•ˆì „í•œ CSV ë¡œë”: ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
def smart_read_csv(path, encodings=("utf-8-sig", "cp949", "euc-kr", "utf-8", "latin1")):
    import pandas as pd
    last_err = None
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            try:
                import streamlit as st
                st.caption(f"ğŸ“„ Loaded {path.name} with encoding = **{enc}**")
            except Exception:
                pass
            return df
        except UnicodeDecodeError as e:
            last_err = e
            continue
    # ìµœí›„ ìˆ˜ë‹¨: errors='replace' ë¡œë¼ë„ ì½ê¸°
    try:
        df = pd.read_csv(path, encoding="utf-8", errors="replace")
        return df
    except Exception:
        raise last_err or Exception(f"Failed to read {path} with tried encodings.")



# -------------------------------------------------------------
# âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ ìë™ ì„¤ì •
# -------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent.parent
CSV_PATH = BASE_DIR / "data" / "seoul_redev_projects.csv"
CSV_ENCODING = "cp949"

# -------------------------------------------------------------
# ğŸ“¦ ì¢Œí‘œ CSV ë³‘í•© ìœ í‹¸
# -------------------------------------------------------------
COORD_CSV_PATH = BASE_DIR / "data" / "ì„œìš¸ì‹œ_ì¬ê°œë°œì¬ê±´ì¶•_ì¢Œí‘œí¬í•¨.csv"
COORD_ENCODING = "cp949"

@st.cache_data(show_spinner=False)
def load_coords() -> pd.DataFrame:
    df = smart_read_csv(COORD_CSV_PATH)
    df["lat"] = pd.to_numeric(df.get("lat"), errors="coerce")
    df["lon"] = pd.to_numeric(df.get("lon"), errors="coerce")

    def _coalesce(*vals):
        for v in vals:
            if pd.notna(v) and str(v).strip():
                return v
        return None

    df_norm = pd.DataFrame({
        "apt_id": df.get("ì‚¬ì—…ë²ˆí˜¸").astype(str) if "ì‚¬ì—…ë²ˆí˜¸" in df.columns else None,
        "name": [_coalesce(n, m) for n, m in zip(df.get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), df.get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))],
        "gu": df.get("ìì¹˜êµ¬"),
        "address": [_coalesce(a, b) for a, b in zip(df.get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), df.get("ëŒ€í‘œì§€ë²ˆ"))],
        "lat": df["lat"],
        "lon": df["lon"],
    })
    df_norm["apt_id"] = df_norm["apt_id"].fillna("").astype(str)
    df_norm["name"] = df_norm["name"].fillna("")
    df_norm["address"] = df_norm["address"].fillna("")
    return df_norm


# ì„œìš¸ ìì¹˜êµ¬ ì¤‘ì‹¬ì¢Œí‘œ (ê°„ì´ê°’)
GU_CENTER = {
    "ê°•ë‚¨êµ¬": (37.5172, 127.0473),
    "ì„œì´ˆêµ¬": (37.4836, 127.0326),
    "ì†¡íŒŒêµ¬": (37.5145, 127.1068),
    "ì˜ë“±í¬êµ¬": (37.5264, 126.8963),
    "ë§ˆí¬êµ¬": (37.5638, 126.9084),
    "ì„±ë™êµ¬": (37.5633, 127.0369),
    "ê´€ì•…êµ¬": (37.4784, 126.9516),
    "êµ¬ë¡œêµ¬": (37.4955, 126.8876),
}


@st.cache_data(show_spinner=False)
def merge_projects_with_coords(gu: str) -> pd.DataFrame:
    # 1) ì›ë³¸ ë¡œë“œ + ìŠ¤í‚¤ë§ˆ í†µì¼
    raw = load_raw_csv()
    proj = normalize_schema(raw)              # âœ… apt_id, name, gu, address, households, land_area_m2 ìƒì„±
    proj = proj[proj["gu"] == gu].copy()

    # 2) ì¢Œí‘œ ë¡œë“œ
    coords = load_coords()
    coords = coords[coords["gu"] == gu].copy()

    # 3) ë³‘í•©: ìš°ì„  nameâ†’(ë³´ê°• í•„ìš” ì‹œ) apt_id/address í‚¤ í™•ì¥ ê°€ëŠ¥
    out = proj.merge(coords[["name","lat","lon"]], on="name", how="left")

    # 4) ì¢Œí‘œ ê²°ì¸¡ ë³´ì • (êµ¬ ì¤‘ì‹¬ + ì§€í„°)
    missing = out["lat"].isna() | out["lon"].isna()
    base_lat, base_lon = GU_CENTER.get(gu, (37.55, 127.0))
    rng = np.random.default_rng(42)
    jitter = lambda n: rng.normal(0, 0.002, n)  # â‰ˆ 200m ë¶„ì‚°
    if missing.any():
        n = int(missing.sum())
        out.loc[missing, "lat"] = base_lat + jitter(n)
        out.loc[missing, "lon"] = base_lon + jitter(n)
    out["has_geo"] = ~missing

    return out.reset_index(drop=True)


# -------------------------------------------------------------
# âš™ï¸ Streamlit ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------------
st.set_page_config(
    page_title="AIoT ìŠ¤ë§ˆíŠ¸ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ | ì¬ê±´ì¶• Helper",
    layout="wide",
)

STYLE = """
<style>
.small-muted { color: #7a7a7a; font-size: 0.9rem; }
.kpi-card { padding: 16px; border-radius: 16px; background: #111827; border: 1px solid #1f2937; }
.kpi-title { font-size: 0.9rem; color: #9ca3af; margin-bottom: 8px; }
.kpi-value { font-size: 1.4rem; font-weight: 700; color: #e5e7eb; }
.section-title { font-size: 1.1rem; font-weight: 700; margin-bottom: 8px; }
hr.soft { border: none; height: 1px; background: #1f2937; margin: 16px 0; }
</style>
"""
st.markdown(STYLE, unsafe_allow_html=True)

# -------------------------------------------------------------
# ğŸ§¾ CSV ë¡œë“œ & ì „ì²˜ë¦¬
# -------------------------------------------------------------
@st.cache_data(show_spinner=False)
# -------------------------------------------------------------
# ğŸ§¾ CSV ë¡œë“œ & ì „ì²˜ë¦¬
# -------------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_raw_csv() -> pd.DataFrame:
    return smart_read_csv(CSV_PATH)  # âœ… ì¸ì½”ë”© ìë™ ê°ì§€ ì‚¬ìš©

def _coalesce(*vals):
    for v in vals:
        if pd.notna(v) and str(v).strip():
            return v
    return None

def normalize_schema(df_raw: pd.DataFrame) -> pd.DataFrame:
    c = df_raw.columns
    get = lambda name: df_raw[name] if name in c else pd.Series([None]*len(df_raw))

    df = pd.DataFrame({
        "apt_id": get("ì‚¬ì—…ë²ˆí˜¸"),
        "name": [_coalesce(n, m) for n, m in zip(get("ì •ë¹„êµ¬ì—­ëª…ì¹­"), get("ì¶”ì§„ìœ„ì›íšŒ/ì¡°í•©ëª…"))],
        "gu": get("ìì¹˜êµ¬"),
        "address": [_coalesce(a, b) for a, b in zip(get("ì •ë¹„êµ¬ì—­ìœ„ì¹˜"), get("ëŒ€í‘œì§€ë²ˆ"))],
        "households": pd.to_numeric(get("ë¶„ì–‘ì„¸ëŒ€ì´ìˆ˜"), errors="coerce"),
        "land_area_m2": pd.to_numeric(get("ì •ë¹„êµ¬ì—­ë©´ì (ã¡)"), errors="coerce"),
    })
    df["apt_id"] = df["apt_id"].astype(str)
    df["name"] = df["name"].fillna("ë¬´ëª… ì •ë¹„êµ¬ì—­")
    df["gu"] = df["gu"].fillna("ë¯¸ìƒ")
    df["address"] = df["address"].fillna("")
    return df

@st.cache_data(show_spinner=False)
def get_projects_by_gu(gu: str) -> pd.DataFrame:
    raw = load_raw_csv()
    norm = normalize_schema(raw)
    return norm[norm["gu"] == gu].reset_index(drop=True)

# -------------------------------------------------------------
# ğŸ“ ì„œìš¸ì‹œ 25ê°œ ìì¹˜êµ¬ ë¦¬ìŠ¤íŠ¸ & ì¤‘ì‹¬ì¢Œí‘œ
# -------------------------------------------------------------
DISTRICTS = [
    "ê°•ë‚¨êµ¬","ê°•ë™êµ¬","ê°•ë¶êµ¬","ê°•ì„œêµ¬","ê´€ì•…êµ¬","ê´‘ì§„êµ¬","êµ¬ë¡œêµ¬","ê¸ˆì²œêµ¬",
    "ë…¸ì›êµ¬","ë„ë´‰êµ¬","ë™ëŒ€ë¬¸êµ¬","ë™ì‘êµ¬","ë§ˆí¬êµ¬","ì„œëŒ€ë¬¸êµ¬","ì„œì´ˆêµ¬","ì„±ë™êµ¬",
    "ì„±ë¶êµ¬","ì†¡íŒŒêµ¬","ì–‘ì²œêµ¬","ì˜ë“±í¬êµ¬","ìš©ì‚°êµ¬","ì€í‰êµ¬","ì¢…ë¡œêµ¬","ì¤‘êµ¬","ì¤‘ë‘êµ¬"
]

GU_CENTER = {
    "ê°•ë‚¨êµ¬": (37.5172, 127.0473),
    "ê°•ë™êµ¬": (37.5301, 127.1238),
    "ê°•ë¶êµ¬": (37.6396, 127.0257),
    "ê°•ì„œêµ¬": (37.5509, 126.8495),
    "ê´€ì•…êµ¬": (37.4784, 126.9516),
    "ê´‘ì§„êµ¬": (37.5386, 127.0822),
    "êµ¬ë¡œêµ¬": (37.4955, 126.8876),
    "ê¸ˆì²œêµ¬": (37.4569, 126.8958),
    "ë…¸ì›êµ¬": (37.6543, 127.0565),
    "ë„ë´‰êµ¬": (37.6688, 127.0471),
    "ë™ëŒ€ë¬¸êµ¬": (37.5740, 127.0396),
    "ë™ì‘êµ¬": (37.5124, 126.9393),
    "ë§ˆí¬êµ¬": (37.5638, 126.9084),
    "ì„œëŒ€ë¬¸êµ¬": (37.5791, 126.9368),
    "ì„œì´ˆêµ¬": (37.4836, 127.0326),
    "ì„±ë™êµ¬": (37.5633, 127.0369),
    "ì„±ë¶êµ¬": (37.5894, 127.0167),
    "ì†¡íŒŒêµ¬": (37.5145, 127.1068),
    "ì–‘ì²œêµ¬": (37.5169, 126.8665),
    "ì˜ë“±í¬êµ¬": (37.5264, 126.8963),
    "ìš©ì‚°êµ¬": (37.5311, 126.9811),
    "ì€í‰êµ¬": (37.6176, 126.9227),
    "ì¢…ë¡œêµ¬": (37.5736, 126.9780),
    "ì¤‘êµ¬": (37.5636, 126.9976),
    "ì¤‘ë‘êµ¬": (37.6063, 127.0929),
}


def attach_latlon_by_gu_centroid(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["lat"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[0]) + np.random.normal(scale=0.004, size=len(df))
    df["lon"] = df["gu"].map(lambda g: GU_CENTER.get(g, (37.55, 127.0))[1]) + np.random.normal(scale=0.004, size=len(df))
    return df


# -------------------------------------------------------------
# ğŸ§­ ì‚¬ì´ë“œë°”
# -------------------------------------------------------------
st.sidebar.title("ì¬ê±´ì¶• ì˜ì‚¬ê²°ì • Helper")
selected_gu = st.sidebar.selectbox("êµ¬ ì„ íƒ", DISTRICTS, index=0)
st.sidebar.markdown(
    "<div class='small-muted'>êµ¬ ì„ íƒ ì‹œ, í•´ë‹¹ êµ¬ì˜ ì •ë¹„ì‚¬ì—… ë‹¨ì§€ ëª©ë¡ê³¼ ì§€ë„ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.</div>",
    unsafe_allow_html=True,
)

project_name = st.sidebar.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=f"{selected_gu} ì¬ê±´ì¶• ì‹œë‚˜ë¦¬ì˜¤")

# -------------------------------------------------------------
# ğŸ—ºï¸ 1-2ì‚¬ë¶„ë©´: ì§€ë„ + ë‹¨ì§€ ì„ íƒ
# -------------------------------------------------------------
col12_left, col12_right = st.columns([2.2, 1.4], gap="large")

with col12_left:
    st.markdown("### ğŸ—º 1-2ì‚¬ë¶„ë©´ Â· ì§€ë„ & ë‹¨ì§€ì„ íƒ")

    base_df = get_projects_by_gu(selected_gu)
    df_map = merge_projects_with_coords(selected_gu)


    # ì§€ë„ ìë¦¬ë§Œ ë¨¼ì € í™•ë³´ (í•„í„°/ì„ íƒ ì ìš© í›„ ì•„ë˜ì—ì„œ ì‹¤ì œ ì°¨íŠ¸ ë Œë”)
    map_slot = st.empty()

    if df_map.empty:
        st.warning("âš ï¸ í•´ë‹¹ êµ¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()


# ---------------------------
# ğŸ“‹ ë‹¨ì§€ í…Œì´ë¸” + í•„í„° UI
# ---------------------------
st.markdown("**ë‹¨ì§€ ëª©ë¡**")

# ìˆ«ì ì»¬ëŸ¼ ì •ë¦¬
df_list = df_map[["apt_id", "name", "households", "land_area_m2"]].copy()
df_list["households"] = pd.to_numeric(df_list["households"], errors="coerce")
df_list["land_area_m2"] = pd.to_numeric(df_list["land_area_m2"], errors="coerce")

# ===== í•„í„° ì˜ì—­ =====
fcol1, fcol2, fcol3, fcol4 = st.columns([1.6, 1.4, 1.6, 1.2])

with fcol1:
    kw = st.text_input("ê²€ìƒ‰ì–´(ë‹¨ì§€ëª…/í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ) ëª©ë™, ì‹ ì›”, ì¬ê±´ì¶•")

with fcol2:
    hh_min = int(np.nan_to_num(df_list["households"].min(), nan=0))
    hh_max = int(np.nan_to_num(df_list["households"].max(), nan=0))
    households_range = st.slider("ì„¸ëŒ€ìˆ˜ ë²”ìœ„", min_value=0, max_value=max(hh_max, 100), value=(0, max(hh_max, 100)))

with fcol3:
    la_min = float(np.nan_to_num(df_list["land_area_m2"].min(), nan=0.0))
    la_max = float(np.nan_to_num(df_list["land_area_m2"].max(), nan=0.0))
    land_range = st.slider(
        "ë©´ì  ë²”ìœ„(mÂ²)",
        min_value=0,
        max_value=int(max(la_max, 0)),
        value=(0, int(max(la_max, 0)))
    )

with fcol4:
    hide_zero = st.checkbox("0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°", value=True)

# ===== í•„í„° ì ìš© =====
mask = pd.Series(True, index=df_list.index)

if kw.strip():
    _kw = kw.strip().lower()
    mask &= df_list["name"].fillna("").str.lower().str.contains(_kw)

# ì„¸ëŒ€ìˆ˜ í•„í„°
mask &= df_list["households"].fillna(-1).between(households_range[0], households_range[1], inclusive="both")

# ë©´ì  í•„í„°
mask &= df_list["land_area_m2"].fillna(-1).between(land_range[0], land_range[1], inclusive="both")

# 0/ê²°ì¸¡ì¹˜ ìˆ¨ê¸°ê¸°
if hide_zero:
    mask &= df_list["households"].fillna(0) > 0
    mask &= df_list["land_area_m2"].fillna(0) > 0

filtered = df_list[mask].reset_index().rename(columns={"index": "orig_index"})  # orig_indexëŠ” df_map ì¸ë±ìŠ¤ ë³´ì¡´ìš©

# ===== ì •ë ¬ ì˜µì…˜ =====
scol1, scol2 = st.columns([1.2, 1.2])
with scol1:
    sort_key = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ", "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ", "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ", "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ", "ì´ë¦„ ì˜¤ë¦„ì°¨ìˆœ"], index=0)
with scol2:
    topn = st.selectbox("í‘œì‹œ ê°œìˆ˜", [10, 20, 50, 100, "ì „ì²´"], index=1)

if sort_key == "ì„¸ëŒ€ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=False, na_position="last")
elif sort_key == "ì„¸ëŒ€ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("households", ascending=True, na_position="last")
elif sort_key == "ë©´ì  ë‚´ë¦¼ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=False, na_position="last")
elif sort_key == "ë©´ì  ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("land_area_m2", ascending=True, na_position="last")
elif sort_key == "ì´ë¦„ ì˜¤ë¦„ì°¨ìˆœ":
    filtered = filtered.sort_values("name", ascending=True, na_position="last")

if topn != "ì „ì²´":
    filtered = filtered.head(int(topn))

# ===== í…Œì´ë¸” í‘œì‹œ =====

show_df = filtered[["orig_index", "name", "households", "land_area_m2"]].copy()
show_df = show_df.rename(columns={
    "name": "ë‹¨ì§€ëª…",
    "households": "ì„¸ëŒ€ìˆ˜",
    "land_area_m2": "ë©´ì (mÂ²)"
})

st.dataframe(
    show_df,
    use_container_width=True,
    hide_index=True,
    column_config={
        "orig_index": st.column_config.NumberColumn("ì›ë³¸ì¸ë±ìŠ¤", help="ë‚´ë¶€ ì„ íƒìš©", width="small"),
        "ë‹¨ì§€ëª…": st.column_config.TextColumn("ë‹¨ì§€ëª…"),
        "ì„¸ëŒ€ìˆ˜": st.column_config.NumberColumn("ì„¸ëŒ€ìˆ˜", format="%,d"),
        "ë©´ì (mÂ²)": st.column_config.NumberColumn("ë©´ì (mÂ²)", format="%,d"),
    }
)

# ===== ì„ íƒ ìœ„ì ¯ (í…Œì´ë¸”ê³¼ ë™ê¸°í™”) =====
if filtered.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    st.stop()

selected_orig_index = st.selectbox(
    "ì •ë¹„ì‚¬ì—… ë‹¨ì§€ ì„ íƒ",
    options=filtered["orig_index"].tolist(),
    format_func=lambda i: f"{df_map.loc[i,'name']} Â· ({int(df_map.loc[i,'households']) if pd.notna(df_map.loc[i,'households']) else 0}ì„¸ëŒ€, {df_map.loc[i,'land_area_m2'] if pd.notna(df_map.loc[i,'land_area_m2']) else '-'}ã¡)"
)

# ---- ê¸°ì¡´ ë¡œì§ê³¼ì˜ ì—°ê²°ì„ ìœ„í•´ selected_rowë¥¼ ì›ë³¸ ì¸ë±ìŠ¤ë¡œ ì„¸íŒ… ----
selected_row = int(selected_orig_index)

# âœ… ì„ íƒ ë‹¨ì§€ ì„ íƒ ì´í›„ ì§€ë„ í‘œì‹œ ì½”ë“œ (ì´ ìœ„ì¹˜ë¡œ ì˜®ê¸°ì„¸ìš”!)
filtered_indices = filtered["orig_index"].tolist()
map_data = df_map.loc[filtered_indices].reset_index(drop=True)

# ì„ íƒëœ ë‹¨ì§€ì˜ ì¢Œí‘œ (ì§€ë„ ì¤‘ì‹¬ ì´ë™ìš©)
sel_lat = float(df_map.loc[selected_row, "lat"])
sel_lon = float(df_map.loc[selected_row, "lon"])

# ì§€ë„ ë·° ì„¤ì •
view_state = pdk.ViewState(latitude=sel_lat, longitude=sel_lon, zoom=12.5)

# í•„í„°ëœ ë‹¨ì§€ í‘œì‹œ
layer_points = pdk.Layer(
    "ScatterplotLayer",
    data=map_data,
    get_position='[lon, lat]',
    get_radius=60,
    pickable=True,
    get_fill_color=[255, 140, 0, 160],  # ì£¼í™©
    get_line_color=[255, 255, 255],
    line_width_min_pixels=0.5,
)

# ì„ íƒ ë‹¨ì§€ í•˜ì´ë¼ì´íŠ¸
highlight_row = df_map.loc[[selected_row]].assign(_selected=True)
layer_highlight = pdk.Layer(
    "ScatterplotLayer",
    data=highlight_row,
    get_position='[lon, lat]',
    get_radius=150,
    pickable=False,
    get_fill_color=[0, 200, 255, 220],  # ì²­ë¡
    get_line_color=[0, 0, 0],
    line_width_min_pixels=1.2,
)

tooltip = {
    "html": "<b>{name}</b><br/>ìì¹˜êµ¬: {gu}<br/>ì„¸ëŒ€ìˆ˜: {households}<br/>êµ¬ì—­ë©´ì (mÂ²): {land_area_m2}",
    "style": {"backgroundColor": "#0f172a", "color": "white"},
}

# map_slotì€ ìœ„ì—ì„œ col12_leftì— ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìŒ
if map_data.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_highlight], initial_view_state=view_state, tooltip=tooltip))
else:
    map_slot.pydeck_chart(pdk.Deck(layers=[layer_points, layer_highlight], initial_view_state=view_state, tooltip=tooltip))

with col12_right:
    st.markdown("### ğŸ§¾ 1ì‚¬ë¶„ë©´ Â· ì‹ ì„¤ì¡°ê±´ ì…ë ¥")
    current = df_map.loc[selected_row]
    with st.container(border=True):
        st.markdown("**ê¸°ì¡´ ë‹¨ì§€ ì •ë³´**")
        st.markdown(
            f"- ë‹¨ì§€ëª…: **{current['name']}**\n\n"
            f"- ìì¹˜êµ¬: **{current['gu']}**\n\n"
            f"- ê¸°ì¡´ ì„¸ëŒ€ìˆ˜: **{int(current['households']) if pd.notna(current['households']) else 'ë¯¸ìƒ'} ì„¸ëŒ€**\n\n"
            f"- ì •ë¹„êµ¬ì—­ë©´ì : **{int(current['land_area_m2']):,} mÂ²**"
        )

    st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
    desired_py = st.number_input("ì›í•˜ëŠ” ì „ìš© í‰í˜•(í‰)", min_value=15, max_value=60, value=34, step=1)
    desired_households = st.number_input("ì›í•˜ëŠ” ì„¸ëŒ€ìˆ˜(ì‹ ê·œ)", min_value=100, max_value=3000,
                                         value=int(current["households"]) + 200 if pd.notna(current["households"]) else 500, step=50)
    expected_pop_increase_ratio = st.slider("ì˜ˆìƒ ì¸êµ¬ì¦ê°€ìœ¨(%)", 0, 100, 15, 5)
    new_bus_count = st.slider("ì‹ ì„¤ ë²„ìŠ¤ ëŒ€ìˆ˜", 0, 20, 2, 1)
    bus_capacity = st.number_input("ë²„ìŠ¤ 1ëŒ€ ìˆ˜ìš© ì¸ì›(ëª…)", min_value=30, max_value=120, value=70, step=5)

# -------------------------------------------------------------
# ğŸš¦ 3ì‚¬ë¶„ë©´ Â· í˜¼ì¡ë„ ì˜ˆì¸¡
# -------------------------------------------------------------
col3, col4 = st.columns([1.6, 1.4], gap="large")

with col3:
    st.markdown("### ğŸš¦ 3ì‚¬ë¶„ë©´ Â· í˜¼ì¡ë„ ì¦ê°€ ì˜ˆì¸¡")

    baseline_congestion = float(np.random.uniform(45, 65))
    people_per_household = 2.3
    delta_households = max(0, desired_households - int(current["households"]))
    added_population = delta_households * people_per_household * (1 + expected_pop_increase_ratio / 100)
    alpha, beta = 0.004, 0.0006
    congestion_delta = alpha * added_population - beta * (new_bus_count * bus_capacity)
    predicted_congestion = max(0.0, min(100.0, baseline_congestion + congestion_delta))

    hours = np.arange(6, 23)
    base_curve = np.clip(np.sin((hours-7)/4) * 20 + baseline_congestion, 10, 95)
    after_curve = np.clip(base_curve + congestion_delta, 0, 100)
    chart_df = pd.DataFrame({"hour": hours, "Baseline": base_curve, "After": after_curve})
    chart_long = chart_df.melt("hour", var_name="Scenario", value_name="CongestionIndex")

    line = (
        alt.Chart(chart_long)
        .mark_line(point=True)
        .encode(
            x=alt.X("hour:O", title="ì‹œê°„ëŒ€"),
            y=alt.Y("CongestionIndex:Q", title="í˜¼ì¡ë„ ì§€ìˆ˜(0~100)"),
            color=alt.Color("Scenario:N", legend=alt.Legend(title="ì‹œë‚˜ë¦¬ì˜¤")),
            tooltip=["hour", "Scenario", alt.Tooltip("CongestionIndex", format=".1f")],
        )
        .properties(height=360)
    )
    st.altair_chart(line, use_container_width=True)

# -------------------------------------------------------------
# ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼
# -------------------------------------------------------------
with col4:
    st.markdown("### ğŸ’¹ 4ì‚¬ë¶„ë©´ Â· ê¸°ëŒ€íš¨ê³¼ & ë¦¬í¬íŠ¸")

    price_per_py = st.number_input("í‰ë‹¹ ë¶„ì–‘ê°€/ë§¤ë§¤ê°€(ë§Œì›)", 1000, 100000, 4800, 100)
    cost_per_py = st.number_input("í‰ë‹¹ ì´ë¹„ìš©(ë§Œì›)", 500, 80000, 3100, 100)

    unit_py = desired_py
    margin_per_unit_million = (price_per_py - cost_per_py) * unit_py
    expected_margin_billion = (margin_per_unit_million * desired_households) / 10000

    kcol1, kcol2, kcol3 = st.columns(3)
    with kcol1:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì˜ˆìƒ ìˆ˜ìµ(ì´)</div><div class='kpi-value'>{expected_margin_billion:.1f} ì‹­ì–µ</div></div>", unsafe_allow_html=True)
    with kcol2:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>í˜¼ì¡ë„ ì§€ìˆ˜(ì˜ˆì¸¡)</div><div class='kpi-value'>{predicted_congestion:.1f}</div></div>", unsafe_allow_html=True)
    with kcol3:
        st.markdown(f"<div class='kpi-card'><div class='kpi-title'>ì‹ ê·œ ì„¸ëŒ€ìˆ˜</div><div class='kpi-value'>{desired_households:,} ì„¸ëŒ€</div></div>", unsafe_allow_html=True)
